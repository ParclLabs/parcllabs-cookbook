{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00775985-42bd-4ebc-87d6-6a8abbe0035a",
   "metadata": {},
   "source": [
    "# Welcome to the Lab ðŸ¥¼ðŸ§ª\n",
    "\n",
    "## Rental Mix Analysis\n",
    "\n",
    "Why does rental housing mix matter? The types of units trading varies by market and can provide insight into where rental prices are going. This analysis will look at the rental mix of a market. The [Parcl Labs Rental Price Feeds](https://www.parcllabs.com/articles/parcl-labs-rental-price-feed-white-paper) is the rental price per square foot of units trading on a market. Understanding the mix and the variation in mix over time can provide insight into where prices could go. \n",
    "\n",
    "**Note** This notebook will work with any of the 70k+ markets supported by the Parcl Labs API.\n",
    "\n",
    "As a reminder, you can get your Parcl Labs API key [here](https://dashboard.parcllabs.com/signup) to follow along. \n",
    "\n",
    "To run this immediately, you can use Google Colab. Remember, you must set your `PARCL_LABS_API_KEY` as a secret. See this [guide](https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75) for more information.\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ParclLabs/parcllabs-examples/blob/main/python/traders/rental_mix_analysis.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd87dd1d-b6d0-491c-922a-88e9a75cdb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "# Collab setup from one click above\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import userdata\n",
    "    %pip install parcllabs plotly kaleido numpy\n",
    "    !git clone https://github.com/ParclLabs/parcllabs-examples.git\n",
    "    sys.path.append('/content/parcllabs-examples/python/')\n",
    "    api_key = userdata.get('PARCL_LABS_API_KEY')\n",
    "else:\n",
    "    api_key = os.getenv('PARCL_LABS_API_KEY')\n",
    "    cur_dir = os.getcwd()\n",
    "    chart_dir = os.path.join(cur_dir, '..')\n",
    "    sys.path.append(chart_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6635c6-8cd8-446c-a4a4-d0497550e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import parcllabs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from parcllabs import ParclLabsClient\n",
    "from charting.utils import create_labs_logo_dict, format_metro_names\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(f\"Parcl Labs Version: {parcllabs.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dbcf0d-717d-4a9b-acee-82006e1f6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init client\n",
    "client = ParclLabsClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8e9fc-73e0-4c53-88ff-1fdd92b95849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 100 CBSAs by population\n",
    "markets = client.search_markets.retrieve(\n",
    "    as_dataframe=True,\n",
    "    # sort_by='PARCL_EXCHANGE_MARKET',\n",
    "    sort_by='PRICEFEED_MARKET',\n",
    "    sort_order='DESC',\n",
    "    params={\n",
    "        'limit': 100\n",
    "    }\n",
    ")\n",
    "\n",
    "markets = markets.loc[markets['pricefeed_market']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3254bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_names(nme):\n",
    "    replace = {\n",
    "        'Washington City': 'D.C.',\n",
    "        'United States Of America': 'USA',\n",
    "        'New York City': 'NYC',\n",
    "        'Kings County': 'Brooklyn, NY',\n",
    "    }\n",
    "    if nme in replace.keys():\n",
    "        return replace[nme]\n",
    "    else:\n",
    "        return nme\n",
    "    \n",
    "markets['name'] = markets['name'].apply(clean_names)\n",
    "markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d9bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2020-01-01'\n",
    "\n",
    "rentals = client.rental_price_feed.retrieve_many(\n",
    "        parcl_ids=markets['parcl_id'].tolist(),\n",
    "        start_date=START_DATE,\n",
    "        as_dataframe=True,\n",
    "        params={'limit': 1000},  # expand the limit to 1000, these are daily series\n",
    "        auto_paginate=True, # auto paginate to get all the data - WARNING: ~6k credits can be used in one parcl price feed. Change the START_DATE to a more recent date to reduce the number of credits used\n",
    ")\n",
    "\n",
    "rentals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacd4f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals = rentals.merge(markets[['name', 'parcl_id']], on='parcl_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c72883",
   "metadata": {},
   "outputs": [],
   "source": [
    "yields = client.rental_market_metrics_gross_yield.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    property_type='ALL_PROPERTIES',\n",
    "    as_dataframe=True,\n",
    "    start_date=START_DATE,\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")\n",
    "\n",
    "mkt_prices = client.market_metrics_housing_event_prices.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    as_dataframe=True,\n",
    "    start_date=START_DATE,\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")\n",
    "\n",
    "mkt_counts = client.market_metrics_housing_event_counts.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    as_dataframe=True,\n",
    "    start_date=START_DATE,\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0019a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_supply = client.rental_market_metrics_new_listings_for_rent_rolling_counts.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    as_dataframe=True,\n",
    "    start_date='2023-03-01',\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")\n",
    "\n",
    "rental_supply_sfh = client.rental_market_metrics_new_listings_for_rent_rolling_counts.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    property_type='SINGLE_FAMILY',\n",
    "    as_dataframe=True,\n",
    "    start_date='2023-03-01',\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")\n",
    "\n",
    "rental_concentration = client.rental_market_metrics_rental_units_concentration.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    as_dataframe=True,\n",
    "    start_date=START_DATE,\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84183553",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_supply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7bc8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_supply_sfh = rental_supply_sfh.rename(columns={'rolling_30_day': 'rolling_30_day_sfh', 'rolling_60_day': 'rolling_60_day_sfh', 'rolling_90_day': 'rolling_90_day_sfh'})\n",
    "rental_supply = rental_supply.merge(rental_supply_sfh[['parcl_id', 'date', 'rolling_30_day_sfh', 'rolling_60_day_sfh', 'rolling_90_day_sfh']], on=['parcl_id', 'date'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3f8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get investor metrics\n",
    "investor_ownership = client.investor_metrics_housing_stock_ownership.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    as_dataframe=True,\n",
    "    start_date=START_DATE,\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")\n",
    "\n",
    "investor_prices = client.investor_metrics_housing_event_prices.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    as_dataframe=True,\n",
    "    start_date=START_DATE,\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")\n",
    "\n",
    "investor_counts = client.investor_metrics_housing_event_counts.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    as_dataframe=True,\n",
    "    start_date=START_DATE,\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d56ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_stock = client.market_metrics_housing_stock.retrieve_many(\n",
    "    parcl_ids=rentals['parcl_id'].unique().tolist(),\n",
    "    as_dataframe=True,\n",
    "    start_date=START_DATE,\n",
    "    params={\n",
    "        'limit': 300\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cfcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rental_concentration['date'] = pd.to_datetime(rental_concentration['date'])\n",
    "rental_concentration = rental_concentration.rename(columns={'date': 'month_start'})\n",
    "# housing_stock['date'] = pd.to_datetime(housing_stock['date'])\n",
    "housing_stock = housing_stock.rename(columns={'date': 'month_start'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a9907",
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_supply['date'] = pd.to_datetime(rental_supply['date'])\n",
    "rental_supply['month_start'] = rental_supply['date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "rental_supply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aad80f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3c5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26943ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = rentals.copy(deep=True)\n",
    "pf['date'] = pd.to_datetime(pf['date'])\n",
    "pf['month_start'] = pf['date'].dt.to_period('M').dt.to_timestamp()\n",
    "pf_monthly = pf.groupby(['parcl_id', 'month_start'])['rental_price_feed'].median().reset_index()\n",
    "investor_ownership_cpy = investor_ownership.copy(deep=True)\n",
    "investor_ownership_cpy['date'] = pd.to_datetime(investor_ownership_cpy['date'])\n",
    "investor_ownership_cpy = investor_ownership_cpy.rename(columns={'date': 'month_start'})\n",
    "pf_monthly = pf_monthly.merge(investor_ownership_cpy, on=['parcl_id', 'month_start'], how='inner')\n",
    "pf_monthly['pf_shift'] = pf_monthly['rental_price_feed'].shift(-4)\n",
    "pf_monthly[['investor_pct_ownership', 'pf_shift']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab106e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cpy = investor_ownership.copy(deep=True)\n",
    "cpy['date'] = pd.to_datetime(cpy['date'])\n",
    "cpy = cpy.rename(columns={'date': 'month_start'})\n",
    "chart = rental_supply.merge(cpy, on=['parcl_id', 'month_start'], how='inner')\n",
    "chart = chart.merge(rental_concentration, on=['parcl_id', 'month_start'], how='inner')\n",
    "chart = chart.merge(housing_stock, on=['parcl_id', 'month_start'], how='inner')\n",
    "chart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5f8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart['rolling_60_day_all_other'] = chart['rolling_60_day'] - chart['rolling_60_day_sfh']\n",
    "chart['all_other_properties'] = chart['all_properties'] - chart['single_family']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14573e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "markets.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29024a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = 5387853\n",
    "markets.loc[markets['parcl_id'] == pid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart['vacancy_rate'] = chart['rolling_60_day'] / chart['rental_units']\n",
    "chart['rental_stock_percentage'] = chart['rolling_60_day'] / chart['all_properties']\n",
    "chart['rental_stock_percentage_sfh'] = chart['rolling_60_day_sfh'] / chart['single_family']\n",
    "chart['rental_stock_percentage_all_other'] = chart['rolling_60_day_all_other'] / chart['all_other_properties']\n",
    "chart.loc[chart['parcl_id']==pid].plot(x='date', y='investor_pct_ownership', title='New Listings for Rent', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74aa587",
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals.loc[(rentals['parcl_id']==pid) & (rentals['date']>='2020-03-01')].plot(x='date', y='rental_price_feed', title='Rental Price Feed', figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_ownership.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6c7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2 = chart.merge(rentals, on=['parcl_id', 'date'], how='inner')\n",
    "chart2['pf_shift'] = chart2.groupby('parcl_id')['rental_price_feed'].shift(-8)\n",
    "chart2 = chart2.dropna(subset=['pf_shift'])\n",
    "chart2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = chart2.loc[chart2['parcl_id']==pid]\n",
    "test['rental_stock_percentage_change'] = test['rental_stock_percentage'].pct_change()\n",
    "test['rental_stock_percentage_sfh_change'] = test['rental_stock_percentage_sfh'].pct_change()\n",
    "test['rental_stock_percentage_all_other_change'] = test['rental_stock_percentage_all_other'].pct_change()\n",
    "test['rolling_7_day_change'] = test['rolling_7_day'].pct_change()\n",
    "test['rolling_30_day_change'] = test['rolling_30_day'].pct_change()\n",
    "test['rolling_60_day_change'] = test['rolling_60_day'].pct_change()\n",
    "test['rolling_90_day_change'] = test['rolling_90_day'].pct_change()\n",
    "test['vacancy_change'] = test['vacancy_rate'].pct_change()\n",
    "test = test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a45f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['investor_pct_ownership', 'pf_shift']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c236e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2[['rolling_60_day', 'pf_shift']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8705ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2.loc[chart2['pct_rental_concentration'] > 40][['investor_pct_ownership', 'pf_shift']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a416211",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2.loc[chart2['pct_rental_concentration']>40]['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2[['investor_pct_ownership', 'pf_shift']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f859e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nme = chart2.groupby('name')['pct_rental_concentration'].mean().reset_index()\n",
    "nme.loc[nme['name'] == 'Chicago City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96d5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "markets.loc[markets['name'] == 'Chicago City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7812d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "nme.loc[nme['pct_rental_concentration'] > 30].sort_values('pct_rental_concentration', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart2.loc[chart2['name']=='Miami City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db006b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering, data prep\n",
    "investor_counts = investor_counts.rename(columns={\n",
    "    'acquisitions': 'investor_acquisitions',\n",
    "    'dispositions': 'investor_dispositions',\n",
    "    'new_listings_for_sale': 'investor_new_listings_for_sale'\n",
    "})\n",
    "\n",
    "investor_ownership = investor_ownership.rename(columns={\n",
    "    'count': 'investor_count',\n",
    "    'pct_ownership': 'investor_pct_ownership'\n",
    "})\n",
    "\n",
    "investor_prices = investor_prices.rename(columns={\n",
    "    'price_per_square_foot_median_acquisitions': 'investor_price_per_square_foot_median_acquisitions',\n",
    "    'price_per_square_foot_median_new_listings_for_sale': 'investor_price_per_square_foot_median_new_listings_for_sale'\n",
    "})\n",
    "\n",
    "investor_counts['investor_net'] = investor_counts['investor_acquisitions'] - investor_counts['investor_dispositions']\n",
    "mkt_prices = mkt_prices.rename(\n",
    "    columns=\n",
    "    {\n",
    "        'price_median_sales': 'mkt_price_median_sales', \n",
    "        'price_median_new_listings_for_sale': 'mkt_price_median_new_listings_for_sale',\n",
    "        'price_per_square_foot_median_sales': 'mkt_price_per_square_foot_median_sales',\n",
    "        'price_per_square_foot_median_new_listings_for_sale': 'mkt_price_per_square_foot_median_new_listings_for_sale'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkt_counts = mkt_counts.drop('property_type', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11eddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc80522",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp = yields.merge(investor_counts[['date', 'parcl_id', 'investor_acquisitions', 'investor_dispositions', 'investor_new_listings_for_sale']], on=['parcl_id', 'date'])\n",
    "tmp = tmp.merge(\n",
    "    investor_prices[[\n",
    "        'parcl_id',\n",
    "        'date',\n",
    "        'investor_price_per_square_foot_median_acquisitions', \n",
    "        'investor_price_per_square_foot_median_new_listings_for_sale'\n",
    "    ]], \n",
    "    on=['parcl_id', 'date']\n",
    ")\n",
    "tmp = tmp.merge(investor_ownership, on=['parcl_id', 'date'])\n",
    "tmp = tmp.merge(mkt_counts, on=['parcl_id', 'date'])\n",
    "tmp = tmp.merge(markets[['location_type', 'parcl_id']], on='parcl_id')\n",
    "tmp = tmp.merge(mkt_prices[['mkt_price_per_square_foot_median_sales', 'date', 'parcl_id']], on=['parcl_id', 'date'])\n",
    "# tmp = tmp.merge(supply, on=['parcl_id', 'date'])\n",
    "# tmp[['pct_gross_yield', 'net']].corr()\n",
    "\n",
    "# Ensure 'date' column is in datetime format\n",
    "rentals['date'] = pd.to_datetime(rentals['date'])\n",
    "\n",
    "# Truncate date to the first of the month\n",
    "rentals['month_start'] = rentals['date'].dt.to_period('M').dt.to_timestamp()\n",
    "rentals.head()\n",
    "\n",
    "agg = rentals.groupby(['parcl_id', 'month_start'])['rental_price_feed'].mean().reset_index()\n",
    "agg = agg.rename(columns={'month_start': 'date'})\n",
    "tmp['date'] = pd.to_datetime(tmp['date'])\n",
    "tmp = tmp.merge(agg, on=['parcl_id', 'date'], how='inner')\n",
    "tmp = tmp.sort_values('date')\n",
    "tmp['pf_shift'] = tmp.groupby('parcl_id')['rental_price_feed'].shift(-3)\n",
    "tmp = tmp.dropna()\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105ccaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.loc[tmp['parcl_id']==5372594][['date', 'rental_price_feed', 'pf_shift']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Exploratory Data Analysis (EDA)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(\n",
    "    tmp[[\n",
    "        'pct_gross_yield',\n",
    "'investor_acquisitions',\n",
    " 'investor_dispositions',\n",
    " 'investor_new_listings_for_sale',\n",
    " 'investor_price_per_square_foot_median_acquisitions',\n",
    " 'investor_price_per_square_foot_median_new_listings_for_sale',\n",
    " 'investor_count',\n",
    " 'investor_pct_ownership',\n",
    " 'sales',\n",
    " 'new_listings_for_sale',\n",
    " 'new_rental_listings',\n",
    " 'mkt_price_per_square_foot_median_sales',\n",
    " 'rental_price_feed',\n",
    " 'pf_shift'\n",
    "]].corr(), \n",
    "    annot=True, \n",
    "    cmap='coolwarm')\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df44918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tmp is your DataFrame\n",
    "tmp['date'] = pd.to_datetime(tmp['date'])\n",
    "tmp['year'] = tmp['date'].dt.year\n",
    "tmp['month'] = tmp['date'].dt.month\n",
    "tmp['parcl_id'] = tmp['parcl_id'].astype('category')\n",
    "\n",
    "tmp['season'] = tmp['month'].apply(lambda x: 'Winter' if x in [12, 1, 2] else 'Spring' if x in [3, 4, 5] else 'Summer' if x in [6, 7, 8] else 'Fall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac139c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['investor_ppsqf_purchase_premium'] = (tmp['investor_price_per_square_foot_median_acquisitions'] - tmp['mkt_price_per_square_foot_median_sales'])/tmp['mkt_price_per_square_foot_median_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a55355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical features\n",
    "numerical_features = [\n",
    "'pct_gross_yield',\n",
    "# 'investor_acquisitions',\n",
    " # 'investor_dispositions',\n",
    " # 'investor_new_listings_for_sale',\n",
    " 'investor_price_per_square_foot_median_acquisitions',\n",
    " # 'investor_price_per_square_foot_median_new_listings_for_sale',\n",
    " # 'investor_count',\n",
    " 'investor_pct_ownership',\n",
    " 'sales',\n",
    " # 'new_listings_for_sale',\n",
    "# 'new_rental_listings',\n",
    " 'mkt_price_per_square_foot_median_sales',\n",
    " # 'investor_ppsqf_purchase_premium'\n",
    "]\n",
    "categorical_features = ['season']\n",
    "\n",
    "# Checking multicollinearity using VIF\n",
    "X_vif = tmp[numerical_features].dropna()\n",
    "\n",
    "# Apply RobustScaler to handle outliers and extreme values\n",
    "scaler = RobustScaler()\n",
    "X_vif_scaled = scaler.fit_transform(X_vif)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X_vif.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_vif_scaled, i) for i in range(len(X_vif.columns))]\n",
    "print(vif_data)\n",
    "\n",
    "# Creating train-test split\n",
    "X = tmp[numerical_features + categorical_features]\n",
    "y = tmp['pf_shift']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, shuffle=False)\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Ridge Regression Model\n",
    "ridge_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_ridge_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mae = mean_absolute_error(y_test, y_ridge_pred)\n",
    "mse = mean_squared_error(y_test, y_ridge_pred)\n",
    "ridge_r2 = r2_score(y_test, y_ridge_pred)\n",
    "\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'R2: {ridge_r2}')\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(ridge_model, X, y, cv=TimeSeriesSplit(n_splits=5), scoring='r2')\n",
    "print(f'Cross-validated R2 scores: {cv_scores}')\n",
    "print(f'Mean cross-validated R2 score: {np.mean(cv_scores)}')\n",
    "\n",
    "# Feature importance\n",
    "feature_names = numerical_features + list(ridge_model.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    "ridge_coefs = ridge_model.named_steps['regressor'].coef_\n",
    "\n",
    "feature_importance = pd.Series(ridge_coefs, index=feature_names).sort_values(ascending=False)\n",
    "plt.figure(figsize=(12, 8))\n",
    "feature_importance.plot(kind='bar')\n",
    "plt.title('Feature Importance - Ridge Regression')\n",
    "plt.show()\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test - y_ridge_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_ridge_pred, residuals)\n",
    "plt.axhline(0, color='r', linestyle='--')\n",
    "plt.title('Residuals vs Predicted')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the relationship between yields and investor pct ownership\n",
    "\n",
    "a = tmp[['date', 'pct_gross_yield', 'investor_acquisitions']].copy()\n",
    "a['date'] = pd.to_datetime(a['date'])\n",
    "a = a.set_index('date')\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f890a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift investor_pct_ownership by 3 months\n",
    "a['investor_acquisitions_shifted'] = a['investor_acquisitions'].shift(3)\n",
    "a = a.dropna()\n",
    "a.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7aa979",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "\n",
    "# Function to create lagged features\n",
    "def create_lagged_features(df, features, max_lag):\n",
    "    lagged_features = pd.DataFrame(index=df.index)\n",
    "    for feature in features:\n",
    "        for lag in range(1, max_lag + 1):\n",
    "            lagged_features[f'{feature}_lag{lag}'] = df.groupby('parcl_id')[feature].shift(lag)\n",
    "    return lagged_features\n",
    "\n",
    "# Define your features and max lag\n",
    "numerical_features = [\n",
    "    'pct_gross_yield',\n",
    "    'investor_acquisitions',\n",
    "    'investor_dispositions',\n",
    "    'investor_new_listings_for_sale',\n",
    "    'investor_price_per_square_foot_median_acquisitions',\n",
    "    'investor_price_per_square_foot_median_new_listings_for_sale',\n",
    "    'investor_count',\n",
    "    'investor_pct_ownership',\n",
    "    'sales',\n",
    "    'new_listings_for_sale',\n",
    "    'new_rental_listings',\n",
    "    'mkt_price_per_square_foot_median_sales',\n",
    "    'rental_price_feed',\n",
    "    'investor_ppsqf_purchase_premium'\n",
    "]\n",
    "max_lag = 12\n",
    "\n",
    "# Create lagged features\n",
    "lagged_df = create_lagged_features(tmp, numerical_features, max_lag)\n",
    "\n",
    "# Merge lagged features with the original dataframe\n",
    "lagged_df = tmp.join(lagged_df).dropna()\n",
    "\n",
    "# Function to compute cross-correlation\n",
    "def compute_cross_correlation(df, x, y, max_lag):\n",
    "    correlations = []\n",
    "    for lag in range(1, max_lag + 1):\n",
    "        corr = df[x].corr(df[f'{y}_lag{lag}'])\n",
    "        correlations.append((x, y, lag, corr))\n",
    "    return correlations\n",
    "\n",
    "# Function to perform Granger causality test\n",
    "def granger_test(df, x, y, max_lag):\n",
    "    test_result = grangercausalitytests(df[[x, y]].dropna(), max_lag, verbose=False)\n",
    "    p_values = [round(test_result[i + 1][0]['ssr_ftest'][1], 4) for i in range(max_lag)]\n",
    "    return p_values\n",
    "\n",
    "# Initialize DataFrames to store results\n",
    "cross_corr_results = pd.DataFrame(columns=['Variable_X', 'Variable_Y', 'Lag', 'Correlation'])\n",
    "granger_results = pd.DataFrame(columns=['Variable_X (Lagged)', 'Variable_Y', 'Lag', 'P_Value'])\n",
    "\n",
    "# Loop through all combinations of variables to perform cross-correlation and Granger causality tests\n",
    "for x in numerical_features:\n",
    "    for y in numerical_features:\n",
    "        if x != y:\n",
    "            # Compute cross-correlation\n",
    "            cross_corr = compute_cross_correlation(lagged_df, x, y, max_lag)\n",
    "            cross_corr_df = pd.DataFrame(cross_corr, columns=['Variable_X', 'Variable_Y', 'Lag', 'Correlation'])\n",
    "            cross_corr_results = pd.concat([cross_corr_results, cross_corr_df], ignore_index=True)\n",
    "            \n",
    "            # Perform Granger causality test\n",
    "            granger_p_values = granger_test(lagged_df, x, y, max_lag)\n",
    "            granger_df = pd.DataFrame({\n",
    "                'Variable_X (Lagged)': [f'{x}_lag{i+1}' for i in range(max_lag)], \n",
    "                'Variable_Y': [y]*max_lag, \n",
    "                'Lag': list(range(1, max_lag + 1)), \n",
    "                'P_Value': granger_p_values\n",
    "            })\n",
    "            granger_results = pd.concat([granger_results, granger_df], ignore_index=True)\n",
    "\n",
    "# Review and analyze the results\n",
    "# Cross-correlation: Filter strong correlations\n",
    "strong_correlations = cross_corr_results[cross_corr_results['Correlation'].abs() > 0.5]\n",
    "print(\"Strong Cross-Correlations:\")\n",
    "print(strong_correlations)\n",
    "\n",
    "# Granger causality: Filter significant p-values (e.g., p < 0.05)\n",
    "significant_granger = granger_results[granger_results['P_Value'] < 0.05]\n",
    "print(\"Significant Granger Causality Results:\")\n",
    "print(significant_granger)\n",
    "\n",
    "# Save results to CSV files for further analysis if needed\n",
    "cross_corr_results.to_csv('cross_correlation_results.csv', index=False)\n",
    "granger_results.to_csv('granger_causality_results.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_granger['Variable_Y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebb038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7646b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4b093",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong_correlations.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3e768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_granger.to_csv('granger.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4ed6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
