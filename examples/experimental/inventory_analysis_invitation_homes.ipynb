{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02467986",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Welcome to the Lab ðŸ¥¼ðŸ§ª</h1>\n",
    "</center>\n",
    "\n",
    "### How can I analyze dispostions by SFR operators and how profitable those sales were\n",
    "\n",
    "In this notebook, we will be examining homes solf by Invitation Homes in the Houston MSA market for the last 12 months (as of July 22 2025). We will use the Parcl Labs API to get the event history for the properties of interest.\n",
    "\n",
    "#### Need help getting started?\n",
    "\n",
    "As a reminder, you can get your Parcl Labs API key [here](https://app.parcllabs.com/) to follow along.\n",
    "\n",
    "To run this immediately, you can use Google Colab.\n",
    "\n",
    "Run in collab --> [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ParclLabs/parcllabs-cookbook/blob/main/examples/experimental/inventory_analysis_invitation_homes.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d616b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install most recent version of parcllabs\n",
    "%pip install --upgrade parcllabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries for the analysis\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from parcllabs import ParclLabsClient\n",
    "\n",
    "\n",
    "# Create a ParclLabsClient instance\n",
    "client = ParclLabsClient(\n",
    "    api_key=os.environ.get('PARCL_LABS_API_KEY', \"<your Parcl Labs API key if not set as environment variable>\"), \n",
    "    limit=1000, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6bfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for Houston market\n",
    "markets = client.search.markets.retrieve(\n",
    "    query = 'Houston',\n",
    "    location_type = 'CBSA',\n",
    "    sort_by='TOTAL_POPULATION',  # Sort by total population\n",
    "    sort_order='DESC',           # In descending order\n",
    "    limit=10                    # Limit results to top 100 metros\n",
    ")\n",
    "markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244f368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parcl id of the houston market, in this case it is the first market \n",
    "# in the list with index 0\n",
    "market_for_analysis_id = markets.iloc[0]['parcl_id']\n",
    "print('Houston market parcl id: ', market_for_analysis_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ccf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the data frame to show all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f142aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will get the event history for the properties of interest using the same endpoint as before\n",
    "# this will allow us to get the average time in market\n",
    "df_properties_listed_last_12_months, metadata = client.property_v2.search.retrieve(\n",
    "    parcl_ids=[market_for_analysis_id],\n",
    "    event_names=['ALL_LISTINGS'], # search all listings events\n",
    "    max_event_date=\"2025-07-22\", # get the events for the last 12 months\n",
    "    min_event_date=\"2024-07-22\",\n",
    "    include_property_details=True, # include the property details in the response\n",
    "    owner_name=[\"INVITATION_HOMES\"], # only get the properties that are owned by Invitation Homes at the time of the event\n",
    "    limit = 10000 # set a high limit to get all the events\n",
    "    )\n",
    "all_properties_of_interest = df_properties_listed_last_12_months.parcl_property_id.unique().tolist()\n",
    "print(f'We found {len(all_properties_of_interest)} properties that were listed for sale in the last 12 months')\n",
    "print(f'total number of rows: {len(df_properties_listed_last_12_months)}')\n",
    "df_properties_listed_last_12_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d586a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets get all the event data for those properties\n",
    "# we dont include the owner name here \n",
    "# to make sure we also get whena property was sold by invitation homes\n",
    "# and is no longer associated to them \n",
    "all_events_for_properties_of_interest, metadata = client.property_v2.search.retrieve(\n",
    "    parcl_property_ids=all_properties_of_interest,\n",
    "    event_names=['ALL_SOLD','ALL_LISTINGS'], # search all listings and all sold events\n",
    "    max_event_date=\"2025-07-22\", # get the events for the last 12 months\n",
    "    min_event_date=\"2024-07-22\",\n",
    "    include_property_details=True, # include the property details in the response\n",
    "    \n",
    "    limit = 10000 # set a high limit to get all the events\n",
    "    )\n",
    "print(len(all_events_for_properties_of_interest))\n",
    "all_events_for_properties_of_interest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0326082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save this data to a csv file\n",
    "all_events_for_properties_of_interest.to_csv('all_events_for_properties_of_interest_invitation_homes_072225.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d69b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets find number of properties listed for sale in the last 12 months\n",
    "number_of_unique_properties_listed_for_sale_in_12_months = (all_events_for_properties_of_interest\n",
    "                                                .query('event_event_name == \"LISTED_SALE\"')\n",
    "                                                .query('event_event_date >= \"2024-07-22\"')\n",
    "                                                .parcl_property_id.nunique())\n",
    "print(f'Number of unique properties listed for sale in the last 12 months: {number_of_unique_properties_listed_for_sale_in_12_months}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064b42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets do how many were sold in the last 12 months\n",
    "number_of_unique_properties_sold_in_12_months = (all_events_for_properties_of_interest\n",
    "                                                .query('event_event_name == \"SOLD\"')\n",
    "                                                .parcl_property_id.nunique())\n",
    "print(f'Number of unique properties sold in the last 12 months: {number_of_unique_properties_sold_in_12_months}')\n",
    "number_of_unique_properties_sold_in_12_months_ids = (all_events_for_properties_of_interest\n",
    "                                                .query('event_event_name == \"SOLD\"')\n",
    "                                                .parcl_property_id.unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d15fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of the properties that actually sold\n",
    "properties_sold_in_12_months = (all_events_for_properties_of_interest\n",
    "                                .query('event_event_name == \"SOLD\"')\n",
    "                                .parcl_property_id.unique().tolist())\n",
    "print(len(properties_sold_in_12_months))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfaa86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values for a specific property\n",
    "all_events_for_properties_of_interest.query('parcl_property_id==75571945').sort_values(by='event_event_date', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b4a912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'event_event_date' column is of datetime type before any calculations\n",
    "all_events_for_properties_of_interest['event_event_date'] = pd.to_datetime(all_events_for_properties_of_interest['event_event_date'])\n",
    "\n",
    "# Calculate days from first listing event to first SOLD event for each property\n",
    "days_on_market_df = (all_events_for_properties_of_interest\n",
    "    .query('parcl_property_id in @properties_sold_in_12_months')\n",
    "    .query('event_event_name in [\"LISTED_SALE\", \"RELISTED\", \"PRICE_CHANGE\", \"SOLD\"]')\n",
    "    .sort_values(['parcl_property_id', 'event_event_date'])\n",
    "    .assign(\n",
    "        # Mark properties that have SOLD events\n",
    "        has_sold = lambda x: x.groupby('parcl_property_id')['event_event_name'].transform(lambda y: 'SOLD' in y.values),\n",
    "        # Mark the first event for each property\n",
    "        is_first_event = lambda x: x.groupby('parcl_property_id').cumcount() == 0,\n",
    "        # Create normalized event name - only transform if it's first event AND property has SOLD\n",
    "        normalized_event_name = lambda x: np.where(\n",
    "            (x['has_sold']) & \n",
    "            (x['is_first_event']) & \n",
    "            (x['event_event_name'].isin(['RELISTED', 'PRICE_CHANGE'])),\n",
    "            'LISTED_SALE',\n",
    "            x['event_event_name']\n",
    "        )\n",
    "    )\n",
    "    .query('normalized_event_name in [\"LISTED_SALE\", \"SOLD\"]')\n",
    "    .groupby(['parcl_property_id', 'normalized_event_name'])['event_event_date'].first()\n",
    "    .unstack('normalized_event_name')\n",
    "    .dropna()  # Only keep properties with both LISTED_SALE and SOLD events\n",
    "    .assign(days_on_market = lambda x: (x['SOLD'] - x['LISTED_SALE']).dt.days)\n",
    "    .query('days_on_market >= 0')  # Ensure SOLD comes after LISTED_SALE\n",
    ")\n",
    "\n",
    "# Calculate average days on market\n",
    "avg_days_on_market = days_on_market_df['days_on_market'].mean()\n",
    "median_days_on_market = days_on_market_df['days_on_market'].median()\n",
    "print(f'Average days on market: {avg_days_on_market}')\n",
    "print(f'Median days on market: {median_days_on_market}')\n",
    "print(f'Number of properties sold used for the analysis: {len(days_on_market_df)}')\n",
    "days_on_market_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172ef7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate price changes (absolute and percentage) for properties with price changes\n",
    "price_changes_analysis = (all_events_for_properties_of_interest\n",
    "    .query('event_event_name in [\"LISTED_SALE\", \"PRICE_CHANGE\", \"RELISTED\", \"SOLD\"]')  # Events with prices\n",
    "    .query('event_price>0')\n",
    "    .sort_values(['parcl_property_id', 'event_event_date'], ascending=[True, True])\n",
    "    .assign(\n",
    "        previous_price = lambda x: x.groupby('parcl_property_id')['event_price'].shift(1),\n",
    "        price_change_absolute = lambda x: x['event_price'] - x['previous_price'],\n",
    "        price_change_percentage = lambda x: ((x['event_price'] - x['previous_price']) / x['previous_price'] * 100)\n",
    "    )\n",
    "    .assign(\n",
    "        is_price_change = lambda x: (\n",
    "            (x['event_event_name'].isin(['PRICE_CHANGE', 'RELISTED','LISTED_SALE'])) & \n",
    "            (x['previous_price'].notna()) &  # Must have a previous price\n",
    "            (x['price_change_absolute'] != 0)  # Price must actually change\n",
    "        )\n",
    "    )\n",
    "    .assign(\n",
    "        price_changes_per_property = lambda x: x.groupby('parcl_property_id')['is_price_change'].transform('sum')\n",
    "    )\n",
    "    .query('event_price > 0')  # remove properties with no price\n",
    "    .query('is_price_change == True or event_event_name == \"SOLD\"')  # Show price changes and final sales\n",
    "    # can be modified to only show is_price_change, meaning a true price change\n",
    "    .loc[:, ['parcl_property_id', 'event_event_name', 'event_event_date', \n",
    "            'event_price', 'previous_price', \n",
    "            'price_change_absolute', 'price_change_percentage', \n",
    "            'price_changes_per_property']]\n",
    ")\n",
    "\n",
    "print(f'Number of properties with price changes: {price_changes_analysis.parcl_property_id.nunique()}')\n",
    "\n",
    "# Summary statistics for price changes per property\n",
    "price_change_counts_summary = (price_changes_analysis\n",
    "    .groupby('parcl_property_id')['price_changes_per_property']\n",
    "    .first()  # Get unique count per property\n",
    "    .describe()\n",
    ")\n",
    "\n",
    "print(f'Price changes per property statistics:')\n",
    "print(price_change_counts_summary)\n",
    "\n",
    "price_changes_analysis.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f4fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for price changes\n",
    "price_change_summary = (price_changes_analysis\n",
    "    .agg({\n",
    "        'price_change_absolute': ['mean', 'median', 'std', 'min', 'max'],\n",
    "        'price_change_percentage': ['mean', 'median', 'std', 'min', 'max']\n",
    "    })\n",
    "    .round(2)\n",
    ")\n",
    "price_change_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ec272e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate original listing vs final sale price analysis\n",
    "listing_vs_sale_analysis = (all_events_for_properties_of_interest\n",
    "    .query('event_event_name in [\"LISTED_SALE\", \"RELISTED\", \"PRICE_CHANGE\", \"SOLD\"]')\n",
    "    .sort_values(['parcl_property_id', 'event_event_date'])\n",
    "    .assign(\n",
    "        # Mark first event for each property\n",
    "        is_first_event = lambda x: x.groupby('parcl_property_id').cumcount() == 0,\n",
    "        # Mark listing-type events\n",
    "        is_listing_event = lambda x: x['event_event_name'].isin(['LISTED_SALE', 'RELISTED', 'PRICE_CHANGE']),\n",
    "        # First listing could be LISTED_SALE, RELISTED, or PRICE_CHANGE if it's the first event\n",
    "        is_first_listing = lambda x: x['is_first_event'] & x['is_listing_event'],\n",
    "        \n",
    "        # Mark valid sale events (SOLD with price > 0)\n",
    "        is_valid_sale = lambda x: (x['event_event_name'] == 'SOLD') & (x['event_price'] > 0)\n",
    "    )\n",
    "    .groupby('parcl_property_id')\n",
    "    .apply(lambda group: {\n",
    "        'original_listing_price': group.loc[group['is_first_listing'], 'event_price'].iloc[0] \n",
    "            if group['is_first_listing'].any() else None,\n",
    "        'final_sale_price': group.loc[group['is_valid_sale'], 'event_price'].iloc[-1] \n",
    "            if group['is_valid_sale'].any() else None\n",
    "    })\n",
    "    .apply(pd.Series)\n",
    "    .dropna()  # Only keep properties with both valid listing and sale prices\n",
    "    .assign(\n",
    "        price_difference_absolute = lambda x: x['final_sale_price'] - x['original_listing_price'],\n",
    "        price_difference_percentage = lambda x: (((x['final_sale_price'] - x['original_listing_price']) / x['original_listing_price']) * 100)\n",
    "    )\n",
    ")\n",
    "listing_vs_sale_analysis.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate comprehensive summary statistics\n",
    "listing_vs_sale_summary = {\n",
    "    'properties_analyzed': len(listing_vs_sale_analysis),\n",
    "    'avg_original_listing_price': listing_vs_sale_analysis['original_listing_price'].mean(),\n",
    "    'median_original_listing_price': listing_vs_sale_analysis['original_listing_price'].median(),\n",
    "    'avg_final_sale_price': listing_vs_sale_analysis['final_sale_price'].mean(),\n",
    "    'median_final_sale_price': listing_vs_sale_analysis['final_sale_price'].median(),\n",
    "    'avg_absolute_difference': listing_vs_sale_analysis['price_difference_absolute'].mean(),\n",
    "    'median_absolute_difference': listing_vs_sale_analysis['price_difference_absolute'].median(),\n",
    "    'avg_percentage_difference': listing_vs_sale_analysis['price_difference_percentage'].mean(),\n",
    "    'median_percentage_difference': listing_vs_sale_analysis['price_difference_percentage'].median(),\n",
    "    'std_absolute_difference': listing_vs_sale_analysis['price_difference_absolute'].std(),\n",
    "    'std_percentage_difference': listing_vs_sale_analysis['price_difference_percentage'].std()\n",
    "}\n",
    "\n",
    "# Show properties that sold above vs below listing\n",
    "price_performance = (listing_vs_sale_analysis\n",
    "    .assign(\n",
    "        performance = lambda x: x['price_difference_absolute'].apply(\n",
    "            lambda y: 'Sold Above Listing' if y > 0 else 'Sold Below Listing' if y < 0 else 'Sold at Listing'\n",
    "        )\n",
    "    )\n",
    "    .groupby('performance')\n",
    "    .agg({\n",
    "        'price_difference_absolute': ['count', 'mean', 'median'],\n",
    "        'price_difference_percentage': ['mean', 'median']\n",
    "    })\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Additional detailed statistics\n",
    "detailed_stats = (listing_vs_sale_analysis\n",
    "    .agg({\n",
    "        'original_listing_price': ['count', 'mean', 'median', 'std', 'min', 'max'],\n",
    "        'final_sale_price': ['count', 'mean', 'median', 'std', 'min', 'max'],\n",
    "        'price_difference_absolute': ['mean', 'median', 'std', 'min', 'max'],\n",
    "        'price_difference_percentage': ['mean', 'median', 'std', 'min', 'max']\n",
    "    })\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(\"=== LISTING VS SALE PRICE ANALYSIS ===\")\n",
    "print(f\"Properties analyzed where final price is available and different to 0: {listing_vs_sale_summary['properties_analyzed']}\")\n",
    "print(f\"Average original listing: ${listing_vs_sale_summary['avg_original_listing_price']:,.2f}\")\n",
    "print(f\"Average final sale: ${listing_vs_sale_summary['avg_final_sale_price']:,.2f}\")\n",
    "print(f\"Average absolute difference: ${listing_vs_sale_summary['avg_absolute_difference']:,.2f}\")\n",
    "print(f\"Average percentage difference: {listing_vs_sale_summary['avg_percentage_difference']:.2f}%\")\n",
    "print(f\"Median absolute difference: ${listing_vs_sale_summary['median_absolute_difference']:,.2f}\")\n",
    "print(f\"Median percentage difference: {listing_vs_sale_summary['median_percentage_difference']:.2f}%\")\n",
    "\n",
    "print(\"\\n=== PERFORMANCE BREAKDOWN ===\")\n",
    "print(price_performance)\n",
    "\n",
    "print(\"\\n=== DETAILED STATISTICS ===\")\n",
    "print(detailed_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2027e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# First, let's combine the days on market with price changes data\n",
    "scatter_plot_data = (all_events_for_properties_of_interest\n",
    "    .pipe(lambda df: \n",
    "        # Get days on market data\n",
    "        df.query('event_event_name in [\"LISTED_SALE\", \"RELISTED\", \"PRICE_CHANGE\", \"SOLD\"]')\n",
    "        .sort_values(['parcl_property_id', 'event_event_date'])\n",
    "        .assign(\n",
    "            has_sold = lambda x: x.groupby('parcl_property_id')['event_event_name'].transform(lambda y: 'SOLD' in y.values),\n",
    "            is_first_event = lambda x: x.groupby('parcl_property_id').cumcount() == 0,\n",
    "            normalized_event_name = lambda x: np.where(\n",
    "                (x['has_sold']) & \n",
    "                (x['is_first_event']) & \n",
    "                (x['event_event_name'].isin(['RELISTED', 'PRICE_CHANGE'])),\n",
    "                'LISTED_SALE',\n",
    "                x['event_event_name']\n",
    "            )\n",
    "        )\n",
    "        .query('normalized_event_name in [\"LISTED_SALE\", \"SOLD\"]')\n",
    "        .groupby(['parcl_property_id', 'normalized_event_name'])['event_event_date'].first()\n",
    "        .unstack('normalized_event_name')\n",
    "        .dropna()\n",
    "        .assign(days_on_market = lambda x: (x['SOLD'] - x['LISTED_SALE']).dt.days)\n",
    "        .query('days_on_market >= 0')\n",
    "        .reset_index()\n",
    "    )\n",
    "    .merge(\n",
    "        # Get price changes count\n",
    "        all_events_for_properties_of_interest\n",
    "        .groupby('parcl_property_id')['event_event_name']\n",
    "        .apply(lambda x: (x == 'PRICE_CHANGE').sum())\n",
    "        .reset_index(name='price_cuts'),\n",
    "        on='parcl_property_id'\n",
    "    )\n",
    "    .query('price_cuts > 0')  # Exclude properties with 0 price cuts\n",
    "    .merge(\n",
    "        # Get property address and combine fields\n",
    "        all_events_for_properties_of_interest[['parcl_property_id', 'property_metadata_address1', 'property_metadata_address2', 'property_metadata_city']]\n",
    "        .drop_duplicates()\n",
    "        .assign(\n",
    "            full_address = lambda x: (\n",
    "                x['property_metadata_address1'].fillna('').astype(str) + ' ' +\n",
    "                x['property_metadata_address2'].fillna('').astype(str) + ', ' +\n",
    "                x['property_metadata_city'].fillna('').astype(str)\n",
    "            ).str.replace(r'\\s+', ' ', regex=True).str.strip().str.rstrip(',')\n",
    "        ),\n",
    "        on='parcl_property_id'\n",
    "    )\n",
    "    .assign(\n",
    "        hover_text = lambda x: x['full_address'] + '<br>' + \n",
    "                              'Days on Market: ' + x['days_on_market'].astype(str) + '<br>' +\n",
    "                              'Price Cuts: ' + x['price_cuts'].astype(str)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the scatter plot\n",
    "fig = px.scatter(\n",
    "    scatter_plot_data,\n",
    "    x='days_on_market',\n",
    "    y='price_cuts',\n",
    "    hover_data={'full_address': True, 'parcl_property_id': True},\n",
    "    title='Days on Market vs. Number of Price Cuts (Properties with Price Cuts Only)',\n",
    "    labels={\n",
    "        'days_on_market': 'Days on Market',\n",
    "        'price_cuts': 'Number of Price Cuts'\n",
    "    },\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Customize the hover template\n",
    "fig.update_traces(\n",
    "    hovertemplate='<b>%{customdata[0]}</b><br>' +\n",
    "                  'Days on Market: %{x}<br>' +\n",
    "                  'Price Cuts: %{y}<br>' +\n",
    "                  'Property ID: %{customdata[1]}<extra></extra>',\n",
    "    customdata=scatter_plot_data[['full_address', 'parcl_property_id']].values\n",
    ")\n",
    "\n",
    "# Update layout for better appearance\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=600,\n",
    "    title_font_size=16,\n",
    "    xaxis_title_font_size=14,\n",
    "    yaxis_title_font_size=14\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "# Print summary statistics for context\n",
    "print(\"=== SCATTER PLOT DATA SUMMARY (Properties with Price Cuts Only) ===\")\n",
    "print(f\"Total properties plotted: {len(scatter_plot_data)}\")\n",
    "print(f\"Average days on market: {scatter_plot_data['days_on_market'].mean():.1f}\")\n",
    "print(f\"Average price cuts: {scatter_plot_data['price_cuts'].mean():.1f}\")\n",
    "print(f\"Max days on market: {scatter_plot_data['days_on_market'].max()}\")\n",
    "print(f\"Max price cuts: {scatter_plot_data['price_cuts'].max()}\")\n",
    "print(f\"Min price cuts: {scatter_plot_data['price_cuts'].min()}\")  # Should be 1 now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parcllabs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
