{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Welcome to the Lab ðŸ¥¼ðŸ§ª</h1>\n",
    "</center>\n",
    "\n",
    "## How to identify markets that could disrupt the US?\n",
    "\n",
    "In this notebook, we will be looking for markets that are outpacing supply growth nationwide to look for the needle in the haystack on markets changing faster than the US. We will look for the following criteria:\n",
    "- Markets with a large, trending skew in supply & demand growth where supply is substantially outpacing demand\n",
    "- Markets with signals for motivated sellers, specifically looking at the ratio of all inventory experiencing price drops\n",
    "- Markets that appreciated significantly since COVID, yet have not given back any of those price gains\n",
    "\n",
    "The notebook is broken up into the following sections:\n",
    "1. [Import required packages and setup the Parcl Labs API key](#1-import-required-packages-and-setup-the-parcl-labs-api-key)\n",
    "2. [Search for markets](#2-search-for-markets)\n",
    "3. [Get the data](#3-retrieve-the-data)\n",
    "4. [Initial data preparation](#4-initial-data-preparation)\n",
    "5. [Supply & demand skew](#5-supply--demand-skew)\n",
    "6. [New construction impact on supply](#6-new-construction-impact-on-supply)\n",
    "7. [Active supply price drops](#7-active-supply-price-drops)\n",
    "8. [Appreciation since COVID](#8-appreciation-since-covid)\n",
    "9. [Real time price check](#9-real-time-price-check)\n",
    "\n",
    "#### What will you create in this notebook?\n",
    "\n",
    "##### Understand changes in supply and Demand YoY\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/changes_supply_yoy_July_2024.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "##### Understanding gaps in supply and demand\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/changes_supply_yoy_July_2024_bar.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "##### Understanding shift in price cuts for on market inventory\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/inventory_price_reductions_July_2024.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "##### Understanding the impact of new construction for on market supply\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/changes_new_listings_new_construction_sept_2024.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "#### Prices since beginning of COVID-19 \n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/change_home_values_since_covid_July_2024.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "#### Need help getting started?\n",
    "\n",
    "As a reminder, you can get your Parcl Labs API key [here](https://dashboard.parcllabs.com/signup) to follow along.\n",
    "\n",
    "To run this immediately, you can use Google Colab. Remember, you must set your `PARCL_LABS_API_KEY`.\n",
    "\n",
    "Run in collab --> [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ParclLabs/parcllabs-cookbook/blob/main/examples/experimental/supply_and_demand/markets_that_could_disrupt.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required packages and setup the Parcl Labs API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, install and/or upgrade to the latest verison of the Parcl Labs Python library\n",
    "%pip install --upgrade parcllabs nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "from parcllabs import ParclLabsClient\n",
    "from parcllabs.beta.charting.styling import SIZE_CONFIG\n",
    "from parcllabs.beta.ts_stats import TimeSeriesAnalysis\n",
    "from parcllabs.beta.charting.utils import create_labs_logo_dict\n",
    "from parcllabs.beta.charting.utils import (\n",
    "    create_labs_logo_dict,\n",
    "    save_figure,\n",
    "    )\n",
    "from parcllabs.beta.charting.styling import default_style_config as style_config\n",
    "\n",
    "\n",
    "client = ParclLabsClient(\n",
    "    api_key=os.environ.get('PARCL_LABS_API_KEY', \"<your Parcl Labs API key if not set as environment variable>\"), \n",
    "    limit=1000, \n",
    "    turbo_mode=True # set turbo mode to True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Search for markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top 100 metro markets, sorted by total population in descending order\n",
    "metros = client.search.markets.retrieve(\n",
    "    sort_by='TOTAL_POPULATION',  # Sort by total population\n",
    "    sort_order='DESC',           # In descending order\n",
    "    location_type='CBSA',        # Location type set to Core Based Statistical Area (CBSA)\n",
    "    limit=100                    # Limit results to top 200 metros\n",
    ")\n",
    "\n",
    "# Retrieve national data for the United States to use as a benchmark\n",
    "us = client.search.markets.retrieve(\n",
    "    query='United States',  # Query for the United States as a whole\n",
    "    limit=1                 # Limit results to one (national-level data)\n",
    ")\n",
    "\n",
    "# Concatenate metro market data with national data for comparison\n",
    "markets = pd.concat([metros, us])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets move the PARCL_ID of our metros to a list so we can retrieve the data\n",
    "market_parcl_ids = markets['parcl_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrieve the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve different datasets from the SDK endpoints.\n",
    "# Capturing weekly supply, demand, and price metrics for 200 metros across the country.\n",
    "\n",
    "# Lists to hold the data retrieved from each endpoint\n",
    "supply_list = []\n",
    "demand_list = []\n",
    "prices_list = []\n",
    "\n",
    "# Define the start date for supply and demand data\n",
    "start_date = '2022-09-01'\n",
    "\n",
    "# Iterate over each metro market ID, retrieving data for supply, demand, and prices\n",
    "for market in market_parcl_ids:\n",
    "    # Retrieve the supply (for-sale inventory) data for the market starting from the specified date\n",
    "    supply = client.for_sale_market_metrics.for_sale_inventory.retrieve(\n",
    "        parcl_ids=market,\n",
    "        start_date=start_date,\n",
    "    )\n",
    "    \n",
    "    # Retrieve the demand data (housing event counts) for the market starting from the specified date\n",
    "    demand = client.market_metrics.housing_event_counts.retrieve(\n",
    "        parcl_ids=market,\n",
    "        start_date=start_date,\n",
    "    )\n",
    "    \n",
    "    # Retrieve the price data (housing event prices) for the market starting from January 2019\n",
    "    prices = client.market_metrics.housing_event_prices.retrieve(\n",
    "        parcl_ids=market,\n",
    "        start_date='2019-01-01',  # Different start date to capture historical price trends\n",
    "    )\n",
    "    \n",
    "    # Append the retrieved data to their respective lists\n",
    "    supply_list.append(supply)\n",
    "    demand_list.append(demand)\n",
    "    prices_list.append(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the retrieved data lists into DataFrames\n",
    "# Concatenate the supply, demand, and prices data into their respective DataFrames\n",
    "supply_df = pd.concat(supply_list)\n",
    "demand_df = pd.concat(demand_list)\n",
    "prices_df = pd.concat(prices_list)\n",
    "\n",
    "# Output the length of each DataFrame to understand the volume of data retrieved\n",
    "print(f'Length of supply data: {len(supply_df)}, prices data: {len(prices_df)}, and demand data: {len(demand_df)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in each DataFrame to check for coverage across different markets\n",
    "print(f'There are {len(supply_df.parcl_id.unique())} unique parcl_ids in the supply data, '\n",
    "      f'{len(prices_df.parcl_id.unique())} unique parcl_ids in the prices data, and '\n",
    "      f'{len(demand_df.parcl_id.unique())} unique parcl_ids in the demand data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prices_df['date'].max())\n",
    "print(demand_df['date'].max())\n",
    "print(supply_df['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`supply_df` contains all the inventory available for sale for all our markets. `prices_df` contains information about the median price for sales, listingts and the standard deviation of the prices. `demand_df` contains information about the number of events that happened in the market.\n",
    "`demand_df` contains information about the number of events that happened in the market including new listings, new sales and new units offered for rent. This information constitutes the first step in our analysis, understanding supply and demand dynamics alongside price information.\n",
    "\n",
    "We also need information on price cuts and for that we will use the SDF specifically the `for_sale_market_metrics.for_sale_inventory_price_changes` method of our client. This endpoint will retrieve price cuts across all types of properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data for price changes in inventory across markets\n",
    "price_changes_list = []  # List to store price change data for each market\n",
    "\n",
    "# Iterate over each metro market ID to retrieve price change data\n",
    "for market in market_parcl_ids:\n",
    "    # Retrieve price changes in inventory for the market starting from the specified date\n",
    "    price_changes = client.for_sale_market_metrics.for_sale_inventory_price_changes.retrieve(\n",
    "        parcl_ids=market,        # Specify the market by its parcl_id\n",
    "        start_date=start_date     # Use the same start date defined earlier for consistency\n",
    "    )\n",
    "    \n",
    "    # Append the retrieved price change data to the list\n",
    "    price_changes_list.append(price_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the list of price change data into a single DataFrame\n",
    "price_changes_df = pd.concat(price_changes_list)\n",
    "\n",
    "# Output the length of the price changes DataFrame to verify the amount of data retrieved\n",
    "print(f'Length of price changes data: {len(price_changes_df)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in the price changes DataFrame to ensure market coverage\n",
    "print(f'There are {len(price_changes_df.parcl_id.unique())} unique parcl_ids in the price changes data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data we can start our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initial data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly supply and percentage of price drops\n",
    "# Note: Supply data is bi-weekly, and price changes are weekly, so we resample both to a monthly frequency\n",
    "\n",
    "supply_monthly = (\n",
    "    supply_df.copy(deep=True)  # Create a deep copy of the supply DataFrame to avoid modifying the original data\n",
    "    \n",
    "    # Merge with price_changes_df on 'parcl_id' and 'date' to include price drop data for each market\n",
    "    .merge(price_changes_df[['parcl_id', 'date', 'count_price_drop']], on=['parcl_id', 'date'])\n",
    "    \n",
    "    # Add new columns for percentage of price drops and resample dates to monthly\n",
    "    .assign(\n",
    "        pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory'],  # Calculate percentage of price drops out of total suply\n",
    "        date=lambda df: df['date'].dt.to_period('M').dt.to_timestamp()  # Convert the 'date' to monthly frequency\n",
    "    )\n",
    "    \n",
    "    # Group the data by 'parcl_id' and 'date' (now monthly) and calculate the median\n",
    "    .groupby(['parcl_id', 'date'])\n",
    "    .agg({\n",
    "        'for_sale_inventory': 'median',     # Calculate the median inventory for each market and month\n",
    "        'pct_price_drops': 'median'         # Calculate the median percentage of price drops\n",
    "    })\n",
    "    \n",
    "    # Reset the index to return a flat DataFrame\n",
    "    .reset_index()\n",
    "\n",
    "    # check what the mean of price drops is and the standard deviation, renamen them pct_price_drops_mean and pct_price_drops_std\n",
    "    # group by date and use the transform function to add these columns to the dataframe\n",
    "    .assign(\n",
    "        pct_price_drops_mean=lambda df: df.groupby('date')['pct_price_drops'].transform('mean'),\n",
    "        pct_price_drops_std=lambda df: df.groupby('date')['pct_price_drops'].transform('std')\n",
    "    )\n",
    "    # add a flag to signal which markets are above the mean, it should be 1 if true and 0 if false\n",
    "    .assign(\n",
    "        above_mean_price_drops_flag=lambda df: (df['pct_price_drops'] > df['pct_price_drops_mean']).astype(int)\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "# Output the length of the final monthly supply DataFrame to verify the amount of data\n",
    "print(f'Length of monthly supply data: {len(supply_monthly)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in the monthly supply data to verify market coverage\n",
    "print(f'There are {len(supply_monthly.parcl_id.unique())} unique parcl_ids in the monthly supply data')\n",
    "\n",
    "# Display the first 10 rows of the monthly supply DataFrame for inspection\n",
    "supply_monthly.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the monthly supply data (with price drops) with the demand data\n",
    "# Note: Demand data is already in a monthly series, so we can directly join the datasets on 'parcl_id' and 'date'\n",
    "\n",
    "supply_demand_data = (\n",
    "    demand_df[['date', 'parcl_id', 'sales']]  # Select relevant columns from the demand DataFrame (date, parcl_id, and sales)\n",
    "    .merge(supply_monthly,                    # Merge with the supply_monthly DataFrame that includes supply and price drop data\n",
    "           on=['date', 'parcl_id'])           # Join on 'date' and 'parcl_id' to align data across markets and time periods\n",
    ")\n",
    "\n",
    "# Output the length of the combined supply and demand DataFrame to verify data consistency\n",
    "print(f'Length of supply_demand_data: {len(supply_demand_data)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values to check how many markets are covered in the merged dataset\n",
    "print(f'There are {len(supply_demand_data.parcl_id.unique())} unique parcl_ids in the supply_demand_data')\n",
    "\n",
    "# Display the combined supply and demand data for inspection\n",
    "supply_demand_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new dataframe provides us with a snapshot of market status including the price cuts, share of inventory for sale with price cuts as well as sales activity. Next step involves calculating imbalances between supply and demand. The key idea is that with the data we have so far we can identify players with dwindling demand and price drop pressure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Supply & demand skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'parcl_id' and 'date' to ensure chronological order for percentage change calculations\n",
    "supply_demand_df_imbalances = (\n",
    "    supply_demand_data.copy(deep=True)  # Create a deep copy of the supply_demand_data DataFrame to avoid modifying the original data\n",
    "    .sort_values(['parcl_id', 'date'])  # Sort by 'parcl_id' and 'date'\n",
    "    \n",
    "    .assign(\n",
    "        # Calculate percentage change in 'sales' over 12 periods (1 year) for each 'parcl_id'\n",
    "        pct_change_demand=lambda df: df.groupby('parcl_id')['sales'].pct_change(periods=12),\n",
    "       \n",
    "        # Calculate percentage change in 'for_sale_inventory' over 12 periods for each 'parcl_id'\n",
    "        pct_change_supply=lambda df: df.groupby('parcl_id')['for_sale_inventory'].pct_change(periods=12),\n",
    "        \n",
    "        # Calculate a 3-month moving average of percentage change in demand ('pct_change_demand')\n",
    "        ma_pct_change_demand=lambda df: df.groupby('parcl_id')['pct_change_demand']\n",
    "                                           .transform(lambda x: x.rolling(window=3).mean()),\n",
    "        \n",
    "        # Calculate a 3-month moving average of percentage change in supply ('pct_change_supply')\n",
    "        ma_pct_change_supply=lambda df: df.groupby('parcl_id')['pct_change_supply']\n",
    "                                           .transform(lambda x: x.rolling(window=3).mean())\n",
    "                        \n",
    "        # Drop rows with missing values in the calculated columns\n",
    "        )\n",
    "    .dropna(subset=['pct_change_demand', 'pct_change_supply', 'ma_pct_change_demand', 'ma_pct_change_supply'])\n",
    "    .assign(\n",
    "        gap_demand_supply=lambda df: df['ma_pct_change_supply'] - df['ma_pct_change_demand']   \n",
    "        )\n",
    "    .sort_values('gap_demand_supply', ascending=False)\n",
    "    )\n",
    "print(f'length of supply_demand_df_imbalances df is {len(supply_demand_df_imbalances)}')\n",
    "print(f'there are {len(supply_demand_df_imbalances.parcl_id.unique())} unique parcl_ids in the supply_demand_df_imbalances data')\n",
    "supply_demand_df_imbalances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check one metro\n",
    "supply_demand_df_imbalances.query('date == \"2024-08-01\"').head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the 'markets' DataFrame by extracting the state and cleaning the market names\n",
    "markets = (\n",
    "    markets.assign(\n",
    "        # Extract the state from the 'name' column by splitting on commas and hyphens, then standardizing it\n",
    "        state=lambda df: df['name'].apply(lambda x: x.split(',')[-1].strip().upper().split('-')[0]),\n",
    "\n",
    "        # Create a 'clean_name' by extracting the first part of 'name' and appending the state\n",
    "        clean_name=lambda df: df.apply(\n",
    "            lambda x: f\"{x['name'].split('-')[0].split(',')[0].strip()}, {x['state']}\", axis=1\n",
    "        )\n",
    "    )\n",
    "    # Replace 'United States Of America, UNITED STATES OF AMERICA' with 'USA'\n",
    "    .replace({'clean_name': {'United States Of America, UNITED STATES OF AMERICA': 'USA'}})\n",
    ")\n",
    "\n",
    "# Display the cleaned 'markets' DataFrame with the extracted state and cleaned market names\n",
    "markets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the supply_demand_imbalance DataFrame to get data for the most recent date,\n",
    "# merge with the 'markets' DataFrame, and filter based on specific conditions.\n",
    "\n",
    "# get latest month of imbalanced data\n",
    "supply_demand_imbalance_last = (\n",
    "    supply_demand_df_imbalances.copy(deep=True)  # Create a deep copy of the supply_demand_df_imbalances DataFrame\n",
    "    .loc[lambda df: df['date'] == df['date'].max()]  # Filter for the most recent date\n",
    "    .merge(markets[['parcl_id', 'clean_name', 'state']], on='parcl_id')  # Merge with 'markets' to add 'clean_name' and 'state'\n",
    "    )\n",
    "# get usa data\n",
    "supply_demand_imbalance_last_us = supply_demand_imbalance_last \\\n",
    "    .query('date == date.max()') \\\n",
    "    .query(f'parcl_id == {us[\"parcl_id\"].values[0]}'\n",
    "           )\n",
    "supply_demand_imbalance_last_us['rank']=None\n",
    "supply_demand_imbalance_last_us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ranking for the gap_demand_supply\n",
    "input_final_df_supply_demand_imbalance_last = (supply_demand_imbalance_last.copy(deep=True)\n",
    "    .query(\"parcl_id!=5826765\")\n",
    "    .assign(rank = lambda x: x['gap_demand_supply'].rank(ascending=False))\n",
    "    )\n",
    "input_final_df_supply_demand_imbalance_last_df = supply_demand_imbalance_last_us.copy(deep=True)[[\n",
    "    'date', \n",
    "    'parcl_id', \n",
    "    'pct_change_demand', \n",
    "    'pct_change_supply',\n",
    "    'ma_pct_change_demand','ma_pct_change_supply',\n",
    "    'gap_demand_supply','clean_name', 'state','rank']]\n",
    "print(len(input_final_df_supply_demand_imbalance_last))\n",
    "# add the usa data\n",
    "data_for_table = pd.concat([input_final_df_supply_demand_imbalance_last[\n",
    "    [\n",
    "    'date', \n",
    "    'parcl_id', \n",
    "    'pct_change_demand', \n",
    "    'pct_change_supply',\n",
    "    'ma_pct_change_demand','ma_pct_change_supply',\n",
    "    'gap_demand_supply','clean_name', 'state','rank'\n",
    "]],\n",
    "    input_final_df_supply_demand_imbalance_last_df[[\n",
    "    'date', \n",
    "    'parcl_id', \n",
    "    'pct_change_demand', \n",
    "    'pct_change_supply',\n",
    "    'ma_pct_change_demand','ma_pct_change_supply',\n",
    "    'gap_demand_supply','clean_name', 'state','rank']]])\n",
    "print(len(data_for_table))\n",
    "data_for_table.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Further filter based on sales, inventory, and percentage change conditions\n",
    "# We want to filter out the markets with low sales, low inventory, and low gap between demand and supply\n",
    "# we use a threshold of 500 for sales and inventory and 0.45 for gap_demand_supply, meaning a relative shift of 45 percent\n",
    "# in favor of supply\n",
    "supply_demand_imbalance_last_filtered = (\n",
    "    supply_demand_imbalance_last.copy(deep=True)\n",
    "    .loc[\n",
    "        (supply_demand_imbalance_last['sales'] > 500) & \n",
    "        (supply_demand_imbalance_last['for_sale_inventory'] > 500) \n",
    "        & (supply_demand_imbalance_last['gap_demand_supply'] > 0.5)\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Concatenate US-specific data with the filtered data\n",
    "supply_demand_imbalance_last = pd.concat([supply_demand_imbalance_last_us, supply_demand_imbalance_last_filtered])\n",
    "\n",
    "print(f'length of supply_demand_imbalance_last is {len(supply_demand_imbalance_last)}')\n",
    "print(f'there are {len(supply_demand_imbalance_last.parcl_id.unique())} unique parcl_ids in the supply_demand_imbalance_last data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_parcl_ids = supply_demand_imbalance_last['parcl_id'].unique().tolist()\n",
    "print(f'before filtering for price cuts larger than the national average we have {len(imbalanced_parcl_ids)} imbalanced markets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will filter based on demand\n",
    "# Calculate the 3-period rolling average of price drops, filter using query, and extract parcl_ids\n",
    "imbalanced_with_price_changes_data_all = (\n",
    "    supply_monthly.copy(deep=True)\n",
    "    .sort_values(by=['parcl_id', 'date'], ascending=[True, True])\n",
    "    # Calculate the 3-month rolling average of price changes for each parcl_id\n",
    "    .assign(\n",
    "        ma_price_changes=lambda df: df.groupby('parcl_id')['pct_price_drops'].transform(lambda x: x.rolling(window=3).mean())\n",
    "    )\n",
    "    \n",
    "    # Sort by the rolling average of price changes in descending order\n",
    "    .sort_values('ma_price_changes', ascending=False)\n",
    "    .query('date == \"8/1/2024\"')\n",
    ")\n",
    "input_for_table_imbalanced_with_price_changes_data = imbalanced_with_price_changes_data_all.copy(deep=True)\n",
    "print(f'length of imbalanced_with_price_changes_data_all is {len(imbalanced_with_price_changes_data_all)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_for_table_imbalanced_with_price_changes_data.query('parcl_id == 5826765').sort_values('date', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_with_price_changes_data = (\n",
    "    imbalanced_with_price_changes_data_all.copy(deep=True)\n",
    "    # Further filter to include only imbalanced parcl_ids using query\n",
    "    .query('parcl_id in @imbalanced_parcl_ids')\n",
    ")\n",
    "print(f'length of imbalanced_with_price_changes_data is {len(imbalanced_with_price_changes_data)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_table_final = data_for_table.merge(input_for_table_imbalanced_with_price_changes_data[['date','parcl_id','ma_price_changes']],\n",
    "                     on=['parcl_id','date'], how='left')\n",
    "print(f'length of data_for_table is {len(data_for_table)}')\n",
    "data_for_table_final.tail(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_table_final = data_for_table.to_csv('data_for_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get the value for the usa\n",
    "us_price_changes = (imbalanced_with_price_changes_data\n",
    "                    .query('(parcl_id == @us[\"parcl_id\"].values[0])')\n",
    "                    .query('date == \"8/1/2024\"'\n",
    "                    ))['ma_price_changes'].values[0]\n",
    "print(us_price_changes)\n",
    "\n",
    "# Filter the imbalanced markets based on price changes\n",
    "print(f'before filtering for price cuts larger than the national average we have {len(imbalanced_with_price_changes_data.parcl_id.unique())} imbalanced markets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalanced_with_price_changes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with markets\n",
    "imbalanced_with_price_changes_data = (\n",
    "    imbalanced_with_price_changes_data\n",
    "    .merge(markets[['parcl_id', 'clean_name', 'state']], on='parcl_id')\n",
    "    .sort_values('ma_price_changes', ascending=False)\n",
    "    # filter on max date\n",
    "    .loc[lambda df: df['date'] == df['date'].max()]\n",
    "    )\n",
    "# sort by ma_price_changes\n",
    "print(len(imbalanced_with_price_changes_data))\n",
    "imbalanced_with_price_changes_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the total after filter\n",
    "imbalanced_with_price_changes_data = imbalanced_with_price_changes_data.query('ma_price_changes > @us_price_changes')\n",
    "imbalanced_parcl_ids_final = imbalanced_with_price_changes_data['parcl_id'].unique().tolist()\n",
    "print(len(imbalanced_parcl_ids_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter supply demand based on the new list\n",
    "supply_demand_imbalance_last = supply_demand_imbalance_last.query('parcl_id in @imbalanced_parcl_ids_final')\n",
    "supply_demand_imbalance_last\n",
    "#print(len(supply_demand_imbalance_last))\n",
    "#print(len(supply_demand_imbalance_last.parcl_id.unique()))\n",
    "line_chart_data = supply_demand_imbalance_last[['clean_name','gap_demand_supply',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_chart = supply_demand_imbalance_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to identify selected states\n",
    "target_states = {'TX', 'FL'}\n",
    "supply_demand_imbalance_last['color_group'] = supply_demand_imbalance_last['state'].apply(\n",
    "    lambda x: 'FL, TX' if x in target_states else 'Other')\n",
    "\n",
    "# Get the maximum date for the chart title\n",
    "chart_max_date = supply_demand_imbalance_last['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B, %Y')\n",
    "\n",
    "\n",
    "CHART_WIDTH = 1000\n",
    "CHART_HEIGHT = 800\n",
    "# Creating the scatter plot\n",
    "fig = px.scatter(\n",
    "    supply_demand_imbalance_last, \n",
    "    x='ma_pct_change_demand', \n",
    "    y='ma_pct_change_supply', \n",
    "    color='color_group',  # Use the new color_group column for color\n",
    "    hover_name='clean_name', \n",
    "    title=f'YoY Changes in Supply vs. Demand ({chart_max_date})',\n",
    "    color_discrete_map={'FL, TX':'red' , 'Other': 'blue'},  # Customize colors,\n",
    "    text='clean_name'\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textposition='top center',\n",
    "    mode='markers+text'  # Ensure that both markers and text are displayed\n",
    ")\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    "    )\n",
    "\n",
    "# Update axes labels and layout to format as a square\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "     xaxis=dict(\n",
    "            title_text='YoY % Change Demand (Sales)',\n",
    "            showgrid=style_config['showgrid'],\n",
    "            gridwidth=style_config['gridwidth'],\n",
    "            gridcolor=style_config['grid_color'],\n",
    "            # tickangle=style_config['tick_angle'],\n",
    "            tickformat='.0%',\n",
    "            linecolor=style_config['line_color_axis'],\n",
    "            linewidth=style_config['linewidth'],\n",
    "            titlefont=style_config['title_font_axis'],\n",
    "            zeroline=False,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text='YoY % Change Supply',\n",
    "            showgrid=style_config['showgrid'],\n",
    "            gridwidth=style_config['gridwidth'],\n",
    "            gridcolor=style_config['grid_color'],\n",
    "            tickfont=style_config['axis_font'],\n",
    "            zeroline=False,\n",
    "            tickformat='.0%',\n",
    "            linecolor=style_config['line_color_axis'],\n",
    "            linewidth=style_config['linewidth'],\n",
    "            titlefont=style_config['title_font_axis']\n",
    "        ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    legend_title_text='',\n",
    "    autosize=False,\n",
    "    height=CHART_HEIGHT,\n",
    "    width=CHART_WIDTH,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    "    legend=dict(\n",
    "            x=style_config['legend_x'],\n",
    "            y=style_config['legend_y'],\n",
    "            xanchor=style_config['legend_xanchor'],\n",
    "            yanchor=style_config['legend_yanchor'],\n",
    "            font=style_config['legend_font'],\n",
    "            bgcolor='rgba(0, 0, 0, 0)'\n",
    "        ),\n",
    ")\n",
    "save_figure(fig, save_path='../../../images/changes_supply_yoy_August_2024.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "supply_demand_imbalance_last.to_csv('../../../changes_supply_yoy_August_2024.csv', index=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Merge the gap data with the supply and demand data to ensure consistent x-values\n",
    "merged_data = supply_demand_imbalance_last[['clean_name', 'ma_pct_change_demand', 'ma_pct_change_supply', 'gap_demand_supply']]\n",
    "\n",
    "# Melt the data for the bar chart\n",
    "data_for_bar = pd.melt(merged_data, \n",
    "                       id_vars=['clean_name'], \n",
    "                       value_vars=['ma_pct_change_demand', 'ma_pct_change_supply'], \n",
    "                       var_name='type', \n",
    "                       value_name='percent_change')\n",
    "\n",
    "data_for_bar['type'] = data_for_bar['type'].map({'ma_pct_change_demand': 'Demand', \n",
    "                                                 'ma_pct_change_supply': 'Supply',\n",
    "                                                 })\n",
    "# sort data bar by the gap\n",
    "# drop Gap from the data\n",
    "#data_for_bar = data_for_bar.query('type != \"Gap\"')\n",
    "line_chart = line_chart.sort_values('gap_demand_supply', ascending=True)\n",
    "\n",
    "\n",
    "# Create a subplot figure with 2 rows, 1 column\n",
    "fig = make_subplots(rows=2, cols=1, shared_xaxes=True, \n",
    "                    row_heights=[0.3, 0.7], vertical_spacing=0.1, \n",
    "                    subplot_titles=[f'Gap between Supply and Demand ({chart_max_date})', \n",
    "                                    f'YoY Change in Supply and Demand ({chart_max_date})'])\n",
    "\n",
    "# 1. Add the gap_demand_supply as a bar chart in the first row\n",
    "fig.add_trace(go.Bar(\n",
    "    x=line_chart['clean_name'], \n",
    "    y=line_chart['gap_demand_supply'],\n",
    "    marker_color='blue',\n",
    "    name='Total Gap (Supply increase minus demand increase)',\n",
    "), row=1, col=1)\n",
    "\n",
    "# 2. Add the combined Demand and Supply bars to the second row\n",
    "# Instead of using Plotly Express, manually create bars for Demand and Supply and stack them\n",
    "fig.add_trace(go.Bar(\n",
    "    x=data_for_bar[data_for_bar['type'] == 'Demand']['clean_name'], \n",
    "    y=data_for_bar[data_for_bar['type'] == 'Demand']['percent_change'], \n",
    "    marker_color='red', \n",
    "    name='Demand (Sales)'\n",
    "), row=2, col=1)\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=data_for_bar[data_for_bar['type'] == 'Supply']['clean_name'], \n",
    "    y=data_for_bar[data_for_bar['type'] == 'Supply']['percent_change'], \n",
    "    marker_color='green', \n",
    "    name='Supply (Inventory)'\n",
    "), row=2, col=1)\n",
    "\n",
    "# Define dimensions\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "\n",
    "# Update layout with barmode='relative' to stack bars in the second row\n",
    "fig.update_layout(\n",
    "    barmode='relative',  # This stacks Demand and Supply bars on top of each other\n",
    "    title_text=f'Total Gap and YoY Changes in Supply and Demand ({chart_max_date})',\n",
    "    height=CHART_HEIGHT + 400,  # Adjusting height for both charts\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    xaxis=dict(\n",
    "        title_text='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='Gap (Demand - Supply)',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title_text='Percent Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=style_config['legend_x'],\n",
    "        y=style_config['legend_y'],\n",
    "        xanchor=style_config['legend_xanchor'],\n",
    "        yanchor=style_config['legend_yanchor'],\n",
    "        font=style_config['legend_font'],\n",
    "        bgcolor='rgba(0, 0, 0, 0)'\n",
    "    ),\n",
    "    autosize=False,\n",
    "    width=CHART_WIDTH,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    ")\n",
    "\n",
    "# Add company logo as in the original code\n",
    "fig.add_layout_image(create_labs_logo_dict())\n",
    "\n",
    "# Save the figure\n",
    "save_figure(fig, save_path='../../../images/changes_supply_gap_yoy_August_2024_bar.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT + 400)\n",
    "\n",
    "data_for_bar.to_csv('../../../images/changes_supply_gap_yoy_August_2024_bar.csv', index=False)\n",
    "line_chart.to_csv('../../../images/changes_supply_gap_yoy_August_2024_line.csv', index=False)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this initial subset we identify a subset of 37 markets plus the USA that meet the criteria for further analysis as of July 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need  to iterated to get the housing event counts \n",
    "new_listings_list = []\n",
    "nc_list = []\n",
    "\n",
    "for market in imbalanced_parcl_ids_final:\n",
    "    new_listings = client.market_metrics.housing_event_counts.retrieve(\n",
    "        parcl_ids=market,\n",
    "        limit =1 # limit to 1 to get the most recent data\n",
    "    )\n",
    "    new_listings_list.append(new_listings)\n",
    "    \n",
    "    nc = client.new_construction_metrics.housing_event_counts.retrieve(\n",
    "        parcl_ids=market,\n",
    "        limit =1 # limit to 1 to get the most recent data\n",
    "    )\n",
    "    nc_list.append(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the list of data into a single dataframe for new listings and new construction\n",
    "new_listings = pd.concat(new_listings_list)\n",
    "new_listings_construction = pd.concat(nc_list)\n",
    "\n",
    "# Rename the columns to distinguish between new listings and new construction data\n",
    "new_listings_construction = (\n",
    "    new_listings_construction\n",
    "    .rename(columns={'new_listings_for_sale': 'new_construction_new_listings_for_sale'})\n",
    "    )\n",
    "\n",
    "# Output the length of the new listings data to confirm the amount of data retrieved\n",
    "print(f'Length of new_listings data: {len(new_listings)} and nc data: {len(nc)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values to verify coverage across different markets\n",
    "print(f'There are {len(new_listings.parcl_id.unique())} unique parcl_ids in the new_listings data and'\n",
    "      f' {len(new_listings_construction.parcl_id.unique())} unique parcl_ids in the new construction data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge new listings data with new construction listings, calculate percentage, and merge with market names\n",
    "new_listings_all = (\n",
    "    new_listings\n",
    "    # Merge new listings with new construction data on 'parcl_id'\n",
    "    .merge(new_listings_construction[['parcl_id', 'new_construction_new_listings_for_sale']], \n",
    "           on='parcl_id')\n",
    "    \n",
    "    # Calculate the percentage of new construction listings out of total new listings\n",
    "    .assign(\n",
    "        pct_new_construction=lambda x: x['new_construction_new_listings_for_sale'] / x['new_listings_for_sale']\n",
    "    )\n",
    "    \n",
    "    # Merge with the 'markets' DataFrame to add clean market names based on 'parcl_id'\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    "    \n",
    ")\n",
    "new_listings_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the bar chart with sorting, melting, and formatting in one step\n",
    "data_for_bar = (\n",
    "    new_listings_all  # Filter for the most recent date\n",
    "    .sort_values('pct_new_construction', ascending=True)  # Sort by percentage of new construction\n",
    "    .assign(\n",
    "        chart_max_date=lambda df: df['date'].max().strftime('%B, %Y')  # Format the latest date\n",
    "    )\n",
    "    .pipe(\n",
    "        lambda df: pd.melt(df, id_vars=['clean_name'], \n",
    "                           value_vars=['pct_new_construction'], \n",
    "                           var_name='type', \n",
    "                           value_name='percentage')  # Reshape for bar chart\n",
    "    )\n",
    "    #.assign(\n",
    "    #    clean_name=lambda df: df['clean_name'].apply(\n",
    "    #        lambda x: f\"<b style='color:red'>{x}</b>\" \n",
    "    #        if x.endswith('FL') or x.endswith('NY') or x.endswith('OH') else x  # Format FL markets\n",
    "    #    )\n",
    "    #)\n",
    ")\n",
    "\n",
    "# Display the prepared data for the bar chart\n",
    "data_for_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the stacked bar chart\n",
    "fig = px.bar(data_for_bar, \n",
    "             x='clean_name', \n",
    "             y='percentage', \n",
    "             color='type', \n",
    "             barmode='stack', \n",
    "             title=f'Percent of New Listings Coming from New Construction ({chart_max_date})',\n",
    "             labels={'percentage': 'Percentage', 'clean_name': 'Market'},\n",
    "             color_discrete_map={'type': 'orange', 'type': 'orange'})\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "# Update the legend names\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'New Construction':\n",
    "        trace.name = 'New Construction'\n",
    "    elif trace.name == 'Investors':\n",
    "        trace.name = 'Investors'\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title_text='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis'],\n",
    "        tickfont=dict(size=style_config['axis_font']['size'], color=style_config['axis_font']['color']),\n",
    "        # showticklabels=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='% of New Inventory',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    legend_title_text='',\n",
    "    autosize=False,\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    "    legend=dict(\n",
    "        x=style_config['legend_x'],\n",
    "        y=style_config['legend_y'],\n",
    "        xanchor=style_config['legend_xanchor'],\n",
    "        yanchor=style_config['legend_yanchor'],\n",
    "        font=style_config['legend_font'],\n",
    "        bgcolor='rgba(0, 0, 0, 0)'\n",
    "    ),\n",
    ")\n",
    "fig.add_layout_image(create_labs_logo_dict())\n",
    "save_figure(fig, save_path='../../../images/changes_new_listings_new_construction_August_2024.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "data_for_bar.to_csv('../../../images/changes_new_listings_new_construction_August_2024.csv', index=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two lists before using in the query\n",
    "combined_parcl_ids = imbalanced_parcl_ids_final + [5826765]\n",
    "\n",
    "# Clean and process price changes data, calculating percentage of price drops and merging relevant columns\n",
    "print(len(price_changes_df))\n",
    "price_changes_skewed = (\n",
    "    price_changes_df\n",
    "    # Filter for relevant parcl_ids using the pre-combined list\n",
    "    .query('parcl_id in @combined_parcl_ids')\n",
    "    )\n",
    "print(len(price_changes_skewed))\n",
    "\n",
    "price_changes_skewed = (\n",
    "    price_changes_skewed\n",
    "    # Merge with the supply data on 'parcl_id' and 'date' to bring in for_sale_inventory\n",
    "    .merge(supply_df[['parcl_id', 'date', 'for_sale_inventory']], on=['parcl_id', 'date'])\n",
    "    \n",
    "    # Calculate the percentage of price drops relative to the for_sale_inventory\n",
    "    .assign(\n",
    "        pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory']\n",
    "    )\n",
    "    \n",
    "    # Merge with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")\n",
    "\n",
    "# Display the unique parcl_ids in the processed price changes data\n",
    "len(price_changes_skewed['parcl_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify\n",
    "max_date_for_chart = price_changes_skewed['date'].max().date()\n",
    "print(max_date_for_chart)\n",
    "max_date_for_chart = max_date_for_chart.strftime('%B %d, %Y')\n",
    "\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "# Create the line chart using Plotly Express\n",
    "fig = px.line(\n",
    "    price_changes_skewed,\n",
    "    x='date',\n",
    "    y='pct_price_drops',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_price_drops': '% of Inventory with Price Cuts'},\n",
    "    title=f'Percentage of Inventory with Price Reductions ({max_date_for_chart})'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(price_changes_skewed['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = price_changes_skewed[\n",
    "        (price_changes_skewed['clean_name'] == trace.name) &\n",
    "        (price_changes_skewed['date'] == latest_date)\n",
    "    ]['pct_price_drops'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Price Reductions',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path='../../../images/inventory_price_reductions_September09_2024.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "data_for_bar.to_csv('../../../images/inventory_price_reductions_September09_2024.csv', index=False)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to most out of balance markets regarding supply and demand\n",
    "prices_need_to_give_back = prices_df.loc[prices_df['parcl_id'].isin(imbalanced_parcl_ids_final + [5826765])]\n",
    "print(f'There are {len(prices_need_to_give_back)} observations in the price history df.')\n",
    "print(f'There are {len(prices_need_to_give_back[\"parcl_id\"].unique())} with substantial price reductions and distressed demand.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will iterate over the parcl_ids to get the time series analysis and identify what\n",
    "# parcls need to give back the most from the beginning of the pandemic compared to the USA\n",
    "all_rows = []\n",
    "for pid in prices_need_to_give_back['parcl_id'].unique().tolist():\n",
    "    prices_skew_test = prices_need_to_give_back.loc[prices_need_to_give_back['parcl_id']==pid]\n",
    "    price_ts_analysis = TimeSeriesAnalysis(prices_skew_test, 'date', 'price_per_square_foot_median_sales', freq='M')\n",
    "    price_rate_of_change_stats = price_ts_analysis.calculate_changes(change_since_date='3/1/2020')\n",
    "    row = pd.json_normalize(price_rate_of_change_stats)\n",
    "    row['parcl_id'] = pid\n",
    "    all_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform time series analysis for each unique parcl_id in a chained and list comprehension style\n",
    "all_rows = (\n",
    "    prices_need_to_give_back['parcl_id'].unique()  # Get the unique parcl_ids\n",
    "    .tolist()  # Convert to a list for iteration\n",
    ")\n",
    "\n",
    "ts_analysis = pd.concat([\n",
    "    pd.json_normalize(\n",
    "        TimeSeriesAnalysis(\n",
    "            prices_need_to_give_back.query('parcl_id == @pid'),  # Filter for each parcl_id\n",
    "            'date', 'price_per_square_foot_median_sales', freq='M'  # Perform time series analysis\n",
    "        ).calculate_changes(change_since_date='3/1/2020')  # Calculate changes since 3/1/2020\n",
    "    ).assign(parcl_id=pid)  # Add the parcl_id to the result\n",
    "    for pid in all_rows  # Iterate over each unique parcl_id\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the length of ts_analysis and filter based on conditions, then print the length of the filtered DataFrame\n",
    "\n",
    "hf = (\n",
    "    ts_analysis\n",
    "    \n",
    ")\n",
    "\n",
    "# Print the lengths before and after the filtering\n",
    "print(len(ts_analysis))  # Original length\n",
    "print(len(hf))  # Filtered length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markets left\n",
    "# Merge filtered hf with markets DataFrame and retrieve the unique parcl_ids in a chained operation\n",
    "\n",
    "parcls_need_to_give_back_list = (\n",
    "    hf.loc[:, ['parcl_id', 'peak_to_current.percent_change', 'change_since_date.percent_change']]  # Use .loc[] for column selection\n",
    "    # Merge with markets DataFrame to add 'clean_name'\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    "    \n",
    "    # Extract unique parcl_id values and convert them to a list\n",
    "    .parcl_id.unique().tolist()\n",
    ")\n",
    "\n",
    "# parcls_need_to_give_back_list contains the unique parcl_ids after the merge3\n",
    "print(len(parcls_need_to_give_back_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter prices_df based on parcl_id from parcls_need_to_give_back_list and a specific parcl_id (5826765)\n",
    "\n",
    "prices_need_to_give_back_df = (\n",
    "    prices_df\n",
    "    # Filter rows where parcl_id is in the list plus the specific parcl_id 5826765\n",
    "    .loc[prices_df['parcl_id'].isin(parcls_need_to_give_back_list + [5826765])]\n",
    ")\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "prices_need_to_give_back_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show percent change relative to the first value after 2020-03-01\n",
    "\n",
    "chart = (\n",
    "    prices_need_to_give_back_df\n",
    "    # Filter rows where the date is greater than or equal to '2020-03-01'\n",
    "    .loc[lambda df: df['date'] >= '2020-03-01']\n",
    "    \n",
    "    # Sort the filtered data by date\n",
    "    .sort_values('date')\n",
    "    \n",
    "    # Select relevant columns for further processing\n",
    "    .loc[:, ['date', 'parcl_id', 'price_per_square_foot_median_sales']]\n",
    "    \n",
    "    # Merge the current data with the first value for each 'parcl_id' on '3/1/2020'\n",
    "    .merge(\n",
    "        prices_need_to_give_back_df\n",
    "        .loc[lambda df: df['date'] == '2020-03-01', ['parcl_id', 'price_per_square_foot_median_sales']]\n",
    "        .rename(columns={'price_per_square_foot_median_sales': 'start'}),\n",
    "        on='parcl_id'\n",
    "    )\n",
    "    \n",
    "    # Calculate the percentage change relative to the start value\n",
    "    .assign(\n",
    "        pct_change=lambda df: (df['price_per_square_foot_median_sales'] - df['start']) / df['start']\n",
    "    )\n",
    "    \n",
    "    # Merge the data with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")\n",
    "\n",
    "# Display the final chart DataFrame\n",
    "chart['clean_name'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get max date\n",
    "chart_max_date = chart['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B, %Y')\n",
    "print(chart_max_date)\n",
    "\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "\n",
    "fig = px.line(\n",
    "    chart,\n",
    "    x='date',\n",
    "    y='pct_change',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_change': '% Change'},\n",
    "    title=f'% Change in Home Values since the Start of the Pandemic ({chart_max_date})'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(chart['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = chart[\n",
    "        (chart['clean_name'] == trace.name) &\n",
    "        (chart['date'] == latest_date)\n",
    "    ]['pct_change'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path='../../../images/change_home_values_since_covid_August_2024.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "chart.to_csv('../../../images/change_home_values_since_covid_August_2024.csv', index=False)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_markets = client.search.markets.retrieve(\n",
    "    sort_by='PRICEFEED_MARKET',\n",
    "    limit=100,\n",
    ")\n",
    "\n",
    "pf_ids = pf_markets.loc[pf_markets['parcl_id'].isin(parcls_need_to_give_back_list)]['parcl_id'].unique().tolist()\n",
    "pf_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markets left\n",
    "markets.loc[markets['parcl_id'].isin(pf_ids)][['clean_name', 'parcl_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2020-03-01'\n",
    "sales_price_feeds = client.price_feed.price_feed.retrieve(\n",
    "    parcl_ids=pf_ids,\n",
    "    start_date=START_DATE,\n",
    "    limit=1000,  # expand the limit to 1000, these are daily series\n",
    "    auto_paginate=True, # auto paginate to get all the data - WARNING: ~6k credits can be used in one parcl price feed. Change the START_DATE to a more recent date to reduce the number of credits used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show percent change for sales price feeds relative to the first value after 2020-03-01\n",
    "\n",
    "chart_pf = (\n",
    "    sales_price_feeds\n",
    "    # Sort the data by date\n",
    "    .sort_values('date')\n",
    "    \n",
    "    # Select relevant columns for further processing\n",
    "    .loc[:, ['date', 'parcl_id', 'price_feed']]\n",
    "    \n",
    "    # Merge the current data with the first value for each 'parcl_id' on '3/1/2020'\n",
    "    .merge(\n",
    "        sales_price_feeds\n",
    "        .loc[lambda df: df['date'] == '2020-03-01', ['parcl_id', 'price_feed']]\n",
    "        .rename(columns={'price_feed': 'start'}),\n",
    "        on='parcl_id'\n",
    "    )\n",
    "    \n",
    "    # Calculate the percentage change relative to the start value\n",
    "    .assign(\n",
    "        pct_change=lambda df: (df['price_feed'] - df['start']) / df['start']\n",
    "    )\n",
    "    \n",
    "    # Merge the data with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")\n",
    "\n",
    "# Display the final chart_pf DataFrame\n",
    "chart_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define names for the chart\n",
    "chart_pf[['clean_name', 'parcl_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chart\n",
    "chart_max_date = chart_pf['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B %d, %Y')\n",
    "print(chart_max_date)\n",
    "\n",
    "fig = px.line(\n",
    "    chart_pf,\n",
    "    x='date',\n",
    "    y='pct_change',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_change': '% Change'},\n",
    "    title=f'% Change in Pricefeed since the Start of the Pandemic ({chart_max_date}) for distressed markets'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(chart_pf['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = chart_pf[\n",
    "        (chart_pf['clean_name'] == trace.name) &\n",
    "        (chart_pf['date'] == latest_date)\n",
    "    ]['pct_change'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path='../../../images/pricefeed_markets_distressed_since_covid_pf_Sept14_2024.png',\n",
    "            width=CHART_WIDTH, height=CHART_WIDTH)\n",
    "chart.to_csv('../../../images/pricefeed_markets_distressed_since_covid_pf_Sept14_2024.csv', index=False)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-spec-mjMMhwjp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
