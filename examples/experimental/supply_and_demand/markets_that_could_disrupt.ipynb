{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Welcome to the Lab ðŸ¥¼ðŸ§ª</h1>\n",
    "</center>\n",
    "\n",
    "## How to identify markets that could disrupt the US?\n",
    "\n",
    "In this notebook, we will be looking for markets that are outpacing supply growth nationwide to look for the needle in the haystack on markets changing faster than the US. We will look for the following criteria:\n",
    "- Markets with a large, trending skew in supply & demand growth where supply is substantially outpacing demand\n",
    "- Markets with signals for motivated sellers, specifically looking at the ratio of all inventory experiencing price drops\n",
    "- Markets that appreciated significantly since COVID, yet have not given back any of those price gains\n",
    "\n",
    "The notebook is broken up into the following sections:\n",
    "1. [Import required packages and setup the Parcl Labs API key](#1-import-required-packages-and-setup-the-parcl-labs-api-key)\n",
    "2. [Search for markets](#2-search-for-markets)\n",
    "3. [Get the data](#3-retrieve-the-data)\n",
    "4. [Initial data preparation](#4-initial-data-preparation)\n",
    "5. [Supply & demand skew](#5-supply--demand-skew)\n",
    "6. [Active supply price drops](#6-new-construction-impact-on-supply)\n",
    "7. [New construction impact on supply](#7-active-supply-price-drops)\n",
    "8. [Appreciation since COVID](#8-appreciation-since-covid)\n",
    "9. [Real time price check](#9-real-time-price-check)\n",
    "\n",
    "#### What will you create in this notebook?\n",
    "\n",
    "##### Understand changes in supply and Demand YoY\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/changes_supply_yoy_scatter.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "##### Understanding gaps in supply and demand\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/changes_supply_yoy_bar.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "#### Prices since beginning of COVID-19 \n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/pct_change_home_values_since_covid_line_chart.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "#### Need help getting started?\n",
    "\n",
    "As a reminder, you can get your Parcl Labs API key [here](https://dashboard.parcllabs.com/signup) to follow along.\n",
    "\n",
    "To run this immediately, you can use Google Colab. Remember, you must set your `PARCL_LABS_API_KEY`.\n",
    "\n",
    "Run in collab --> [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ParclLabs/parcllabs-cookbook/blob/main/examples/experimental/supply_and_demand/markets_that_could_disrupt.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required packages and setup the Parcl Labs API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, install and/or upgrade to the latest verison of the Parcl Labs Python library\n",
    "%pip install --upgrade parcllabs nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import timedelta\n",
    "import plotly.graph_objects as go\n",
    "from parcllabs import ParclLabsClient\n",
    "from parcllabs.beta.charting.styling import SIZE_CONFIG\n",
    "from parcllabs.beta.ts_stats import TimeSeriesAnalysis\n",
    "from parcllabs.beta.charting.utils import create_labs_logo_dict\n",
    "from parcllabs.beta.charting.utils import (\n",
    "    create_labs_logo_dict,\n",
    "    save_figure,\n",
    "    )\n",
    "from parcllabs.beta.charting.styling import default_style_config as style_config\n",
    "\n",
    "\n",
    "client = ParclLabsClient(\n",
    "    api_key=os.environ.get('PARCL_LABS_API_KEY', \"<your Parcl Labs API key if not set as environment variable>\"), \n",
    "    limit=1000, \n",
    "    turbo_mode=True # set turbo mode to True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define root dir to save assets\n",
    "ROOT_DIR = \"../../../outputs\" # Replace with your own directory \n",
    "ANALYSIS_MONTHLY_SERIES = '9/1/2024'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Search for markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top 100 metro markets, sorted by total population in descending order\n",
    "metros = client.search.markets.retrieve(\n",
    "    sort_by='TOTAL_POPULATION',  # Sort by total population\n",
    "    sort_order='DESC',           # In descending order\n",
    "    location_type='CBSA',        # Location type set to Core Based Statistical Area (CBSA)\n",
    "    limit=100                    # Limit results to top 200 metros\n",
    ")\n",
    "\n",
    "# Retrieve national data for the United States to use as a benchmark\n",
    "us = client.search.markets.retrieve(\n",
    "    query='United States',  # Query for the United States as a whole\n",
    "    limit=1                 # Limit results to one (national-level data)\n",
    ")\n",
    "\n",
    "# Concatenate metro market data with national data for comparison\n",
    "markets = pd.concat([metros, us])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets move the PARCL_ID of our metros to a list so we can retrieve the data\n",
    "market_parcl_ids = markets['parcl_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrieve the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve different datasets from the SDK endpoints.\n",
    "# Capturing weekly supply, demand, and price metrics for 200 metros across the country.\n",
    "\n",
    "# Define the start date for supply and demand data\n",
    "start_date = '2022-09-01'\n",
    "\n",
    "\n",
    "# Retrieve the supply (for-sale inventory) data for the market starting from the specified date\n",
    "supply_df = client.for_sale_market_metrics.for_sale_inventory.retrieve(\n",
    "    parcl_ids=market_parcl_ids,\n",
    "    auto_paginate=True,\n",
    "    start_date=start_date,\n",
    ")\n",
    "\n",
    "# Retrieve the demand data (housing event counts) for the market starting from the specified date\n",
    "demand_df = client.market_metrics.housing_event_counts.retrieve(\n",
    "    parcl_ids=market_parcl_ids,\n",
    "    auto_paginate=True,\n",
    "    start_date=start_date,\n",
    ")\n",
    "\n",
    "# Retrieve the price data (housing event prices) for the market starting from Sept 2022\n",
    "prices_df = client.market_metrics.housing_event_prices.retrieve(\n",
    "    parcl_ids=market_parcl_ids,\n",
    "    auto_paginate=True,\n",
    "    start_date='2020-03-01',  # Different start date to capture historical price trends\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the retrieved data lists into DataFrames\n",
    "# Output the length of each DataFrame to understand the volume of data retrieved\n",
    "print(f'Length of supply data: {len(supply_df)}, prices data: {len(prices_df)}, and demand data: {len(demand_df)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in each DataFrame to check for coverage across different markets\n",
    "print(f'There are {len(supply_df.parcl_id.unique())} unique parcl_ids in the supply data, '\n",
    "      f'{len(prices_df.parcl_id.unique())} unique parcl_ids in the prices data, and '\n",
    "      f'{len(demand_df.parcl_id.unique())} unique parcl_ids in the demand data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the date range of the data \n",
    "print(prices_df['date'].max())\n",
    "print(demand_df['date'].max())\n",
    "print(supply_df['date'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `supply_df` dataframe contains all the inventory available for sale across all our markets and its weekly. The `prices_df` dataframe contains information about the median price for sales, listings, and the standard deviation of prices on a monthly basis. The `demand_df` dataframe provides details about the number of events that occurred in the market, including new listings, sales, and units offered for rent on a monthly basis. This information constitutes the first step in our analysis, helping us understand the dynamics of supply and demand alongside price trends.\n",
    "\n",
    "We also need information on price cuts. For this, we will use the `SDF`, specifically the `for_sale_market_metrics.for_sale_inventory_price_changes` method of our client. This endpoint will retrieve price cuts across all types of properties. This endpoint is updated weekly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve price changes in inventory for the market starting from the specified date\n",
    "price_changes_df = client.for_sale_market_metrics.for_sale_inventory_price_changes.retrieve(\n",
    "    parcl_ids=market_parcl_ids,        # Specify the market by its parcl_id\n",
    "    auto_paginate=True,\n",
    "    start_date=start_date     # Use the same start date defined earlier for consistency\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the length of the price changes DataFrame to verify the amount of data retrieved\n",
    "print(f'Length of price changes data: {len(price_changes_df)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in the price changes DataFrame to ensure market coverage\n",
    "print(f'There are {len(price_changes_df.parcl_id.unique())} unique parcl_ids in the price changes data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data we can start our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initial data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly supply and percentage of price drops\n",
    "# Note: Supply data is weekly, and price changes are weekly, so we resample both to a monthly frequency\n",
    "\n",
    "supply_monthly = (\n",
    "    supply_df.copy(deep=True)  # Create a deep copy of the supply DataFrame to avoid modifying the original data\n",
    "    \n",
    "    # Merge with price_changes_df on 'parcl_id' and 'date' to include price drop data for each market\n",
    "    .merge(price_changes_df[['parcl_id', 'date', 'count_price_drop']], on=['parcl_id', 'date'])\n",
    "    \n",
    "    # Add new columns for percentage of price drops and resample dates to monthly\n",
    "    .assign(\n",
    "        pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory'],  # Calculate percentage of price drops out of total suply\n",
    "        date=lambda df: df['date'].dt.to_period('M').dt.to_timestamp()  # Convert the 'date' to monthly frequency\n",
    "    )\n",
    "    \n",
    "    # Group the data by 'parcl_id' and 'date' (now monthly) and calculate the median\n",
    "    .groupby(['parcl_id', 'date'])\n",
    "    .agg({\n",
    "        'for_sale_inventory': 'median',     # Calculate the median inventory for each market and month\n",
    "        'pct_price_drops': 'median'         # Calculate the median percentage of price drops\n",
    "    })\n",
    "    \n",
    "    # Reset the index to return a flat DataFrame\n",
    "    .reset_index()\n",
    "\n",
    "    # Calculate the mean percentage of price drops for each month for all markets\n",
    "    .assign(\n",
    "        pct_price_drops_mean=lambda df: df.groupby('date')['pct_price_drops'].transform('mean'),\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "# Output the length of the final monthly supply DataFrame to verify the amount of data\n",
    "print(f'Length of monthly supply data: {len(supply_monthly)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in the monthly supply data to verify market coverage\n",
    "print(f'There are {len(supply_monthly.parcl_id.unique())} unique parcl_ids in the monthly supply data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly supply and percentage of price drops\n",
    "# Note: Supply data is weekly, and price changes are weekly, so we resample both to a monthly frequency\n",
    "\n",
    "supply_weekly = (\n",
    "    supply_df.copy(deep=True)  # Create a deep copy of the supply DataFrame to avoid modifying the original data\n",
    "    # Add new columns for percentage of price drops and resample dates to monthly\n",
    "    # Merge with price_changes_df on 'parcl_id' and 'date' to include price drop data for each market\n",
    "    .merge(price_changes_df[['parcl_id', 'date', 'count_price_drop']], on=['parcl_id', 'date'])\n",
    "    .assign(\n",
    "        pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory'])    \n",
    "    # Add new columns for percentage of price drops and resample dates to monthly\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the monthly supply data (with price drops) with the demand data\n",
    "# Note: Demand data is already in a monthly series, so we can directly join the datasets on 'parcl_id' and 'date'\n",
    "\n",
    "supply_demand_data = (\n",
    "    demand_df.copy(deep=True)\n",
    "    .loc[:,['date', 'parcl_id', 'sales']]  # Select relevant columns from the demand DataFrame (date, parcl_id, and sales)\n",
    "    .merge(supply_monthly,                    # Merge with the supply_monthly DataFrame that includes supply and price drop data\n",
    "           on=['date', 'parcl_id'])           # Join on 'date' and 'parcl_id' to align data across markets and time periods\n",
    ")\n",
    "\n",
    "# Output the length of the combined supply and demand DataFrame to verify data consistency\n",
    "print(f'Length of supply_demand_data: {len(supply_demand_data)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values to check how many markets are covered in the merged dataset\n",
    "print(f'There are {len(supply_demand_data.parcl_id.unique())} unique parcl_ids in the supply_demand_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new dataframe provides us with a snapshot of market status including the price cuts, share of inventory for sale with price cuts as well as sales activity. Next step involves calculating imbalances between supply and demand. The key idea is that with the data we have so far we can identify players with dwindling demand and price drop pressure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Supply & demand skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'parcl_id' and 'date' to ensure chronological order for percentage change calculations\n",
    "supply_demand_df_imbalances = (\n",
    "    supply_demand_data.copy(deep=True)  # Create a deep copy of the supply_demand_data DataFrame to avoid modifying the original data\n",
    "    .sort_values(['parcl_id', 'date'])  # Sort by 'parcl_id' and 'date'\n",
    "    \n",
    "    .assign(\n",
    "        # Calculate percentage change in 'sales' over 12 periods (1 year) for each 'parcl_id'\n",
    "        pct_change_demand=lambda df: df.groupby('parcl_id')['sales'].pct_change(periods=12),\n",
    "       \n",
    "        # Calculate percentage change in 'for_sale_inventory' over 12 periods for each 'parcl_id'\n",
    "        pct_change_supply=lambda df: df.groupby('parcl_id')['for_sale_inventory'].pct_change(periods=12),\n",
    "        \n",
    "        # Calculate a 3-month moving average of percentage change in demand ('pct_change_demand')\n",
    "        ma_pct_change_demand=lambda df: df.groupby('parcl_id')['pct_change_demand']\n",
    "                                           .transform(lambda x: x.rolling(window=3).mean()),\n",
    "        \n",
    "        # Calculate a 3-month moving average of percentage change in supply ('pct_change_supply')\n",
    "        ma_pct_change_supply=lambda df: df.groupby('parcl_id')['pct_change_supply']\n",
    "                                           .transform(lambda x: x.rolling(window=3).mean())\n",
    "                        \n",
    "        # Drop rows with missing values in the calculated columns\n",
    "        )\n",
    "    .dropna(subset=['pct_change_demand', 'pct_change_supply', 'ma_pct_change_demand', 'ma_pct_change_supply'])\n",
    "    .assign(\n",
    "        gap_demand_supply=lambda df: df['ma_pct_change_supply'] - df['ma_pct_change_demand']   \n",
    "        )\n",
    "    .sort_values('gap_demand_supply', ascending=False)\n",
    "    )\n",
    "print(f'length of supply_demand_df_imbalances df is {len(supply_demand_df_imbalances)}')\n",
    "print(f'there are {len(supply_demand_df_imbalances.parcl_id.unique())} unique parcl_ids in the supply_demand_df_imbalances data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the 'markets' DataFrame by extracting the state and cleaning the market names\n",
    "markets = (\n",
    "    markets.assign(\n",
    "        # Extract the state from the 'name' column by splitting on commas and hyphens, then standardizing it\n",
    "        state=lambda df: df['name'].apply(lambda x: x.split(',')[-1].strip().upper().split('-')[0]),\n",
    "\n",
    "        # Create a 'clean_name' by extracting the first part of 'name' and appending the state\n",
    "        clean_name=lambda df: df.apply(\n",
    "            lambda x: f\"{x['name'].split('-')[0].split(',')[0].strip()}, {x['state']}\", axis=1\n",
    "        )\n",
    "    )\n",
    "    # Replace 'United States Of America, UNITED STATES OF AMERICA' with 'USA'\n",
    "    .replace({'clean_name': {'United States Of America, UNITED STATES OF AMERICA': 'USA'}})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the supply_demand_imbalance DataFrame to get data for the most recent date defined in ANALYSIS_MONTHLY_SERIES\n",
    "# merge with the 'markets' DataFrame, and filter based on specific conditions.\n",
    "# define us parcl_id\n",
    "usa_parcl_id = us[\"parcl_id\"].values[0]\n",
    "max_date = pd.to_datetime(ANALYSIS_MONTHLY_SERIES)\n",
    "\n",
    "# get latest month of imbalanced data\n",
    "supply_demand_imbalance_last = (\n",
    "    supply_demand_df_imbalances.copy(deep=True)  # Create a deep copy of the supply_demand_df_imbalances DataFrame\n",
    "    .loc[lambda df: df['date'] == ANALYSIS_MONTHLY_SERIES]  # Filter for the most recent date\n",
    "    .merge(markets[['parcl_id', 'clean_name', 'state']], on='parcl_id')  # Merge with 'markets' to add 'clean_name' and 'state'\n",
    "    )\n",
    "# get data only for the USA, we do this so it is not included in the ranking\n",
    "supply_demand_imbalance_last_us = supply_demand_imbalance_last \\\n",
    "    .query('date == @max_date') \\\n",
    "    .query(f'parcl_id == {usa_parcl_id}'\n",
    "           )\n",
    "# add a rank none to the US data so we can concatenate with the supply and demand imbalanced data\n",
    "supply_demand_imbalance_last_us['rank']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ranking for the gap_demand_supply, filter US parcl_id\n",
    "# this has the df with the rank of the gap_demand_supply  minus the US data\n",
    "input_final_df_supply_demand_imbalance_last = (\n",
    "    supply_demand_imbalance_last.copy(deep=True)\n",
    "    # filter out US data\n",
    "    .query(\"parcl_id!=@usa_parcl_id\")\n",
    "    # create a rank based on gap_demand_supply\n",
    "    .assign(rank = lambda x: x['gap_demand_supply'].rank(ascending=False))\n",
    "    )\n",
    "\n",
    "input_final_df_supply_demand_imbalance_last_df = (\n",
    "    supply_demand_imbalance_last_us.copy(deep=True)\n",
    "    .loc[:,['date', 'parcl_id', 'pct_change_demand', 'pct_change_supply',\n",
    "          'ma_pct_change_demand','ma_pct_change_supply','gap_demand_supply','clean_name', 'state','rank']]\n",
    "    )\n",
    "# check that we have 100 markets in the input_final_df_supply_demand_imbalance_last dataframe \n",
    "print(len(input_final_df_supply_demand_imbalance_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparate data to be exported, we append the usa data at the end\n",
    "data_for_table = pd.concat([\n",
    "    input_final_df_supply_demand_imbalance_last[\n",
    "    ['date', 'parcl_id', 'pct_change_demand','pct_change_supply',\n",
    "    'ma_pct_change_demand','ma_pct_change_supply',\n",
    "    'gap_demand_supply','clean_name', 'state','rank']],\n",
    "    input_final_df_supply_demand_imbalance_last_df[[\n",
    "    'date', 'parcl_id', 'pct_change_demand', 'pct_change_supply',\n",
    "    'ma_pct_change_demand','ma_pct_change_supply',\n",
    "    'gap_demand_supply','clean_name', 'state','rank']]\n",
    "    ]\n",
    "    )\n",
    "# print the length of the data, we should have the usa data and the rest of the data\n",
    "print(len(data_for_table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save full rankings to csv\n",
    "data_for_table_output_file = data_for_table[[\n",
    "    'parcl_id', \n",
    "    'clean_name',\n",
    "    'state',\n",
    "    'rank',\n",
    "    'date', \n",
    "    'ma_pct_change_demand',\n",
    "    'ma_pct_change_supply',\n",
    "    'gap_demand_supply',\n",
    "]]\n",
    "\n",
    "data_for_table_output_file = data_for_table_output_file.rename(columns={\n",
    "    'clean_name': 'name',\n",
    "    'ma_pct_change_demand': 'trend_pct_change_demand',\n",
    "    'ma_pct_change_supply': 'trend_pct_change_supply',\n",
    "    'gap_demand_supply': 'trend_gap_demand_supply'\n",
    "})\n",
    "imbalanced_with_price_changes_data_all = (\n",
    "    supply_df.copy(deep=True)\n",
    "    .merge(price_changes_df[['parcl_id', 'date', 'count_price_drop']], on=['parcl_id', 'date'])\n",
    "    .sort_values(by=['parcl_id', 'date'], ascending=[True, True])\n",
    "    .assign(pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory'])\n",
    "    # Calculate the 3-month rolling average of price changes for each parcl_id\n",
    "    .assign(\n",
    "        ma_price_changes=lambda df: df.groupby('parcl_id')['pct_price_drops'].transform(lambda x: x.rolling(window=3).mean())\n",
    "    )\n",
    "    .groupby('parcl_id').tail(1)\n",
    ")\n",
    "\n",
    "# merge data with price changes\n",
    "data_for_table_output_file = data_for_table_output_file.merge(imbalanced_with_price_changes_data_all[['parcl_id', 'ma_price_changes']], on='parcl_id', how='left')\n",
    "data_for_table_output_file = data_for_table_output_file.rename(columns={'ma_price_changes': 'pct_inventory_with_price_cuts'})\n",
    "\n",
    "# Save output in directory\n",
    "data_for_table_output_file.to_csv(f'{ROOT_DIR}/september_rankings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Further filter based on sales, inventory, and percentage change conditions\n",
    "# We want to filter out the markets with low sales, low inventory, and low gap between demand and supply\n",
    "# we use a threshold of 500 for sales and inventory and 0.45 for gap_demand_supply, meaning a relative shift of 45 percent\n",
    "# in favor of supply\n",
    "supply_demand_imbalance_last_filtered = (\n",
    "    supply_demand_imbalance_last.copy(deep=True)\n",
    "    .loc[\n",
    "        (supply_demand_imbalance_last['sales'] > 500) & \n",
    "        (supply_demand_imbalance_last['for_sale_inventory'] > 500) \n",
    "        & (supply_demand_imbalance_last['gap_demand_supply'] > 0.5)\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Concatenate US-specific data with the filtered data\n",
    "supply_demand_imbalance_last = pd.concat([supply_demand_imbalance_last_us, supply_demand_imbalance_last_filtered])\n",
    "\n",
    "print(f'length of supply_demand_imbalance_last is {len(supply_demand_imbalance_last)}')\n",
    "print(f'there are {len(supply_demand_imbalance_last.parcl_id.unique())} unique parcl_ids in the supply_demand_imbalance_last data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the list of parcls to imblanced_parcl_ids, this already includes the USA national data\n",
    "imbalanced_parcl_ids = supply_demand_imbalance_last['parcl_id'].unique().tolist() \n",
    "print(f'before filtering for price cuts larger than the national average we have {len(imbalanced_parcl_ids)} imbalanced markets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Active supply price drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will filter based on demand\n",
    "# Calculate the 3-period rolling average of price drops, filter using query, and extract parcl_ids\n",
    "imbalanced_with_price_changes_data_all = (\n",
    "    supply_df.copy(deep=True)\n",
    "    .merge(price_changes_df[['parcl_id', 'date', 'count_price_drop']], on=['parcl_id', 'date'])\n",
    "    .assign(pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory'])\n",
    "    .sort_values(by=['parcl_id', 'date'], ascending=[True, True])\n",
    "    # Calculate the 3-month rolling average of price changes for each parcl_id\n",
    "    .assign(\n",
    "        ma_price_changes=lambda df: df.groupby('parcl_id')['pct_price_drops'].transform(lambda x: x.rolling(window=3).mean())\n",
    "    )\n",
    "    \n",
    "    .sort_values(by=['parcl_id', 'date'], ascending=[True, True])\n",
    "    .groupby('parcl_id').tail(1)\n",
    "    # Sort by the rolling average of price changes in descending order\n",
    "    .sort_values('ma_price_changes', ascending=False)\n",
    ")\n",
    "# define input for table\n",
    "input_for_table_imbalanced_with_price_changes_data = imbalanced_with_price_changes_data_all.copy(deep=True)\n",
    "print(f'length of imbalanced_with_price_changes_data_all is {len(imbalanced_with_price_changes_data_all)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to only include markets with a gap larger than the defined threshold, should be the same as the lenght\n",
    "# of imbalance_parcl_ids\n",
    "imbalanced_with_price_changes_data = (\n",
    "    imbalanced_with_price_changes_data_all.copy(deep=True)\n",
    "    # Further filter to include only imbalanced parcl_ids using query\n",
    "    .query('parcl_id in @imbalanced_parcl_ids')\n",
    ")\n",
    "print(f'length of imbalanced_with_price_changes_data is {len(imbalanced_with_price_changes_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value for the usa\n",
    "us_price_changes = (imbalanced_with_price_changes_data\n",
    "                    .query('(parcl_id == @usa_parcl_id)')\n",
    "                    )['ma_price_changes'].values[0]\n",
    " \n",
    "# filter based on the last 3 months moving average of inventory with price cuts at the national level\n",
    "print(f'the price cut threshold for this month is {us_price_changes:.2%}')\n",
    "# Filter the imbalanced markets based on price changes\n",
    "print(f'before filtering for price cuts larger than the national average we have {len(imbalanced_with_price_changes_data.parcl_id.unique())} imbalanced markets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with markets info\n",
    "imbalanced_with_price_changes_data = (\n",
    "    imbalanced_with_price_changes_data.copy(deep=True)\n",
    "    .merge(markets[['parcl_id', 'clean_name', 'state']], on='parcl_id')\n",
    "    .sort_values('ma_price_changes', ascending=False)\n",
    "    # filter on max date\n",
    "    .loc[lambda df: df['date'] == df['date'].max()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter and print how many observations we have\n",
    "imbalanced_with_price_changes_data = imbalanced_with_price_changes_data.query('ma_price_changes > @us_price_changes')\n",
    "imbalanced_parcl_ids_final = imbalanced_with_price_changes_data['parcl_id'].unique().tolist()\n",
    "# add back comp to US\n",
    "imbalanced_parcl_ids_final = imbalanced_parcl_ids_final + [usa_parcl_id]\n",
    "# drop baton rouge due to volatility\n",
    "imbalanced_parcl_ids_final = [x for x in imbalanced_parcl_ids_final if x != 2899589]\n",
    "print(len(imbalanced_parcl_ids_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter supply demand based on the new list\n",
    "supply_demand_imbalance_last = supply_demand_imbalance_last.query('parcl_id in @imbalanced_parcl_ids_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to identify selected states\n",
    "target_states = {'TX', 'FL'}\n",
    "supply_demand_imbalance_last['color_group'] = supply_demand_imbalance_last['state'].apply(\n",
    "    lambda x: 'FL, TX' if x in target_states else 'Other')\n",
    "\n",
    "# Get the maximum date for the chart title\n",
    "chart_max_date = supply_demand_imbalance_last['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B, %Y')\n",
    "\n",
    "\n",
    "CHART_WIDTH = 1000\n",
    "CHART_HEIGHT = 800\n",
    "# Creating the scatter plot\n",
    "fig = px.scatter(\n",
    "    supply_demand_imbalance_last, \n",
    "    x='ma_pct_change_demand', \n",
    "    y='ma_pct_change_supply', \n",
    "    color='color_group',  # Use the new color_group column for color\n",
    "    hover_name='clean_name', \n",
    "    title=f'YoY Changes in Supply vs. Demand ({chart_max_date})',\n",
    "    color_discrete_map={'FL, TX':'red' , 'Other': 'blue'},  # Customize colors,\n",
    "    text='clean_name'\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textposition='top center',\n",
    "    mode='markers+text'  # Ensure that both markers and text are displayed\n",
    ")\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    "    )\n",
    "\n",
    "# Update axes labels and layout to format as a square\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "     xaxis=dict(\n",
    "            title_text='YoY % Change Demand (Sales)',\n",
    "            showgrid=style_config['showgrid'],\n",
    "            gridwidth=style_config['gridwidth'],\n",
    "            gridcolor=style_config['grid_color'],\n",
    "            # tickangle=style_config['tick_angle'],\n",
    "            tickformat='.0%',\n",
    "            linecolor=style_config['line_color_axis'],\n",
    "            linewidth=style_config['linewidth'],\n",
    "            titlefont=style_config['title_font_axis'],\n",
    "            zeroline=False,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text='YoY % Change Supply',\n",
    "            showgrid=style_config['showgrid'],\n",
    "            gridwidth=style_config['gridwidth'],\n",
    "            gridcolor=style_config['grid_color'],\n",
    "            tickfont=style_config['axis_font'],\n",
    "            zeroline=False,\n",
    "            tickformat='.0%',\n",
    "            linecolor=style_config['line_color_axis'],\n",
    "            linewidth=style_config['linewidth'],\n",
    "            titlefont=style_config['title_font_axis']\n",
    "        ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    legend_title_text='',\n",
    "    autosize=False,\n",
    "    height=CHART_HEIGHT,\n",
    "    width=CHART_WIDTH,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    "    legend=dict(\n",
    "            x=style_config['legend_x'],\n",
    "            y=style_config['legend_y'],\n",
    "            xanchor=style_config['legend_xanchor'],\n",
    "            yanchor=style_config['legend_yanchor'],\n",
    "            font=style_config['legend_font'],\n",
    "            bgcolor='rgba(0, 0, 0, 0)'\n",
    "        ),\n",
    ")\n",
    "save_figure(fig, save_path=f'{ROOT_DIR}/changes_supply_yoy_scatter.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar chart\n",
    "\n",
    "# Merge the gap data with the supply and demand data to ensure consistent x-values\n",
    "merged_data = supply_demand_imbalance_last[['clean_name', 'ma_pct_change_demand', 'ma_pct_change_supply', 'gap_demand_supply']]\n",
    "merged_data = merged_data.sort_values('gap_demand_supply', ascending=True)\n",
    "\n",
    "# Melt the data for the bar chart\n",
    "data_for_bar = pd.melt(merged_data, \n",
    "                       id_vars=['clean_name'], \n",
    "                       value_vars=['ma_pct_change_demand', 'ma_pct_change_supply'], \n",
    "                       var_name='type', \n",
    "                       value_name='percent_change')\n",
    "\n",
    "data_for_bar['type'] = data_for_bar['type'].map({'ma_pct_change_demand': 'Demand', \n",
    "                                                 'ma_pct_change_supply': 'Supply',\n",
    "                                                 })\n",
    "\n",
    "fig = px.bar(data_for_bar, \n",
    "             x='clean_name', \n",
    "             y='percent_change', \n",
    "             color='type', \n",
    "             barmode='relative', \n",
    "             title=f'YoY Change in Supply and Demand ({chart_max_date})',\n",
    "             labels={'percent_change': 'Percent Change', 'clean_name': 'Market'},\n",
    "             color_discrete_map={'Demand': 'red', 'Supply': 'green'})\n",
    "\n",
    "# Update the legend names\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'Demand':\n",
    "        trace.name = 'Demand (Sales)'\n",
    "    elif trace.name == 'Supply':\n",
    "        trace.name = 'Supply (Inventory)'\n",
    "\n",
    "# Define dimensions\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title_text='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis'],\n",
    "        tickfont=dict(size=style_config['axis_font']['size'], color=style_config['axis_font']['color']),\n",
    "        # showticklabels=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='Percent Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    legend_title_text='',\n",
    "    autosize=False,\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    "    legend=dict(\n",
    "        x=style_config['legend_x'],\n",
    "        y=style_config['legend_y'],\n",
    "        xanchor=style_config['legend_xanchor'],\n",
    "        yanchor=style_config['legend_yanchor'],\n",
    "        font=style_config['legend_font'],\n",
    "        bgcolor='rgba(0, 0, 0, 0)'\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_layout_image(create_labs_logo_dict())\n",
    "save_figure(fig, save_path=f'{ROOT_DIR}/changes_supply_yoy_bar.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data from scatter plot and bar plot\n",
    "supply_demand_imbalance_out = supply_demand_imbalance_last[[\n",
    "    'parcl_id',\n",
    "    'clean_name',\n",
    "    'date',\n",
    "    'ma_pct_change_demand',\n",
    "    'ma_pct_change_supply',\n",
    "    'gap_demand_supply'\n",
    "]]\n",
    "\n",
    "supply_demand_imbalance_out = supply_demand_imbalance_out.rename(columns={\n",
    "    'clean_name': 'name',\n",
    "    'ma_pct_change_demand': 'trend_pct_change_demand',\n",
    "    'ma_pct_change_supply': 'trend_pct_change_supply'\n",
    "})\n",
    "\n",
    "supply_demand_imbalance_out.to_csv(f'{ROOT_DIR}/changes_supply_yoy_gap_bar_scatter_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the gap data with the supply and demand data to ensure consistent x-values\n",
    "merged_data = supply_demand_imbalance_last[['clean_name', 'gap_demand_supply']]\n",
    "merged_data = merged_data.sort_values('gap_demand_supply', ascending=True)\n",
    "\n",
    "# No need to melt the data as we are only using one value (gap_demand_supply)\n",
    "data_for_bar = merged_data.copy()\n",
    "\n",
    "# Create the bar chart for gap_demand_supply with orange color\n",
    "fig = px.bar(data_for_bar, \n",
    "             x='clean_name', \n",
    "             y='gap_demand_supply', \n",
    "             title=f'Gap Between Demand and Supply ({chart_max_date})',\n",
    "             labels={'gap_demand_supply': 'Gap (Percentage)', 'clean_name': 'Market'},\n",
    "             color_discrete_sequence=['orange'])  # Set the bar color to orange\n",
    "\n",
    "# Define dimensions\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title_text='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis'],\n",
    "        tickfont=dict(size=style_config['axis_font']['size'], color=style_config['axis_font']['color']),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='Gap (Percentage)',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    autosize=False,\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    ")\n",
    "\n",
    "# Add any custom images (like a logo)\n",
    "fig.add_layout_image(create_labs_logo_dict())\n",
    "\n",
    "# Save the figure\n",
    "save_figure(fig, save_path=f\"{ROOT_DIR}/changes_supply_gap_bar.png\", \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "\n",
    "# Show the chart\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. New construction impact on supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need  to iterated to get the housing event counts \n",
    "new_listings = client.market_metrics.housing_event_counts.retrieve(\n",
    "    parcl_ids=imbalanced_parcl_ids_final,\n",
    "    start_date='2024-09-01',\n",
    "    auto_paginate=True\n",
    "    # limit =1 # limit to 1 to get the most recent data\n",
    ")\n",
    "\n",
    "new_listings_construction = client.new_construction_metrics.housing_event_counts.retrieve(\n",
    "    parcl_ids=imbalanced_parcl_ids_final,\n",
    "    start_date='2024-09-01',\n",
    "    auto_paginate=True\n",
    "    # limit=1 # limit to 1 to get the most recent data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns to distinguish between new listings and new construction data\n",
    "new_listings_construction = (\n",
    "    new_listings_construction\n",
    "    .rename(columns={'new_listings_for_sale': 'new_construction_new_listings_for_sale'})\n",
    "    )\n",
    "\n",
    "# Output the length of the new listings data to confirm the amount of data retrieved\n",
    "print(f'Length of new_listings data: {len(new_listings)} and nc data: {len(new_listings_construction)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values to verify coverage across different markets\n",
    "print(f'There are {len(new_listings.parcl_id.unique())} unique parcl_ids in the new_listings data and'\n",
    "      f' {len(new_listings_construction.parcl_id.unique())} unique parcl_ids in the new construction data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge new listings data with new construction listings, calculate percentage, and merge with market names\n",
    "new_listings_all = (\n",
    "    new_listings\n",
    "    # Merge new listings with new construction data on 'parcl_id'\n",
    "    .merge(new_listings_construction[['parcl_id', 'new_construction_new_listings_for_sale']], \n",
    "           on='parcl_id')\n",
    "    \n",
    "    # Calculate the percentage of new construction listings out of total new listings\n",
    "    .assign(\n",
    "        pct_new_construction=lambda x: x['new_construction_new_listings_for_sale'] / x['new_listings_for_sale']\n",
    "    )\n",
    "    \n",
    "    # Merge with the 'markets' DataFrame to add clean market names based on 'parcl_id'\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the bar chart with sorting, melting, and formatting in one step\n",
    "data_for_bar = (\n",
    "    new_listings_all  # Filter for the most recent date\n",
    "    .sort_values('pct_new_construction', ascending=True)  # Sort by percentage of new construction\n",
    "    .assign(\n",
    "        chart_max_date=lambda df: df['date'].max().strftime('%B, %Y')  # Format the latest date\n",
    "    )\n",
    "    .pipe(\n",
    "        lambda df: pd.melt(df, id_vars=['clean_name'], \n",
    "                           value_vars=['pct_new_construction'], \n",
    "                           var_name='type', \n",
    "                           value_name='percentage')  # Reshape for bar chart\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the stacked bar chart\n",
    "fig = px.bar(data_for_bar, \n",
    "             x='clean_name', \n",
    "             y='percentage', \n",
    "             color='type', \n",
    "             barmode='stack', \n",
    "             title=f'Percent of New Listings Coming from New Construction ({chart_max_date})',\n",
    "             labels={'percentage': 'Percentage', 'clean_name': 'Market'},\n",
    "             color_discrete_map={'type': 'orange', 'type': 'orange'})\n",
    "\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "\n",
    "# Update the layout to remove the legend\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title_text='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis'],\n",
    "        tickfont=dict(size=style_config['axis_font']['size'], color=style_config['axis_font']['color']),\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='% of New Inventory',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    autosize=False,\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend=dict(\n",
    "        x=style_config['legend_x'],\n",
    "        y=style_config['legend_y'],\n",
    "        xanchor=style_config['legend_xanchor'],\n",
    "        yanchor=style_config['legend_yanchor'],\n",
    "        font=style_config['legend_font'],\n",
    "        bgcolor='rgba(0, 0, 0, 0)'\n",
    "    ),\n",
    "    showlegend=False  # This will hide the legend\n",
    ")\n",
    "\n",
    "fig.add_layout_image(create_labs_logo_dict())\n",
    "save_figure(fig, save_path=f'{ROOT_DIR}/pct_new_listings_construction_bar.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "nc_out_data = pd.merge(data_for_bar, markets[['clean_name', 'parcl_id']], on='clean_name')\n",
    "nc_out_data = nc_out_data[['parcl_id', 'clean_name', 'percentage']]\n",
    "nc_out_data = nc_out_data.rename(columns={\n",
    "    'clean_name': 'name',\n",
    "    'percentage': 'pct_new_construction'\n",
    "})\n",
    "nc_out_data.to_csv(f'{ROOT_DIR}/pct_new_listings_construction_bar.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and process price changes data, calculating percentage of price drops and merging relevant columns\n",
    "price_changes_skewed = (\n",
    "    price_changes_df.copy(deep=True)\n",
    "    # Filter for relevant parcl_ids using the pre-combined list\n",
    "    .query('parcl_id in @imbalanced_parcl_ids_final')\n",
    "    )\n",
    "\n",
    "\n",
    "price_changes_skewed = (\n",
    "    price_changes_skewed\n",
    "    # Merge with the supply data on 'parcl_id' and 'date' to bring in for_sale_inventory\n",
    "    .merge(supply_df[['parcl_id', 'date', 'for_sale_inventory']], on=['parcl_id', 'date'])\n",
    "    \n",
    "    # Calculate the percentage of price drops relative to the for_sale_inventory\n",
    "    .assign(\n",
    "        pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory']\n",
    "    )\n",
    "    \n",
    "    # Merge with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_changes_skewed.groupby('parcl_id').tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max date for chart\n",
    "max_date_for_chart = price_changes_skewed['date'].max().date()\n",
    "max_date_for_chart = max_date_for_chart.strftime('%B %d, %Y')\n",
    "\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "# Create the line chart using Plotly Express\n",
    "fig = px.line(\n",
    "    price_changes_skewed,\n",
    "    x='date',\n",
    "    y='pct_price_drops',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_price_drops': '% of Inventory with Price Cuts'},\n",
    "    title=f'Percentage of Inventory with Price Reductions ({max_date_for_chart})'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(price_changes_skewed['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = price_changes_skewed[\n",
    "        (price_changes_skewed['clean_name'] == trace.name) &\n",
    "        (price_changes_skewed['date'] == latest_date)\n",
    "    ]['pct_price_drops'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Price Reductions',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path=f'{ROOT_DIR}/pct_inventory_price_reductions_line_chart.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Appreciation since COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data for the line chart\n",
    "price_changes_data = price_changes_skewed[['parcl_id', 'clean_name', 'date', 'pct_price_drops']]\n",
    "price_changes_data = price_changes_data.rename(columns={\n",
    "    'clean_name': 'name',\n",
    "    'pct_price_drops': 'pct_price_drops'\n",
    "})\n",
    "price_changes_data.to_csv(f'{ROOT_DIR}/pct_inventory_price_reductions_line_chart_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to most out of balance markets regarding supply and demand\n",
    "prices_need_to_give_back = prices_df.copy(deep=True).loc[prices_df['parcl_id'].isin(imbalanced_parcl_ids_final + [5826765])]\n",
    "print(f'There are {len(prices_need_to_give_back)} observations in the price history df.')\n",
    "print(f'There are {len(prices_need_to_give_back[\"parcl_id\"].unique())} with substantial price reductions and distressed demand.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will iterate over the parcl_ids to get the time series analysis and identify what\n",
    "# parcls need to give back the most from the beginning of the pandemic compared to the USA\n",
    "all_rows = []\n",
    "for pid in prices_need_to_give_back['parcl_id'].unique().tolist():\n",
    "    prices_skew_test = prices_need_to_give_back.copy(deep=True).loc[prices_need_to_give_back['parcl_id']==pid]\n",
    "    price_ts_analysis = TimeSeriesAnalysis(prices_skew_test, 'date', 'price_per_square_foot_median_sales', freq='M')\n",
    "    price_rate_of_change_stats = price_ts_analysis.calculate_changes(change_since_date='3/1/2020')\n",
    "    row = pd.json_normalize(price_rate_of_change_stats)\n",
    "    row['parcl_id'] = pid\n",
    "    all_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform time series analysis for each unique parcl_id in a chained and list comprehension style\n",
    "all_rows = (\n",
    "    prices_need_to_give_back['parcl_id'].unique()  # Get the unique parcl_ids\n",
    "    .tolist()  # Convert to a list for iteration\n",
    ")\n",
    "\n",
    "ts_analysis = pd.concat([\n",
    "    pd.json_normalize(\n",
    "        TimeSeriesAnalysis(\n",
    "            prices_need_to_give_back.query('parcl_id == @pid'),  # Filter for each parcl_id\n",
    "            'date', 'price_per_square_foot_median_sales', freq='M'  # Perform time series analysis\n",
    "        ).calculate_changes(change_since_date='3/1/2020')  # Calculate changes since 3/1/2020\n",
    "    ).assign(parcl_id=pid)  # Add the parcl_id to the result\n",
    "    for pid in all_rows  # Iterate over each unique parcl_id\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique parcl_ids\n",
    "all_rows = prices_need_to_give_back['parcl_id'].unique().tolist()\n",
    "\n",
    "# Calculate price changes for the last month (September 2024)\n",
    "last_month_changes = pd.concat([\n",
    "    pd.json_normalize(\n",
    "        TimeSeriesAnalysis(\n",
    "            prices_need_to_give_back.query('parcl_id == @pid'),  # Filter for each parcl_id\n",
    "            'date', 'price_per_square_foot_median_sales', freq='M'  # Perform time series analysis\n",
    "        ).calculate_changes(change_since_date='3/1/2020')  # Calculate changes since 3/1/2020 for the last month\n",
    "    ).assign(parcl_id=pid)  # Add the parcl_id to the result\n",
    "    for pid in all_rows\n",
    "], ignore_index=True)\n",
    "\n",
    "# Calculate price changes for the second-to-last month (August 2024)\n",
    "second_last_month_changes = pd.concat([\n",
    "    pd.json_normalize(\n",
    "        TimeSeriesAnalysis(\n",
    "            prices_need_to_give_back.query('parcl_id == @pid and date <= \"2024-08-31\"'),  # Filter for each parcl_id up to August 2024\n",
    "            'date', 'price_per_square_foot_median_sales', freq='M'  # Perform time series analysis\n",
    "        ).calculate_changes(change_since_date='3/1/2020')  # Calculate changes since 3/1/2020 for the second-to-last month\n",
    "    ).assign(parcl_id=pid)  # Add the parcl_id to the result\n",
    "    for pid in all_rows\n",
    "], ignore_index=True)\n",
    "second_last_month_changes = second_last_month_changes.rename(columns={'change_since_date.percent_change': 'change_august'})\n",
    "\n",
    "# Merge the two results on parcl_id\n",
    "ts_analysis = last_month_changes.merge(\n",
    "    second_last_month_changes[['parcl_id','change_august']],\n",
    "    on='parcl_id',\n",
    ")\n",
    "\n",
    "# Now `ts_analysis` contains both the last month and second-to-last month changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for the line chart\n",
    "hf = (\n",
    "    ts_analysis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge filtered hf with markets DataFrame and retrieve the unique parcl_ids in a chained operation\n",
    "parcls_need_to_give_back_list = (\n",
    "    hf.loc[:, ['parcl_id', 'peak_to_current.percent_change', 'change_since_date.percent_change','change_august']]  # Use .loc[] for column selection\n",
    "    # Merge with markets DataFrame to add 'clean_name'\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    "    \n",
    "    # Extract unique parcl_id values and convert them to a list\n",
    "    .parcl_id.unique().tolist()\n",
    ")\n",
    "\n",
    "# parcls_need_to_give_back_list contains the unique parcl_ids after the merge3\n",
    "print(len(parcls_need_to_give_back_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter prices_df based on parcl_id from parcls_need_to_give_back_list and a specific parcl_id (5826765)\n",
    "\n",
    "prices_need_to_give_back_df = (\n",
    "    prices_df\n",
    "    # Filter rows where parcl_id is in the list plus the specific parcl_id 5826765\n",
    "    .loc[prices_df['parcl_id'].isin(parcls_need_to_give_back_list + [5826765])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show percent change relative to the first value after 2020-03-01\n",
    "\n",
    "chart = (\n",
    "    prices_need_to_give_back_df\n",
    "    # Filter rows where the date is greater than or equal to '2020-03-01'\n",
    "    .loc[lambda df: df['date'] >= '2020-03-01']\n",
    "    \n",
    "    # Sort the filtered data by date\n",
    "    .sort_values('date')\n",
    "    \n",
    "    # Select relevant columns for further processing\n",
    "    .loc[:, ['date', 'parcl_id', 'price_per_square_foot_median_sales']]\n",
    "    \n",
    "    # Merge the current data with the first value for each 'parcl_id' on '3/1/2020'\n",
    "    .merge(\n",
    "        prices_need_to_give_back_df\n",
    "        .loc[lambda df: df['date'] == '2020-03-01', ['parcl_id', 'price_per_square_foot_median_sales']]\n",
    "        .rename(columns={'price_per_square_foot_median_sales': 'start'}),\n",
    "        on='parcl_id'\n",
    "    )\n",
    "    \n",
    "    # Calculate the percentage change relative to the start value\n",
    "    .assign(\n",
    "        pct_change=lambda df: (df['price_per_square_foot_median_sales'] - df['start']) / df['start'],\n",
    "        max_value = lambda df: df.groupby('parcl_id')['price_per_square_foot_median_sales'].transform('max')\n",
    "    )\n",
    "    # Merge the data with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    "    .assign(diff_from_peak = lambda x: (x['max_value'] - x['price_per_square_foot_median_sales'])/x['max_value'])\n",
    ")\n",
    "\n",
    "prices_since_last_report = (\n",
    "    prices_need_to_give_back_df.copy(deep=True)\n",
    "    # Filter rows where the date is greater than or equal to '2020-03-01'\n",
    "    .query('date >= \"2020-03-01\"')\n",
    "    \n",
    "    # Sort the filtered data by date\n",
    "    .sort_values(by =['parcl_id','date'])\n",
    "    \n",
    "    # Select relevant columns for further processing\n",
    "    .loc[:, ['date', 'parcl_id', 'price_per_square_foot_median_sales']]\n",
    "\n",
    "    .assign(\n",
    "        change_price_mom = lambda df: df.groupby('parcl_id')['price_per_square_foot_median_sales'].pct_change(),\n",
    "    )\n",
    "    \n",
    "    .query('date == \"2024-09-01\"')\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")\n",
    "prices_since_last_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get max date\n",
    "chart_max_date = chart['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B, %Y')\n",
    "print(chart_max_date)\n",
    "\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "\n",
    "fig = px.line(\n",
    "    chart,\n",
    "    x='date',\n",
    "    y='pct_change',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_change': '% Change'},\n",
    "    title=f'% Change in Home Values since the Start of the Pandemic ({chart_max_date})'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(chart['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = chart[\n",
    "        (chart['clean_name'] == trace.name) &\n",
    "        (chart['date'] == latest_date)\n",
    "    ]['pct_change'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path=f'{ROOT_DIR}/pct_change_home_values_since_covid_line_chart.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "chart_data = chart[['parcl_id', 'clean_name', 'date', 'pct_change']]\n",
    "chart_data.to_csv(f'{ROOT_DIR}/pct_change_home_values_since_covid_line_chart_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Real time price check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2020-03-01'\n",
    "\n",
    "# isolate markets in the list that have price feeds\n",
    "pf_ids = markets.loc[(markets['parcl_id'].isin(imbalanced_parcl_ids_final)) & markets['pricefeed_market']== 1]['parcl_id'].tolist()\n",
    "\n",
    "sales_price_feeds = client.price_feed.price_feed.retrieve(\n",
    "     parcl_ids=pf_ids,\n",
    "     start_date=START_DATE,\n",
    "     limit=1000,  # expand the limit to 1000, these are daily series\n",
    "     auto_paginate=True, # auto paginate to get all the data - WARNING: ~6k credits can be used in one parcl price feed. Change the START_DATE to a more recent date to reduce the number of credits used\n",
    ")\n",
    "print(len(pf_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show percent change for sales price feeds relative to the first value after 2020-03-01\n",
    "\n",
    "chart_pf = (\n",
    "    sales_price_feeds\n",
    "    # Sort the data by date\n",
    "    .sort_values('date')\n",
    "    \n",
    "    # Select relevant columns for further processing\n",
    "    .loc[:, ['date', 'parcl_id', 'price_feed']]\n",
    "    \n",
    "    # Merge the current data with the first value for each 'parcl_id' on '3/1/2020'\n",
    "    .merge(\n",
    "        sales_price_feeds\n",
    "        .loc[lambda df: df['date'] == '2020-03-01', ['parcl_id', 'price_feed']]\n",
    "        .rename(columns={'price_feed': 'start'}),\n",
    "        on='parcl_id'\n",
    "    )\n",
    "    \n",
    "    # Calculate the percentage change relative to the start value\n",
    "    .assign(\n",
    "        pct_change=lambda df: (df['price_feed'] - df['start']) / df['start']\n",
    "    )\n",
    "    \n",
    "    # Merge the data with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chart\n",
    "chart_max_date = chart_pf['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B %d, %Y')\n",
    "print(chart_max_date)\n",
    "\n",
    "fig = px.line(\n",
    "    chart_pf,\n",
    "    x='date',\n",
    "    y='pct_change',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_change': '% Change'},\n",
    "    title=f'% Change in Pricefeed since the Start of the Pandemic ({chart_max_date})'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(chart_pf['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = chart_pf[\n",
    "        (chart_pf['clean_name'] == trace.name) &\n",
    "        (chart_pf['date'] == latest_date)\n",
    "    ]['pct_change'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path=f'{ROOT_DIR}/realtime_pct_change_home_values_since_covid_line_chart.png',\n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "chart_pf_data = chart_pf[['parcl_id', 'clean_name', 'date', 'pct_change']]\n",
    "chart_pf_data = chart_pf_data.rename(columns={\n",
    "    'clean_name': 'name',\n",
    "    'pct_change': 'pct_change'\n",
    "})\n",
    "chart_pf_data.to_csv(f'{ROOT_DIR}/realtime_pct_change_home_values_since_covid_line_chart_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parcllabs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
