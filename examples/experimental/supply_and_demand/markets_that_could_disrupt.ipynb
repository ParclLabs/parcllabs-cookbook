{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<h1>Welcome to the Lab ðŸ¥¼ðŸ§ª</h1>\n",
    "</center>\n",
    "\n",
    "## How to identify markets that could disrupt the US?\n",
    "\n",
    "In this notebook, we will be looking for markets that are outpacing supply growth nationwide to look for the needle in the haystack on markets changing faster than the US. We will look for the following criteria:\n",
    "- Markets with a large, trending skew in supply & demand growth where supply is substantially outpacing demand\n",
    "- Markets with signals for motivated sellers, specifically looking at the ratio of all inventory experiencing price drops\n",
    "- Markets that appreciated significantly since COVID, yet have not given back any of those price gains\n",
    "\n",
    "The notebook is broken up into the following sections:\n",
    "1. [Import required packages and setup the Parcl Labs API key](#1-import-required-packages-and-setup-the-parcl-labs-api-key)\n",
    "2. [Search for markets](#2-search-for-markets)\n",
    "3. [Get the data](#3-retrieve-the-data)\n",
    "4. [Initial data preparation](#4-initial-data-preparation)\n",
    "5. [Supply & demand skew](#5-supply--demand-skew)\n",
    "6. [New construction impact on supply](#6-new-construction-impact-on-supply)\n",
    "7. [Active supply price drops](#7-active-supply-price-drops)\n",
    "8. [Appreciation since COVID](#8-appreciation-since-covid)\n",
    "9. [Real time price check](#9-real-time-price-check)\n",
    "\n",
    "#### What will you create in this notebook?\n",
    "\n",
    "##### Understand changes in supply and Demand YoY\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/changes_supply_yoy_July_2024.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "##### Understand changes in Acquisitions and Dispositions YoY\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/changes_acquisitions_dispositions_yoy_May_2024_bar.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "##### Understanding inflection points in supply and demand\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/YoY Bar Supply Demand.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "##### Understanding shift in price cuts for on market inventory\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/inventory_price_reductions_July_2024.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "##### Understanding the impact of new construction for on market supply\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/changes_new_listings_new_construction_sept_2024.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "#### Prices since beginning of COVID-19 \n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/change_home_values_since_covid_July_2024.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "#### Need help getting started?\n",
    "\n",
    "As a reminder, you can get your Parcl Labs API key [here](https://dashboard.parcllabs.com/signup) to follow along.\n",
    "\n",
    "To run this immediately, you can use Google Colab. Remember, you must set your `PARCL_LABS_API_KEY`.\n",
    "\n",
    "Run in collab --> [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ParclLabs/parcllabs-cookbook/blob/main/examples/experimental/supply_and_demand/markets_that_could_disrupt.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import required packages and setup the Parcl Labs API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, install and/or upgrade to the latest verison of the Parcl Labs Python library\n",
    "%pip install --upgrade parcllabs nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "from parcllabs import ParclLabsClient\n",
    "from parcllabs.beta.charting.styling import SIZE_CONFIG\n",
    "from parcllabs.beta.ts_stats import TimeSeriesAnalysis\n",
    "from parcllabs.beta.charting.utils import create_labs_logo_dict\n",
    "from parcllabs.beta.charting.utils import (\n",
    "    create_labs_logo_dict,\n",
    "    save_figure,\n",
    "    )\n",
    "from parcllabs.beta.charting.styling import default_style_config as style_config\n",
    "\n",
    "\n",
    "client = ParclLabsClient(\n",
    "    api_key=os.environ.get('PARCL_LABS_API_KEY', \"<your Parcl Labs API key if not set as environment variable>\"), \n",
    "    limit=12, \n",
    "    turbo_mode=True # set turbo mode to True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Search for markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top 200 metro markets, sorted by total population in descending order\n",
    "metros = client.search.markets.retrieve(\n",
    "    sort_by='TOTAL_POPULATION',  # Sort by total population\n",
    "    sort_order='DESC',           # In descending order\n",
    "    location_type='CBSA',        # Location type set to Core Based Statistical Area (CBSA)\n",
    "    limit=200                    # Limit results to top 200 metros\n",
    ")\n",
    "\n",
    "# Retrieve national data for the United States to use as a benchmark\n",
    "us = client.search.markets.retrieve(\n",
    "    query='United States',  # Query for the United States as a whole\n",
    "    limit=1                 # Limit results to one (national-level data)\n",
    ")\n",
    "\n",
    "# Concatenate metro market data with national data for comparison\n",
    "markets = pd.concat([metros, us])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets move the PARCL_ID of our metros to a list so we can retrieve the data\n",
    "market_parcl_ids = markets['parcl_id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Retrieve the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve different datasets from the SDK endpoints.\n",
    "# Capturing weekly supply, demand, and price metrics for 200 metros across the country.\n",
    "\n",
    "# Lists to hold the data retrieved from each endpoint\n",
    "supply_list = []\n",
    "demand_list = []\n",
    "prices_list = []\n",
    "\n",
    "# Define the start date for supply and demand data\n",
    "start_date = '2022-09-01'\n",
    "\n",
    "# Iterate over each metro market ID, retrieving data for supply, demand, and prices\n",
    "for market in market_parcl_ids:\n",
    "    # Retrieve the supply (for-sale inventory) data for the market starting from the specified date\n",
    "    supply = client.for_sale_market_metrics.for_sale_inventory.retrieve(\n",
    "        parcl_ids=market,\n",
    "        start_date=start_date,\n",
    "    )\n",
    "    \n",
    "    # Retrieve the demand data (housing event counts) for the market starting from the specified date\n",
    "    demand = client.market_metrics.housing_event_counts.retrieve(\n",
    "        parcl_ids=market,\n",
    "        start_date=start_date,\n",
    "    )\n",
    "    \n",
    "    # Retrieve the price data (housing event prices) for the market starting from January 2019\n",
    "    prices = client.market_metrics.housing_event_prices.retrieve(\n",
    "        parcl_ids=market,\n",
    "        start_date='2019-01-01',  # Different start date to capture historical price trends\n",
    "    )\n",
    "    \n",
    "    # Append the retrieved data to their respective lists\n",
    "    supply_list.append(supply)\n",
    "    demand_list.append(demand)\n",
    "    prices_list.append(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the retrieved data lists into DataFrames\n",
    "# Concatenate the supply, demand, and prices data into their respective DataFrames\n",
    "supply_df = pd.concat(supply_list)\n",
    "demand_df = pd.concat(demand_list)\n",
    "prices_df = pd.concat(prices_list)\n",
    "\n",
    "# Output the length of each DataFrame to understand the volume of data retrieved\n",
    "print(f'Length of supply data: {len(supply_df)}, prices data: {len(prices_df)}, and demand data: {len(demand_df)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in each DataFrame to check for coverage across different markets\n",
    "print(f'There are {len(supply_df.parcl_id.unique())} unique parcl_ids in the supply data, '\n",
    "      f'{len(prices_df.parcl_id.unique())} unique parcl_ids in the prices data, and '\n",
    "      f'{len(demand_df.parcl_id.unique())} unique parcl_ids in the demand data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`supply_df` contains all the inventory available for sale for all our markets. `prices_df` contains information about the median price for sales, listingts and the standard deviation of the prices. `demand_df` contains information about the number of events that happened in the market.\n",
    "`demand_df` contains information about the number of events that happened in the market including new listings, new sales and new units offered for rent. This information constitutes the first step in our analysis, understanding supply and demand dynamics alongside price information.\n",
    "\n",
    "We also need information on price cuts and for that we will use the SDF specifically the `for_sale_market_metrics.for_sale_inventory_price_changes` method of our client. This endpoint will retrieve price cuts across all types of properties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data for price changes in inventory across markets\n",
    "price_changes_list = []  # List to store price change data for each market\n",
    "\n",
    "# Iterate over each metro market ID to retrieve price change data\n",
    "for market in market_parcl_ids:\n",
    "    # Retrieve price changes in inventory for the market starting from the specified date\n",
    "    price_changes = client.for_sale_market_metrics.for_sale_inventory_price_changes.retrieve(\n",
    "        parcl_ids=market,        # Specify the market by its parcl_id\n",
    "        start_date=start_date     # Use the same start date defined earlier for consistency\n",
    "    )\n",
    "    \n",
    "    # Append the retrieved price change data to the list\n",
    "    price_changes_list.append(price_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the list of price change data into a single DataFrame\n",
    "price_changes_df = pd.concat(price_changes_list)\n",
    "\n",
    "# Output the length of the price changes DataFrame to verify the amount of data retrieved\n",
    "print(f'Length of price changes data: {len(price_changes_df)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in the price changes DataFrame to ensure market coverage\n",
    "print(f'There are {len(price_changes_df.parcl_id.unique())} unique parcl_ids in the price changes data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables to also keep track\n",
    "#median_pct_price_change\n",
    "# median_days_bt_change\n",
    "#median_days_bt_change -- add percentage of inventory with price decrease as part of the endpoints. pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "demand.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data we can start our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Initial data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly supply and percentage of price drops\n",
    "# Note: Supply data is bi-weekly, and price changes are weekly, so we resample both to a monthly frequency\n",
    "\n",
    "supply_monthly = (\n",
    "    supply_df.copy(deep=True)  # Create a deep copy of the supply DataFrame to avoid modifying the original data\n",
    "    \n",
    "    # Merge with price_changes_df on 'parcl_id' and 'date' to include price drop data for each market\n",
    "    .merge(price_changes_df[['parcl_id', 'date', 'count_price_drop']], on=['parcl_id', 'date'])\n",
    "    \n",
    "    # Add new columns for percentage of price drops and resample dates to monthly\n",
    "    .assign(\n",
    "        pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory'],  # Calculate percentage of price drops out of total suply\n",
    "        date=lambda df: df['date'].dt.to_period('M').dt.to_timestamp()  # Convert the 'date' to monthly frequency\n",
    "    )\n",
    "    \n",
    "    # Group the data by 'parcl_id' and 'date' (now monthly) and calculate the median\n",
    "    .groupby(['parcl_id', 'date'])\n",
    "    .agg({\n",
    "        'for_sale_inventory': 'median',     # Calculate the median inventory for each market and month\n",
    "        'pct_price_drops': 'median'         # Calculate the median percentage of price drops\n",
    "    })\n",
    "    \n",
    "    # Reset the index to return a flat DataFrame\n",
    "    .reset_index()\n",
    "\n",
    "    # check what the mean of price drops is and the standard deviation, renamen them pct_price_drops_mean and pct_price_drops_std\n",
    "    # group by date and use the transform function to add these columns to the dataframe\n",
    "    .assign(\n",
    "        pct_price_drops_mean=lambda df: df.groupby('date')['pct_price_drops'].transform('mean'),\n",
    "        pct_price_drops_std=lambda df: df.groupby('date')['pct_price_drops'].transform('std')\n",
    "    )\n",
    "    # add a flag to signal which markets are above the mean, it should be 1 if true and 0 if false\n",
    "    .assign(\n",
    "        above_mean_price_drops_flag=lambda df: (df['pct_price_drops'] > df['pct_price_drops_mean']).astype(int)\n",
    "    )\n",
    "\n",
    ")\n",
    "\n",
    "# Output the length of the final monthly supply DataFrame to verify the amount of data\n",
    "print(f'Length of monthly supply data: {len(supply_monthly)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values in the monthly supply data to verify market coverage\n",
    "print(f'There are {len(supply_monthly.parcl_id.unique())} unique parcl_ids in the monthly supply data')\n",
    "\n",
    "# Display the first 10 rows of the monthly supply DataFrame for inspection\n",
    "supply_monthly.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the monthly supply data (with price drops) with the demand data\n",
    "# Note: Demand data is already in a monthly series, so we can directly join the datasets on 'parcl_id' and 'date'\n",
    "\n",
    "supply_demand_data = (\n",
    "    demand_df[['date', 'parcl_id', 'sales']]  # Select relevant columns from the demand DataFrame (date, parcl_id, and sales)\n",
    "    .merge(supply_monthly,                    # Merge with the supply_monthly DataFrame that includes supply and price drop data\n",
    "           on=['date', 'parcl_id'])           # Join on 'date' and 'parcl_id' to align data across markets and time periods\n",
    ")\n",
    "\n",
    "# Output the length of the combined supply and demand DataFrame to verify data consistency\n",
    "print(f'Length of supply_demand_data: {len(supply_demand_data)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values to check how many markets are covered in the merged dataset\n",
    "print(f'There are {len(supply_demand_data.parcl_id.unique())} unique parcl_ids in the supply_demand_data')\n",
    "\n",
    "# Display the combined supply and demand data for inspection\n",
    "supply_demand_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This new dataframe provides us with a snapshot of market status including the price cuts, share of inventory for sale with price cuts as well as sales activity. Next step involves calculating imbalances between supply and demand. The key idea is that with the data we have so far we can identify players with dwindling demand and price drop pressure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Supply & demand skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by 'parcl_id' and 'date' to ensure chronological order for percentage change calculations\n",
    "supply_demand_df_imbalances = (\n",
    "    supply_demand_data.copy(deep=True)  # Create a deep copy of the supply_demand_data DataFrame to avoid modifying the original data\n",
    "    .sort_values(['parcl_id', 'date'])  # Sort by 'parcl_id' and 'date'\n",
    "    \n",
    "    .assign(\n",
    "        # Calculate percentage change in 'sales' over 12 periods (1 year) for each 'parcl_id'\n",
    "        pct_change_demand=lambda df: df.groupby('parcl_id')['sales'].pct_change(periods=12),\n",
    "       \n",
    "        # Calculate percentage change in 'for_sale_inventory' over 12 periods for each 'parcl_id'\n",
    "        pct_change_supply=lambda df: df.groupby('parcl_id')['for_sale_inventory'].pct_change(periods=12),\n",
    "        \n",
    "        # Calculate a 3-month moving average of percentage change in demand ('pct_change_demand')\n",
    "        ma_pct_change_demand=lambda df: df.groupby('parcl_id')['pct_change_demand']\n",
    "                                           .transform(lambda x: x.rolling(window=3).mean()),\n",
    "        \n",
    "        # Calculate a 3-month moving average of percentage change in supply ('pct_change_supply')\n",
    "        ma_pct_change_supply=lambda df: df.groupby('parcl_id')['pct_change_supply']\n",
    "                                           .transform(lambda x: x.rolling(window=3).mean())\n",
    "        # Drop rows with missing values in the calculated columns\n",
    "        )\n",
    "    .dropna(subset=['pct_change_demand', 'pct_change_supply', 'ma_pct_change_demand', 'ma_pct_change_supply'])\n",
    "    \n",
    ")\n",
    "\n",
    "print(f'length of supply_demand_df_imbalances df is {len(supply_demand_df_imbalances)}')\n",
    "print(f'there are {len(supply_demand_df_imbalances.parcl_id.unique())} unique parcl_ids in the supply_demand_df_imbalances data')\n",
    "supply_demand_df_imbalances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check one metro\n",
    "supply_demand_df_imbalances.query('parcl_id == 2900475').tail(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the 'markets' DataFrame by extracting the state and cleaning the market names\n",
    "markets = (\n",
    "    markets.assign(\n",
    "        # Extract the state from the 'name' column by splitting on commas and hyphens, then standardizing it\n",
    "        state=lambda df: df['name'].apply(lambda x: x.split(',')[-1].strip().upper().split('-')[0]),\n",
    "\n",
    "        # Create a 'clean_name' by extracting the first part of 'name' and appending the state\n",
    "        clean_name=lambda df: df.apply(\n",
    "            lambda x: f\"{x['name'].split('-')[0].split(',')[0].strip()}, {x['state']}\", axis=1\n",
    "        )\n",
    "    )\n",
    "    # Replace 'United States Of America, UNITED STATES OF AMERICA' with 'USA'\n",
    "    .replace({'clean_name': {'United States Of America, UNITED STATES OF AMERICA': 'USA'}})\n",
    ")\n",
    "\n",
    "# Display the cleaned 'markets' DataFrame with the extracted state and cleaned market names\n",
    "markets.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the supply_demand_imbalance DataFrame to get data for the most recent date,\n",
    "# merge with the 'markets' DataFrame, and filter based on specific conditions.\n",
    "\n",
    "# get latest month of imbalanced data\n",
    "supply_demand_imbalance_last = (\n",
    "    supply_demand_df_imbalances\n",
    "    .loc[lambda df: df['date'] == df['date'].max()]  # Filter for the most recent date\n",
    "    .merge(markets[['parcl_id', 'clean_name', 'state']], on='parcl_id')  # Merge with 'markets' to add 'clean_name' and 'state'\n",
    ")\n",
    "\n",
    "# get the the US market\n",
    "supply_demand_imbalance_last_us = supply_demand_imbalance_last.loc[\n",
    "\n",
    "    # filter suply and demand to get the USA market, we defined the `us` dataframe earlier when pulling data from the markets\n",
    "    supply_demand_imbalance_last['parcl_id'] == us['parcl_id'].values[0]\n",
    "]\n",
    "\n",
    "# Further filter based on sales, inventory, and percentage change conditions\n",
    "supply_demand_imbalance_last_filtered = (\n",
    "    supply_demand_imbalance_last.loc[\n",
    "        (supply_demand_imbalance_last['sales'] > 500) & \n",
    "        (supply_demand_imbalance_last['for_sale_inventory'] > 500) & \n",
    "        (supply_demand_imbalance_last['ma_pct_change_demand'] < -0.1) & \n",
    "        (supply_demand_imbalance_last['ma_pct_change_supply'] > 0.2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Concatenate US-specific data with the filtered data\n",
    "supply_demand_imbalance_last = pd.concat([supply_demand_imbalance_last_us, supply_demand_imbalance_last_filtered])\n",
    "\n",
    "print(f'length of supply_demand_imbalance_last is {len(supply_demand_imbalance_last)}')\n",
    "print(f'there are {len(supply_demand_imbalance_last.parcl_id.unique())} unique parcl_ids in the supply_demand_imbalance_last data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this initial subset we identify a subset of 37 markets plus the USA that meet the criteria for further analysis as of July 2024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the filtered supply_demand_imbalance_last sorted by the largest change in demand\n",
    "supply_demand_imbalance_last.sort_values('ma_pct_change_demand', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to identify selected states\n",
    "target_states = {'NY', 'OH', 'FL'}\n",
    "supply_demand_imbalance_last['color_group'] = supply_demand_imbalance_last['state'].apply(\n",
    "    lambda x: 'NY, OH, FL' if x in target_states else 'Other')\n",
    "\n",
    "# Get the maximum date for the chart title\n",
    "chart_max_date = supply_demand_imbalance_last['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B, %Y')\n",
    "\n",
    "\n",
    "CHART_WIDTH = 1000\n",
    "CHART_HEIGHT = 800\n",
    "# Creating the scatter plot\n",
    "fig = px.scatter(\n",
    "    supply_demand_imbalance_last, \n",
    "    x='ma_pct_change_demand', \n",
    "    y='ma_pct_change_supply', \n",
    "    color='color_group',  # Use the new color_group column for color\n",
    "    hover_name='clean_name', \n",
    "    title=f'YoY Changes in Supply vs. Demand ({chart_max_date})',\n",
    "    color_discrete_map={'NY, OH, FL':'red' , 'Other': 'blue'},  # Customize colors,\n",
    "    text='clean_name'\n",
    ")\n",
    "\n",
    "fig.update_traces(\n",
    "    textposition='top center',\n",
    "    mode='markers+text'  # Ensure that both markers and text are displayed\n",
    ")\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    "    )\n",
    "\n",
    "# Update axes labels and layout to format as a square\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "     xaxis=dict(\n",
    "            title_text='YoY % Change Demand (Sales)',\n",
    "            showgrid=style_config['showgrid'],\n",
    "            gridwidth=style_config['gridwidth'],\n",
    "            gridcolor=style_config['grid_color'],\n",
    "            # tickangle=style_config['tick_angle'],\n",
    "            tickformat='.0%',\n",
    "            linecolor=style_config['line_color_axis'],\n",
    "            linewidth=style_config['linewidth'],\n",
    "            titlefont=style_config['title_font_axis']\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text='YoY % Change Supply',\n",
    "            showgrid=style_config['showgrid'],\n",
    "            gridwidth=style_config['gridwidth'],\n",
    "            gridcolor=style_config['grid_color'],\n",
    "            tickfont=style_config['axis_font'],\n",
    "            zeroline=False,\n",
    "            tickformat='.0%',\n",
    "            linecolor=style_config['line_color_axis'],\n",
    "            linewidth=style_config['linewidth'],\n",
    "            titlefont=style_config['title_font_axis']\n",
    "        ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    legend_title_text='',\n",
    "    autosize=False,\n",
    "    height=CHART_HEIGHT,\n",
    "    width=CHART_WIDTH,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    "    legend=dict(\n",
    "            x=style_config['legend_x'],\n",
    "            y=style_config['legend_y'],\n",
    "            xanchor=style_config['legend_xanchor'],\n",
    "            yanchor=style_config['legend_yanchor'],\n",
    "            font=style_config['legend_font'],\n",
    "            bgcolor='rgba(0, 0, 0, 0)'\n",
    "        ),\n",
    ")\n",
    "save_figure(fig, save_path='../../../images/changes_supply_yoy_July_2024.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture unique 'parcl_id' values for later analysis\n",
    "imbalanced_parcl_ids = supply_demand_imbalance_last['parcl_id'].unique().tolist()\n",
    "print(f'There were {len(imbalanced_parcl_ids)} unbalanced markets identified for further analysis.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `imbalanced_parcl_ids` list contain the `parcl_ids` of the markets that are identified as unbalanced based on the criteria we set. We can use these `parcl_ids` to retrieve more detailed data for these markets and perform further analysis. This is the first step of our algorithm.\n",
    "\n",
    "Lets visualize this trend using a barchart to understand changes in suply now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by supply percentage change\n",
    "supply_demand_imbalance_last = supply_demand_imbalance_last.sort_values(by='ma_pct_change_supply', ascending=True)\n",
    "\n",
    "chart_max_date = supply_demand_imbalance_last['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B, %Y')\n",
    "\n",
    "# Prepare the data for the bar chart\n",
    "data_for_bar = pd.melt(supply_demand_imbalance_last, id_vars=['clean_name'], \n",
    "                       value_vars=['ma_pct_change_demand', 'ma_pct_change_supply'], \n",
    "                       var_name='type', value_name='percent_change')\n",
    "data_for_bar['type'] = data_for_bar['type'].map({'ma_pct_change_demand': 'Demand', 'ma_pct_change_supply': 'Supply'})\n",
    "\n",
    "# Apply bold formatting and light blue color to markets ending with \"FL\"\n",
    "data_for_bar['clean_name'] = data_for_bar['clean_name'].apply(\n",
    "    lambda x: f\"<b style='color:red'>{x}</b>\" if x.endswith('FL') or x.endswith('NY') or x.endswith('OH') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar chart\n",
    "fig = px.bar(data_for_bar, \n",
    "             x='clean_name', \n",
    "             y='percent_change', \n",
    "             color='type', \n",
    "             barmode='relative', \n",
    "             title=f'YoY Change in Supply and Demand ({chart_max_date})',\n",
    "             labels={'percent_change': 'Percent Change', 'clean_name': 'Market'},\n",
    "             color_discrete_map={'Demand': 'red', 'Supply': 'green'})\n",
    "\n",
    "# Update the legend names\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'Demand':\n",
    "        trace.name = 'Demand (Sales)'\n",
    "    elif trace.name == 'Supply':\n",
    "        trace.name = 'Supply (Inventory)'\n",
    "\n",
    "# Define dimensions\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title_text='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis'],\n",
    "        tickfont=dict(size=style_config['axis_font']['size'], color=style_config['axis_font']['color']),\n",
    "        # showticklabels=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='Percent Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    legend_title_text='',\n",
    "    autosize=False,\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    "    legend=dict(\n",
    "        x=style_config['legend_x'],\n",
    "        y=style_config['legend_y'],\n",
    "        xanchor=style_config['legend_xanchor'],\n",
    "        yanchor=style_config['legend_yanchor'],\n",
    "        font=style_config['legend_font'],\n",
    "        bgcolor='rgba(0, 0, 0, 0)'\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_layout_image(create_labs_logo_dict())\n",
    "save_figure(fig, save_path='../../../images/changes_supply_yoy_July_2024_bar.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a csv\n",
    "#supply_demand_imbalance_last[['parcl_id', 'clean_name', 'date', 'pct_change_demand', 'pct_change_supply', 'ma_pct_change_demand', 'ma_pct_change_supply']].to_csv('supply_demand_shifts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investor Sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen markets with increased in supply we need to check what investor sentiment is. This could potentially signal that in addition to an increase in supply, a decrease in demand we also see pressure for investors.\n",
    "\n",
    "Particularly we will understand acquisition and disposition trends in the markets that registered supply and demand imbalances. We will query that information using the `investor_metrics.housing_event_counts` from our client. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve investor activity data (acquisitions and dispositions) for the markets of interest\n",
    "# We're interested in how investors are responding in these markets based on housing event counts\n",
    "\n",
    "investor_supply = client.investor_metrics.housing_event_counts.retrieve(\n",
    "    parcl_ids=imbalanced_parcl_ids, #supply_demand_imbalance_last['parcl_id'].unique().tolist()  # Get unique parcl_ids from the supply-demand imbalance data\n",
    "    start_date=start_date  # Use the predefined start date to align the data collection\n",
    ")\n",
    "\n",
    "# Sort the investor supply data by 'parcl_id' and 'date' for consistent analysis and plotting\n",
    "investor_supply = investor_supply.sort_values(['parcl_id', 'date'])\n",
    "\n",
    "# Output the length of the investor supply DataFrame to verify the amount of data retrieved\n",
    "print(f'Length of investor_supply data: {len(investor_supply)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values to verify market coverage\n",
    "print(f'There are {len(investor_supply.parcl_id.unique())} unique parcl_ids in the investor_supply data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now have access to the investor_supply data\n",
    "investor_supply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the investor supply data to analyze quarterly investor activity using the chain method\n",
    "quarterly = (\n",
    "    investor_supply.copy(deep=True)  # Create a deep copy of the investor_supply DataFrame to avoid modifying the original data\n",
    "    # Convert 'date' to quarterly periods\n",
    "    .assign(quarter=lambda df: df['date'].dt.to_period('Q').dt.to_timestamp())\n",
    "    \n",
    "    # Group by 'parcl_id' and 'quarter' and aggregate acquisitions and dispositions using sum\n",
    "    .groupby(['parcl_id', 'quarter'])\n",
    "    .agg(\n",
    "        acquisitions=('acquisitions', 'sum'),\n",
    "        dispositions=('dispositions', 'sum')\n",
    "    )\n",
    "    \n",
    "    # Reset the index to return a flat DataFrame\n",
    "    .reset_index()\n",
    "    \n",
    "    # Calculate net investor activity and its percentage relative to acquisitions\n",
    "    .assign(\n",
    "        net_investor_activity=lambda df: df['acquisitions'] - df['dispositions'],\n",
    "        net_investor_activity_pct=lambda df: df['net_investor_activity'] / df['acquisitions']    \n",
    "        )\n",
    "    # Calculate the net investor investor activity percentage relative to acquisitions using a moving average\n",
    "    # grouping by parcl_id and quarter, use the assign and groupby method and a moving average of 2 periods\n",
    "    .assign(\n",
    "        net_investor_activity_ma=lambda df: df.groupby('parcl_id')['net_investor_activity']\n",
    "                                           .transform(lambda x: x.rolling(window=2).mean())\n",
    "        )\n",
    ")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "quarterly.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage changes in acquisitions and dispositions\n",
    "# and merging the data with market information\n",
    "quarterly = (\n",
    "    quarterly\n",
    "    # Calculate percentage change in acquisitions over 4 quarters (1 year) for each 'parcl_id'\n",
    "    .assign(\n",
    "        pct_change_acquisitions=lambda df: df.groupby('parcl_id')['acquisitions'].pct_change(periods=4),\n",
    "        # Calculate percentage change in dispositions over 4 quarters (1 year) for each 'parcl_id'\n",
    "        pct_change_dispositions=lambda df: df.groupby('parcl_id')['dispositions'].pct_change(periods=4),\n",
    "        # Calculate net investor activity percentage relative to acquisitions compare to a year before\n",
    "        pct_change_net_investor_activity=lambda df: \n",
    "            df.groupby('parcl_id')['net_investor_activity'].pct_change(periods=4)\n",
    "    )\n",
    "    # now calculate the moving average  of \n",
    "    # Merge with the 'markets' DataFrame to add market name and state information based on 'parcl_id'\n",
    "    .merge(markets[['parcl_id', 'clean_name', 'state']], on='parcl_id')\n",
    ")\n",
    "\n",
    "# Display the final quarterly data with\n",
    "quarterly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look at Buffalo\n",
    "quarterly.query('parcl_id==2899645')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the last full quarter's data and sort by net investor activity percentage\n",
    "quarterly_max = (\n",
    "    quarterly\n",
    "    # Filter for the most recent quarter for which we have more data \n",
    "    .loc[quarterly['quarter'] == '2024-04-01']\n",
    "    # Sort by 'net_investor_activity_pct' in ascending order to identify markets with the least or most activity\n",
    "    .sort_values('pct_change_acquisitions', ascending=True)\n",
    "    # Calculate the mean of the pct_change in dispositions\n",
    "    .assign(\n",
    "        pct_change_acq_mean=lambda df: df.groupby('quarter')['pct_change_acquisitions'].transform('mean'),\n",
    "        pct_change_net_inv_actity_mean=lambda df: df.groupby('quarter')['pct_change_net_investor_activity'].transform('mean')\n",
    "    )\n",
    "    # add flag if pct_change_dispositions is above the mean\n",
    "    .assign(\n",
    "        below_mean_acq_flag=lambda df: (df['pct_change_acquisitions'] < df['pct_change_acq_mean']).astype(int),\n",
    "        below_net_inv_actity_flag=lambda df: (df['pct_change_net_investor_activity'] < df['pct_change_net_inv_actity_mean']).astype(int)\n",
    "    )\n",
    "\n",
    ")\n",
    "# Display the filtered and sorted data for the last full quarter\n",
    "quarterly_max.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many markets are below the mean\n",
    "print(len(quarterly_max.query('below_mean_acq_flag == 1')))\n",
    "print(len(quarterly_max.query('below_net_inv_actity_flag == 1')))\n",
    "print(len(quarterly_max.query('below_mean_acq_flag == 1 and below_net_inv_actity_flag == 1')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We identified 20 markets with below-average investor acquisition activity in the most recent quarter (Q2 of 2024) when compared to the same period a year ago. This means what conditions in terms of aqcuisitions are also deteriorating as there is a decrease in investor activity in this markets.\n",
    "\n",
    "We can visualize both changes to the supply and demand in these markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by disposition percentage change and prepare for bar chart visualization\n",
    "filter = True\n",
    "data_for_bar = (\n",
    "    quarterly_max\n",
    "    .query(\"below_mean_acq_flag == 1 and below_net_inv_actity_flag == 1\")\n",
    "    \n",
    "    # Sort the data by percentage change in dispositions, in ascending order\n",
    "    .sort_values(by='pct_change_dispositions', ascending=True)\n",
    "    \n",
    "    # Extract and format the most recent date for chart labels\n",
    "    .assign(\n",
    "        chart_max_date=lambda df: supply_demand_imbalance_last['date'].max().strftime('%B, %Y')\n",
    "    )\n",
    "    \n",
    "    # Prepare the data for the bar chart using pd.melt to transform columns into rows\n",
    "    .pipe(lambda df: pd.melt(df, \n",
    "                             id_vars=['clean_name'], \n",
    "                             value_vars=['pct_change_acquisitions', 'pct_change_dispositions'], \n",
    "                             var_name='type', \n",
    "                             value_name='percent_change'))\n",
    "    \n",
    "    # Map the 'type' column values for clarity in the chart (Acquisitions vs. Dispositions)\n",
    "    .assign(\n",
    "        type=lambda df: df['type'].map({\n",
    "            'pct_change_acquisitions': 'Acquisitions', \n",
    "            'pct_change_dispositions': 'Dispositions'\n",
    "        })\n",
    "    )\n",
    "    .sort_values(by='percent_change', ascending=True)\n",
    "    # Apply bold and red text formatting to market names ending with \"FL\"\n",
    "    .assign(\n",
    "        clean_name=lambda df: df['clean_name'].apply(\n",
    "            lambda x: f\"<b style='color:red'>{x}</b>\" if x.endswith('FL') or x.endswith('OH') or x.endswith('NY') else x\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the bar chart\n",
    "fig = px.bar(data_for_bar, \n",
    "             x='clean_name', \n",
    "             y='percent_change', \n",
    "             color='type', \n",
    "             barmode='relative', \n",
    "             title=f'YoY Change in Investor Acquisitions and Dispositions ({chart_max_date})',\n",
    "             labels={'percent_change': 'Percent Change', 'clean_name': 'Market'},\n",
    "             color_discrete_map={'Demand': 'red', 'Supply': 'green'})\n",
    "\n",
    "# Update the legend names\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'Demand':\n",
    "        trace.name = 'Demand (Sales)'\n",
    "    elif trace.name == 'Supply':\n",
    "        trace.name = 'Supply (Inventory)'\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title_text='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis'],\n",
    "        tickfont=dict(size=style_config['axis_font']['size'], color=style_config['axis_font']['color']),\n",
    "        # showticklabels=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='Percent Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    legend_title_text='',\n",
    "    autosize=False,\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    "    legend=dict(\n",
    "        x=style_config['legend_x'],\n",
    "        y=style_config['legend_y'],\n",
    "        xanchor=style_config['legend_xanchor'],\n",
    "        yanchor=style_config['legend_yanchor'],\n",
    "        font=style_config['legend_font'],\n",
    "        bgcolor='rgba(0, 0, 0, 0)'\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_layout_image(create_labs_logo_dict())\n",
    "save_figure(fig, save_path='../../../images/changes_acquisitions_dispositions_yoy_May_2024_bar.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "investor_dropoff_parcl_ids = quarterly_max.query(\"below_mean_acq_flag == 1 and below_net_inv_actity_flag == 1\")['parcl_id'].unique().tolist()\n",
    "print(f'There were {len(investor_dropoff_parcl_ids)} markets with investor drop-off identified for further analysis.')\n",
    "#imbalanced_parcl_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. New construction impact on supply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the new construction impact on supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need  to iterated to get the housing event counts \n",
    "new_listings_list = []\n",
    "nc_list = []\n",
    "\n",
    "for market in imbalanced_parcl_ids:\n",
    "    new_listings = client.market_metrics.housing_event_counts.retrieve(\n",
    "        parcl_ids=market,\n",
    "        limit =1 # limit to 1 to get the most recent data\n",
    "    )\n",
    "    new_listings_list.append(new_listings)\n",
    "    \n",
    "    nc = client.new_construction_metrics.housing_event_counts.retrieve(\n",
    "        parcl_ids=market,\n",
    "        limit =1 # limit to 1 to get the most recent data\n",
    "    )\n",
    "    nc_list.append(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the list of data into a single dataframe for new listings and new construction\n",
    "new_listings = pd.concat(new_listings_list)\n",
    "new_listings_construction = pd.concat(nc_list)\n",
    "\n",
    "# Rename the columns to distinguish between new listings and new construction data\n",
    "new_listings_construction = (\n",
    "    new_listings_construction\n",
    "    .rename(columns={'new_listings_for_sale': 'new_construction_new_listings_for_sale'})\n",
    "    )\n",
    "\n",
    "# Output the length of the new listings data to confirm the amount of data retrieved\n",
    "print(f'Length of new_listings data: {len(new_listings)} and nc data: {len(nc)}')\n",
    "\n",
    "# Output the number of unique 'parcl_id' values to verify coverage across different markets\n",
    "print(f'There are {len(new_listings.parcl_id.unique())} unique parcl_ids in the new_listings data and'\n",
    "      f' {len(nc.parcl_id.unique())} unique parcl_ids in the nc data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look at the data\n",
    "new_listings_construction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge new listings data with new construction listings, calculate percentage, and merge with market names\n",
    "new_listings_all = (\n",
    "    new_listings\n",
    "    # Merge new listings with new construction data on 'parcl_id'\n",
    "    .merge(new_listings_construction[['parcl_id', 'new_construction_new_listings_for_sale']], \n",
    "           on='parcl_id')\n",
    "    \n",
    "    # Calculate the percentage of new construction listings out of total new listings\n",
    "    .assign(\n",
    "        pct_new_construction=lambda x: x['new_construction_new_listings_for_sale'] / x['new_listings_for_sale']\n",
    "    )\n",
    "    \n",
    "    # Merge with the 'markets' DataFrame to add clean market names based on 'parcl_id'\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    "    \n",
    ")\n",
    "new_listings_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the final merged and calculated new listings data\n",
    "new_listings.head()\n",
    "print(len(new_listings), len(new_listings.parcl_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we use the market imbalance data we can filter the data to get the markets that are below the mean\n",
    "new_listings_all_filtered = new_listings_all.query('parcl_id in @investor_dropoff_parcl_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for the bar chart with sorting, melting, and formatting in one step\n",
    "data_for_bar = (\n",
    "    new_listings_all_filtered  # Filter for the most recent date\n",
    "    .sort_values('pct_new_construction', ascending=True)  # Sort by percentage of new construction\n",
    "    .assign(\n",
    "        chart_max_date=lambda df: df['date'].max().strftime('%B, %Y')  # Format the latest date\n",
    "    )\n",
    "    .pipe(\n",
    "        lambda df: pd.melt(df, id_vars=['clean_name'], \n",
    "                           value_vars=['pct_new_construction'], \n",
    "                           var_name='type', \n",
    "                           value_name='percentage')  # Reshape for bar chart\n",
    "    )\n",
    "    .assign(\n",
    "        clean_name=lambda df: df['clean_name'].apply(\n",
    "            lambda x: f\"<b style='color:red'>{x}</b>\" \n",
    "            if x.endswith('FL') or x.endswith('NY') or x.endswith('OH') else x  # Format FL markets\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the prepared data for the bar chart\n",
    "data_for_bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the stacked bar chart\n",
    "fig = px.bar(data_for_bar, \n",
    "             x='clean_name', \n",
    "             y='percentage', \n",
    "             color='type', \n",
    "             barmode='stack', \n",
    "             title=f'Percent of New Listings Coming from New Construction ({chart_max_date})',\n",
    "             labels={'percentage': 'Percentage', 'clean_name': 'Market'},\n",
    "             color_discrete_map={'New Construction': 'orange', 'Investors': 'blue'})\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "# Update the legend names\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'New Construction':\n",
    "        trace.name = 'New Construction'\n",
    "    elif trace.name == 'Investors':\n",
    "        trace.name = 'Investors'\n",
    "\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title_text='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis'],\n",
    "        tickfont=dict(size=style_config['axis_font']['size'], color=style_config['axis_font']['color']),\n",
    "        # showticklabels=False\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='% of New Inventory',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    legend_title_text='',\n",
    "    autosize=False,\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    title_font=dict(size=24),\n",
    "    xaxis_title_font=dict(size=18),\n",
    "    yaxis_title_font=dict(size=18),\n",
    "    legend_title_font=dict(size=14),\n",
    "    legend_font=dict(size=12),\n",
    "    legend=dict(\n",
    "        x=style_config['legend_x'],\n",
    "        y=style_config['legend_y'],\n",
    "        xanchor=style_config['legend_xanchor'],\n",
    "        yanchor=style_config['legend_yanchor'],\n",
    "        font=style_config['legend_font'],\n",
    "        bgcolor='rgba(0, 0, 0, 0)'\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig.add_layout_image(create_labs_logo_dict())\n",
    "save_figure(fig, save_path='../../../images/changes_new_listings_new_construction_Sept_2024.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data\n",
    "#new_listings[['parcl_id', 'clean_name', 'date', 'property_type', 'pct_new_construction']].to_csv('pct_new_construction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Active supply price drops\n",
    "\n",
    "Now within these skewed markets, which markets also are having price changes? These markets would now have not only a supply/demand skew but also a supply side that is demonstrating a willingness to sell, actively reducing prices. \n",
    "\n",
    "Let's look for markets where at least 25% of the inventory is experiencing price changes as measured by the moving average of the last 3 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 3-period rolling average of price drops, filter using query, and extract parcl_ids\n",
    "imbalanced_with_price_changes_data = (\n",
    "    supply_monthly\n",
    "    # Calculate the 3-month rolling average of price changes for each parcl_id\n",
    "    .assign(\n",
    "        ma_price_changes=lambda df: df.groupby('parcl_id')['pct_price_drops'].transform(lambda x: x.rolling(window=6).mean())\n",
    "    )\n",
    "    \n",
    "    # Filter for records where the rolling average of price changes is greater than 0.25 and date is '7/1/2024'\n",
    "    .query('ma_price_changes > 0.15 and date == \"7/1/2024\"')\n",
    "    \n",
    "    # Sort by the rolling average of price changes in descending order\n",
    "    .sort_values('ma_price_changes', ascending=False)\n",
    "    \n",
    "    # Further filter to include only imbalanced parcl_ids using query\n",
    "    .query('parcl_id in @imbalanced_parcl_ids')\n",
    "    # Further filter for investor drop-off markets\n",
    "    .query('parcl_id in @investor_dropoff_parcl_ids')\n",
    "    \n",
    ")\n",
    "\n",
    "# Display the final list of imbalanced parcl_ids with significant price changes\n",
    "print(f'There are {len(imbalanced_with_price_changes_data)} markets with significant price changes.')\n",
    "print(f'There are {len(imbalanced_with_price_changes_data[\"parcl_id\"].unique())} with significant price changes and distressed demand.')\n",
    "print(f'The parcl_ids with significant price changes are: {imbalanced_with_price_changes_data[\"parcl_id\"].unique()}')\n",
    "\n",
    "# Save the list of parcl_ids with significant price changes to a variable for further analysis\n",
    "imbalanced_with_price_changes_pids =  imbalanced_with_price_changes_data['parcl_id'].unique().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markets left\n",
    "markets.loc[markets['parcl_id'].isin(imbalanced_with_price_changes_pids)][['clean_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two lists before using in the query\n",
    "combined_parcl_ids = imbalanced_with_price_changes_pids + [5826765]\n",
    "\n",
    "# Clean and process price changes data, calculating percentage of price drops and merging relevant columns\n",
    "print(len(price_changes_df))\n",
    "price_changes_skewed = (\n",
    "    price_changes_df\n",
    "    # Filter for relevant parcl_ids using the pre-combined list\n",
    "    .query('parcl_id in @combined_parcl_ids')\n",
    "    )\n",
    "print(len(price_changes_skewed))\n",
    "\n",
    "price_changes_skewed = (\n",
    "    price_changes_skewed\n",
    "    # Merge with the supply data on 'parcl_id' and 'date' to bring in for_sale_inventory\n",
    "    .merge(supply_df[['parcl_id', 'date', 'for_sale_inventory']], on=['parcl_id', 'date'])\n",
    "    \n",
    "    # Calculate the percentage of price drops relative to the for_sale_inventory\n",
    "    .assign(\n",
    "        pct_price_drops=lambda df: df['count_price_drop'] / df['for_sale_inventory']\n",
    "    )\n",
    "    \n",
    "    # Merge with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")\n",
    "\n",
    "# Display the unique parcl_ids in the processed price changes data\n",
    "len(price_changes_skewed['parcl_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify\n",
    "max_date_for_chart = price_changes_skewed['date'].max().date()\n",
    "max_date_for_chart = max_date_for_chart.strftime('%B %d, %Y')\n",
    "\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "# Create the line chart using Plotly Express\n",
    "fig = px.line(\n",
    "    price_changes_skewed,\n",
    "    x='date',\n",
    "    y='pct_price_drops',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_price_drops': '% of Inventory with Price Cuts'},\n",
    "    title=f'Percentage of Inventory with Price Reductions ({max_date_for_chart})'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(price_changes_skewed['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = price_changes_skewed[\n",
    "        (price_changes_skewed['clean_name'] == trace.name) &\n",
    "        (price_changes_skewed['date'] == latest_date)\n",
    "    ]['pct_price_drops'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Price Reductions',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path='../../../images/inventory_price_reductions_July_2024.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#price_changes_skewed = price_changes_skewed.merge(markets[['parcl_id', 'name']], on='parcl_id')\n",
    "#price_changes_skewed[['parcl_id', 'clean_name', 'date', 'pct_price_drops']].to_csv('pct_inventory_with_price_drops_weekly.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_changes_skewed.loc[price_changes_skewed['date']=='2024-07-22'].sort_values('pct_price_drops', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new subset with substantial price drops\n",
    "price_reduction_skewed_ids = price_changes_skewed['parcl_id'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Appreciation since COVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to most out of balance markets regarding supply and demand\n",
    "prices_need_to_give_back = prices_df.loc[prices_df['parcl_id'].isin(price_reduction_skewed_ids + [5826765])]\n",
    "print(f'There are {len(prices_need_to_give_back)} observations in the price history df.')\n",
    "print(f'There are {len(prices_need_to_give_back[\"parcl_id\"].unique())} with substantial price reductions and distressed demand.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will iterate over the parcl_ids to get the time series analysis and identify what\n",
    "# parcls need to give back the most from the beginning of the pandemic compared to the USA\n",
    "all_rows = []\n",
    "for pid in prices_need_to_give_back['parcl_id'].unique().tolist():\n",
    "    prices_skew_test = prices_need_to_give_back.loc[prices_need_to_give_back['parcl_id']==pid]\n",
    "    price_ts_analysis = TimeSeriesAnalysis(prices_skew_test, 'date', 'price_per_square_foot_median_sales', freq='M')\n",
    "    price_rate_of_change_stats = price_ts_analysis.calculate_changes(change_since_date='3/1/2020')\n",
    "    row = pd.json_normalize(price_rate_of_change_stats)\n",
    "    row['parcl_id'] = pid\n",
    "    all_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform time series analysis for each unique parcl_id in a chained and list comprehension style\n",
    "all_rows = (\n",
    "    prices_need_to_give_back['parcl_id'].unique()  # Get the unique parcl_ids\n",
    "    .tolist()  # Convert to a list for iteration\n",
    ")\n",
    "\n",
    "ts_analysis = pd.concat([\n",
    "    pd.json_normalize(\n",
    "        TimeSeriesAnalysis(\n",
    "            prices_need_to_give_back.query('parcl_id == @pid'),  # Filter for each parcl_id\n",
    "            'date', 'price_per_square_foot_median_sales', freq='M'  # Perform time series analysis\n",
    "        ).calculate_changes(change_since_date='3/1/2020')  # Calculate changes since 3/1/2020\n",
    "    ).assign(parcl_id=pid)  # Add the parcl_id to the result\n",
    "    for pid in all_rows  # Iterate over each unique parcl_id\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the length of ts_analysis and filter based on conditions, then print the length of the filtered DataFrame\n",
    "\n",
    "hf = (\n",
    "    ts_analysis\n",
    "    # Filter rows where peak_to_current.percent_change > -0.05 and change_since_date.percent_change > 0.5\n",
    "    .loc[\n",
    "        (ts_analysis['peak_to_current.percent_change'] > -0.05) & \n",
    "        (ts_analysis['change_since_date.percent_change'] > 0.5)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the lengths before and after the filtering\n",
    "print(len(ts_analysis))  # Original length\n",
    "print(len(hf))  # Filtered length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markets left\n",
    "# Merge filtered hf with markets DataFrame and retrieve the unique parcl_ids in a chained operation\n",
    "\n",
    "parcls_need_to_give_back_list = (\n",
    "    hf.loc[:, ['parcl_id', 'peak_to_current.percent_change', 'change_since_date.percent_change']]  # Use .loc[] for column selection\n",
    "    # Merge with markets DataFrame to add 'clean_name'\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    "    \n",
    "    # Extract unique parcl_id values and convert them to a list\n",
    "    .parcl_id.unique().tolist()\n",
    ")\n",
    "\n",
    "# parcls_need_to_give_back_list contains the unique parcl_ids after the merge3\n",
    "print(len(parcls_need_to_give_back_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter prices_df based on parcl_id from parcls_need_to_give_back_list and a specific parcl_id (5826765)\n",
    "\n",
    "prices_need_to_give_back_df = (\n",
    "    prices_df\n",
    "    # Filter rows where parcl_id is in the list plus the specific parcl_id 5826765\n",
    "    .loc[prices_df['parcl_id'].isin(parcls_need_to_give_back_list + [5826765])]\n",
    ")\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "prices_need_to_give_back_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show percent change relative to the first value after 2020-03-01\n",
    "\n",
    "chart = (\n",
    "    prices_need_to_give_back_df\n",
    "    # Filter rows where the date is greater than or equal to '2020-03-01'\n",
    "    .loc[lambda df: df['date'] >= '2020-03-01']\n",
    "    \n",
    "    # Sort the filtered data by date\n",
    "    .sort_values('date')\n",
    "    \n",
    "    # Select relevant columns for further processing\n",
    "    .loc[:, ['date', 'parcl_id', 'price_per_square_foot_median_sales']]\n",
    "    \n",
    "    # Merge the current data with the first value for each 'parcl_id' on '3/1/2020'\n",
    "    .merge(\n",
    "        prices_need_to_give_back_df\n",
    "        .loc[lambda df: df['date'] == '2020-03-01', ['parcl_id', 'price_per_square_foot_median_sales']]\n",
    "        .rename(columns={'price_per_square_foot_median_sales': 'start'}),\n",
    "        on='parcl_id'\n",
    "    )\n",
    "    \n",
    "    # Calculate the percentage change relative to the start value\n",
    "    .assign(\n",
    "        pct_change=lambda df: (df['price_per_square_foot_median_sales'] - df['start']) / df['start']\n",
    "    )\n",
    "    \n",
    "    # Merge the data with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")\n",
    "\n",
    "# Display the final chart DataFrame\n",
    "chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get max date\n",
    "chart_max_date = chart['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B, %Y')\n",
    "\n",
    "CHART_WIDTH = 1600\n",
    "CHART_HEIGHT = 800\n",
    "\n",
    "fig = px.line(\n",
    "    chart,\n",
    "    x='date',\n",
    "    y='pct_change',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_change': '% Change'},\n",
    "    title=f'% Change in Home Values since the Start of the Pandemic ({chart_max_date})'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(chart['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = chart[\n",
    "        (chart['clean_name'] == trace.name) &\n",
    "        (chart['date'] == latest_date)\n",
    "    ]['pct_change'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=CHART_WIDTH,\n",
    "    height=CHART_HEIGHT,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path='../../../images/change_home_values_since_covid_July_2024.png', \n",
    "            width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "#chart.to_csv('price_appreciation.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Real time price check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_markets = client.search.markets.retrieve(\n",
    "    sort_by='PRICEFEED_MARKET',\n",
    "    limit=100,\n",
    ")\n",
    "\n",
    "pf_ids = pf_markets.loc[pf_markets['parcl_id'].isin(parcls_need_to_give_back_list)]['parcl_id'].unique().tolist()\n",
    "pf_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markets left\n",
    "markets.loc[markets['parcl_id'].isin(pf_ids)][['clean_name', 'parcl_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = '2020-03-01'\n",
    "sales_price_feeds = client.price_feed.price_feed.retrieve(\n",
    "    parcl_ids=pf_ids,\n",
    "    start_date=START_DATE,\n",
    "    limit=1000,  # expand the limit to 1000, these are daily series\n",
    "    auto_paginate=True, # auto paginate to get all the data - WARNING: ~6k credits can be used in one parcl price feed. Change the START_DATE to a more recent date to reduce the number of credits used\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show percent change for sales price feeds relative to the first value after 2020-03-01\n",
    "\n",
    "chart_pf = (\n",
    "    sales_price_feeds\n",
    "    # Sort the data by date\n",
    "    .sort_values('date')\n",
    "    \n",
    "    # Select relevant columns for further processing\n",
    "    .loc[:, ['date', 'parcl_id', 'price_feed']]\n",
    "    \n",
    "    # Merge the current data with the first value for each 'parcl_id' on '3/1/2020'\n",
    "    .merge(\n",
    "        sales_price_feeds\n",
    "        .loc[lambda df: df['date'] == '2020-03-01', ['parcl_id', 'price_feed']]\n",
    "        .rename(columns={'price_feed': 'start'}),\n",
    "        on='parcl_id'\n",
    "    )\n",
    "    \n",
    "    # Calculate the percentage change relative to the start value\n",
    "    .assign(\n",
    "        pct_change=lambda df: (df['price_feed'] - df['start']) / df['start']\n",
    "    )\n",
    "    \n",
    "    # Merge the data with the markets DataFrame to add clean market names\n",
    "    .merge(markets[['parcl_id', 'clean_name']], on='parcl_id')\n",
    ")\n",
    "\n",
    "# Display the final chart_pf DataFrame\n",
    "chart_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define names for the chart\n",
    "chart_pf[['clean_name', 'parcl_id']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create chart\n",
    "chart_max_date = chart_pf['date'].max()\n",
    "chart_max_date = chart_max_date.strftime('%B %d, %Y')\n",
    "\n",
    "fig = px.line(\n",
    "    chart_pf,\n",
    "    x='date',\n",
    "    y='pct_change',\n",
    "    color='clean_name',\n",
    "    line_group='clean_name',\n",
    "    labels={'pct_change': '% Change'},\n",
    "    title=f'% Change in Home Values since the Start of the Pandemic ({chart_max_date})'\n",
    ")\n",
    "\n",
    "# Update traces to apply specific styles\n",
    "for trace in fig.data:\n",
    "    if trace.name == 'USA':\n",
    "        trace.update(\n",
    "            line=dict(color='red', width=4),\n",
    "            opacity=1\n",
    "        )\n",
    "    else:\n",
    "        trace.update(\n",
    "            line=dict(color='lightblue', dash='dash', width=2),\n",
    "            opacity=0.8\n",
    "        )\n",
    "    # Remove text annotations from traces\n",
    "    trace.update(\n",
    "        mode='lines'\n",
    "    )\n",
    "\n",
    "# Find the latest date in the dataset\n",
    "latest_date = max(chart_pf['date'])\n",
    "\n",
    "# Add annotations for each line on the far right\n",
    "annotations = []\n",
    "y_positions = []\n",
    "\n",
    "for trace in fig.data:\n",
    "    # Get the last y-value for each clean_name\n",
    "    last_y_value = chart_pf[\n",
    "        (chart_pf['clean_name'] == trace.name) &\n",
    "        (chart_pf['date'] == latest_date)\n",
    "    ]['pct_change'].values[0]\n",
    "    \n",
    "    # Only add the annotation if it doesn't overlap with existing annotations\n",
    "    if not any(abs(last_y_value - y) < 0.02 for y in y_positions):  # Adjust threshold as needed\n",
    "        annotations.append(dict(\n",
    "            x=latest_date,\n",
    "            y=last_y_value,\n",
    "            xref='x',\n",
    "            yref='y',\n",
    "            text=trace.name,\n",
    "            showarrow=False,\n",
    "            xanchor='left',\n",
    "            font=dict(size=12)  # Adjust the font size if needed\n",
    "        ))\n",
    "        y_positions.append(last_y_value)\n",
    "\n",
    "fig.add_layout_image(\n",
    "        create_labs_logo_dict()\n",
    ")\n",
    "\n",
    "# Update layout for axes, title, and other styling\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    xaxis=dict(\n",
    "        title='',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        # tickangle=style_config['tick_angle'],\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='% Change',\n",
    "        showgrid=style_config['showgrid'],\n",
    "        gridwidth=style_config['gridwidth'],\n",
    "        gridcolor=style_config['grid_color'],\n",
    "        tickfont=style_config['axis_font'],\n",
    "        zeroline=False,\n",
    "        tickformat='.0%',\n",
    "        linecolor=style_config['line_color_axis'],\n",
    "        linewidth=style_config['linewidth'],\n",
    "        titlefont=style_config['title_font_axis']\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],\n",
    "    paper_bgcolor=style_config['background_color'],\n",
    "    font=dict(color=style_config['font_color']),\n",
    "    showlegend=False,  # Remove the legend\n",
    "    margin=dict(l=40, r=40, t=80, b=40),\n",
    "    title={\n",
    "        'y': 0.98,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top',\n",
    "        'font': dict(size=24)\n",
    "    },\n",
    "    annotations=annotations  # Add annotations\n",
    ")\n",
    "save_figure(fig, save_path='../../../images/pricefeed_markets_distressed_since_covid_pf_July_2024.png',\n",
    "            width=CHART_WIDTH, height=CHART_WIDTH)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-spec-mjMMhwjp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
