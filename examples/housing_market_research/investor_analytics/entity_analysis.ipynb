{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k<center>\n",
    "<h1>Welcome to the Lab ðŸ¥¼ðŸ§ª</h1>\n",
    "</center>\n",
    "\n",
    "## How can I analyze the behavior and performance of major single family rental (SFR) entities across their portfolios using the Parcl Labs API?\n",
    "\n",
    "This notebook demonstrates how to use the Parcl Labs API to conduct in-depth analysis of large-scale SFR operators. By leveraging our entity-to-unit mapping and housing event data, you'll learn to:\n",
    "\n",
    "- Query and aggregate property data for specific SFR entities\n",
    "- Track portfolio changes through acquisition and disposition events\n",
    "- Analyze rental trends and performance metrics at scale\n",
    "- Implement comparative analysis between major market players\n",
    "\n",
    "We'll focus on the Phoenix metro market and two prominent SFR operators, but the methodology is applicable across Parcl Labsâ€™ 70,000+ available markets and all entities in ourÂ [events history endpoint](https://docs.parcllabs.com/reference/property).\n",
    "\n",
    "### What you will build\n",
    "In this notebook, we will:\n",
    "\n",
    "- Quantify entity-specific inventory\n",
    "- Calculate time-series data for acquisitions and dispositions\n",
    "- Extract and analyze rental event data\n",
    "- Compute and visualize key performance indicators\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/sfh_ownership_for_individual_entities.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "| Quarter | Total Acquisitions | Total Dispositions | Entity | Net  |\n",
    "|---------|--------------------|--------------------|--------|------|\n",
    "| 2020Q4  | 32.0               | 1.0                | AMH    | 31.0 |\n",
    "| 2021Q1  | 46.0               | 0.0                | AMH    | 46.0 |\n",
    "| 2021Q2  | 54.0               | 0.0                | AMH    | 54.0 |\n",
    "| 2021Q3  | 25.0               | 0.0                | AMH    | 25.0 |\n",
    "| 2021Q4  | 37.0               | 1.0                | AMH    | 36.0 |\n",
    "| 2022Q1  | 57.0               | 0.0                | AMH    | 57.0 |\n",
    "| 2022Q2  | 24.0               | 0.0                | AMH    | 24.0 |\n",
    "| 2022Q3  | 19.0               | 0.0                | AMH    | 19.0 |\n",
    "| 2022Q4  | 31.0               | 0.0                | AMH    | 31.0 |\n",
    "| 2023Q2  | 28.0               | 0.0                | AMH    | 28.0 |\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/acquisitions_vs_dispositions_amh_phoenix.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/acquisitions_vs_dispositions_tricon_phoenix.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/entity_monthly_rental_price_phoenix.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"../../../images/entity_total_rental_events_phoenix.png\" alt=\"Alt text\">\n",
    "</p>\n",
    "\n",
    "\n",
    "#### Need help getting started?\n",
    "\n",
    "As a reminder, you can get your Parcl Labs API keyÂ [here](https://dashboard.parcllabs.com/login)Â to follow along. \n",
    "\n",
    "Please note that you will need a paid account to access the full functionality demonstrated in this notebook. You can easily upgrade directly via your [API dashboard](https://dashboard.parcllabs.com/login).\n",
    "\n",
    "To run this notebook immediately, you can use Google Colab. \n",
    "\n",
    "Remember, you must set yourÂ `PARCL_LABS_API_KEY`Â in the Colab environment before executing the code.\n",
    "Run in Colab --> [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ParclLabs/parcllabs-cookbook/blob/main/examples/housing_market_research/investor_analytics/entity_analysis.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, install and/or upgrade to the latest verison of the Parcl Labs Python library\n",
    "%pip install --upgrade parcllabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing the required libraries, we need to load them and instantiate the Parcl Labs client. The client is a Python library designed to facilitate and optimize the user experience with the Parcl Labs API. It handles searching, retrieving, and formatting the data for us. \n",
    "\n",
    "To use the client, you need to have an `API_KEY`, which is available in your [dashboard](https://dashboard.parcllabs.com/). While you can enter your `API_KEY` directly, it is recommended to save it as an environment variable for better security. If you are using Colab, you can follow these [steps](https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from parcllabs import ParclLabsClient\n",
    "from parcllabs.beta.charting.utils import (\n",
    "    create_labs_logo_dict,\n",
    "    save_figure,\n",
    "    sort_chart_data\n",
    "    )\n",
    "from parcllabs.beta.charting.styling import default_style_config as style_config \n",
    "from parcllabs.beta.charting.styling import SIZE_CONFIG\n",
    "from parcllabs import ParclLabsClient\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "# Create a Parcl Labs client\n",
    "client = ParclLabsClient(\n",
    "    api_key=os.environ.get('PARCL_LABS_API_KEY', \"<your Parcl Labs API key if not set as environment variable>\"), \n",
    "    limit=10 # set default limit\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze the Phoenix metro market. To find the corresponding `parcl_id` for that market, we can use the `search.markets.retrieve` method of the client with the appropriate parameters. In this case, the main parameter defines the type of market we are looking for. For the Phoenix metro area, we set this value to \"CBSA,\" which is an abbreviation for Core-Based Statistical Area, the official term used by the Census Bureau.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for a specific market by name and type\n",
    "# In this case, we are going to search for Phoenix CBSA (Core Based Statistical Area)\n",
    "market = client.search.markets.retrieve(\n",
    "    query='phoenix',\n",
    "    location_type='CBSA',\n",
    ")\n",
    "\n",
    "# Get the name and parcl_id of the market\n",
    "market_name = market[\"name\"].iloc[0]\n",
    "market_parcl_id = market[\"parcl_id\"].iloc[0]\n",
    "print(f' The name of the market is {market_name} and the parcl_id is {market_parcl_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will identify properties owned by two different large SFR (Single-Family Rental) operators in Phoenix. To do this, we first need to identify which single-family homes they currently own using the `property.search.retrieve` method of the client. \n",
    "\n",
    "In a previous notebook, we covered all the details on how to narrow your search using the available parameters for this endpoint. You can find that notebook [here](https://github.com/ParclLabs/parcllabs-cookbook/blob/main/examples/getting_started/property_data_download.ipynb) if you need a refresher.\n",
    "\n",
    "For this example, we will focus on `Tricon` and `American Homes 4 Rent (AMH)`, two of the largest housing rental companies in the country. We will look at the Phoenix Metropolitan area (`parcl_id: 2900245`), one of the epicenters of institutional activity for large portfolios, and analyze their behavior in this market. We will start by identifying single-family homes currently owned by AMH, specifying the required parameters: `parcl_id`, `property_type`, and `current_entity_owner_name`. You will notice we have several commented-out parameters that could be used to further narrow our search. Feel free to uncomment and tailor the search to suit your needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the search parameters\n",
    "search_params_amh = {\n",
    "    'parcl_ids': [2900245],  # Required\n",
    "    'property_type': 'SINGLE_FAMILY',  # Required\n",
    "    'current_entity_owner_name': 'AMH',  # Specify one of the options or None\n",
    "    #'square_footage_min': 1000,\n",
    "    #'square_footage_max': 5000,\n",
    "    #'bedrooms_min': 2,\n",
    "    #'bedrooms_max': 4,\n",
    "    #'bathrooms_min': 2,\n",
    "    #'bathrooms_max': 3,\n",
    "    #'year_built_min': 1990,\n",
    "    #'year_built_max': 2023,\n",
    "    #'event_history_sale_flag': True,\n",
    "    #'event_history_rental_flag': False,\n",
    "    #'event_history_listing_flag': True,\n",
    "    #'current_new_construction_flag': False,\n",
    "    #'current_owner_occupied_flag': True,\n",
    "    #'current_investor_owned_flag': False\n",
    "}\n",
    "\n",
    "# We search for properties in the market we defined above using the parameters that are not commented out.\n",
    "# We can pass the search_params dictionary to the retrieve method to get the search results using **search_params\n",
    "amh_homes_phoenix = client.property.search.retrieve(**search_params_amh)\n",
    "\n",
    "print(f\"Found {len(amh_homes_phoenix)} properties matching the criteria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the same approach to get single-family homes owned by `Tricon`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now repeat for Tricon\n",
    "# Define the search parameters\n",
    "search_params_tricon = {\n",
    "    'parcl_ids': [2900245],  # Required\n",
    "    'property_type': 'SINGLE_FAMILY',  # Required\n",
    "    'current_entity_owner_name': 'TRICON',  # Specify one of the options or None\n",
    "    #'square_footage_min': 1000,\n",
    "    #'square_footage_max': 5000,\n",
    "    #'bedrooms_min': 2,\n",
    "    #'bedrooms_max': 4,\n",
    "    #'bathrooms_min': 2,\n",
    "    #'bathrooms_max': 3,\n",
    "    #'year_built_min': 1990,\n",
    "    #'year_built_max': 2023,\n",
    "    #'event_history_sale_flag': True,\n",
    "    #'event_history_rental_flag': False,\n",
    "    #'event_history_listing_flag': True,\n",
    "    #'current_new_construction_flag': False,\n",
    "    #'current_owner_occupied_flag': True,\n",
    "    #'current_investor_owned_flag': False\n",
    "}\n",
    "\n",
    "# We search for properties in the market we defined above using the parameters that are not commented out.\n",
    "# We can pass the search_params dictionary to the retrieve method to get the search results using **search_params\n",
    "tricon_homes_phoenix = client.property.search.retrieve(**search_params_tricon)\n",
    "\n",
    "print(f\"Found {len(tricon_homes_phoenix)} properties matching the criteria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the total number of properties owned by each entity in the market. We will use a bar chart to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes and group by the entity owner name\n",
    "total_home_stock = pd.concat([amh_homes_phoenix, tricon_homes_phoenix])\n",
    "\n",
    "# Group by 'current_entity_owner_name' to calculate the total number of units per entity\n",
    "df_melted = (total_home_stock\n",
    "             .groupby('current_entity_owner_name').size()\n",
    "             .reset_index(name='Total Units')  # Add the total units column\n",
    "             .rename(columns={'current_entity_owner_name': 'Entity_PF'})  # Rename the entity column for readability\n",
    "             .sort_values('Total Units', ascending=False)  # Sort by total units in descending order\n",
    "             )\n",
    "\n",
    "# Define custom colors for the chart\n",
    "colors = ['#142872', '#8a9cb7']  # Ensure these colors are distinct and accessible\n",
    "\n",
    "# Create the stacked bar chart using Plotly Express\n",
    "fig = px.bar(df_melted, \n",
    "             x='Total Units', \n",
    "             y='Entity_PF', \n",
    "             barmode='relative',  # Use relative barmode for better comparison\n",
    "             title=f'Total Units by Entity {market_name}',  # Correct the title text\n",
    "             color='Entity_PF',  # Differentiate entities by color\n",
    "             color_discrete_sequence=colors  # Apply custom colors\n",
    ")\n",
    "\n",
    "# Update trace properties\n",
    "fig.update_traces(marker=dict(line=dict(width=0)))  # Remove border lines from the bars\n",
    "\n",
    "# Customize the layout of the chart\n",
    "fig.update_layout(\n",
    "    margin=dict(l=40, r=40, t=100, b=40),  # Adjust margins for better fitting\n",
    "    showlegend=False,  # Hide the legend for simplicity\n",
    "    title={\n",
    "        'text': f'Total Units Owned by Large Entities in {market_name}'.upper(),  # Updated title for clarity\n",
    "        'y': 0.95,\n",
    "        'x': 0.5,\n",
    "        'xanchor': 'center',  # Center the title\n",
    "        'yanchor': 'top',\n",
    "        'font': style_config['title_font']  # Apply the custom font from style_config\n",
    "    },\n",
    "    xaxis=dict(\n",
    "        title_text='',  # No label for x-axis since it's self-explanatory\n",
    "        tickformat=',',  # Format large numbers with commas\n",
    "        showgrid=style_config['showgrid'],  # Grid visibility based on style_config\n",
    "        gridwidth=style_config['gridwidth'],  # Grid width from style_config\n",
    "        gridcolor=style_config['grid_color'],  # Grid color from style_config\n",
    "        linecolor=style_config['line_color_axis'],  # Axis line color\n",
    "        linewidth=style_config['linewidth'],  # Axis line width\n",
    "        titlefont=style_config['title_font_axis'],  # Axis title font from style_config\n",
    "        tickfont=dict(size=style_config['axis_font']['size'], color=style_config['axis_font']['color'])  # Tick font style\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title_text='Total Units in Portfolio',  # Y-axis title\n",
    "        showgrid=style_config['showgrid'],  # Grid visibility for y-axis\n",
    "        gridwidth=style_config['gridwidth'],  # Grid width for y-axis\n",
    "        gridcolor=style_config['grid_color'],  # Grid color for y-axis\n",
    "        tickfont=style_config['axis_font'],  # Tick font for y-axis\n",
    "        zeroline=False,  # Hide the zero line for cleaner visuals\n",
    "        tickformat=',',  # Format y-axis numbers with commas\n",
    "        linecolor=style_config['line_color_axis'],  # Y-axis line color\n",
    "        linewidth=style_config['linewidth'],  # Y-axis line width\n",
    "        titlefont=style_config['title_font_axis']  # Y-axis title font\n",
    "    ),\n",
    "    plot_bgcolor=style_config['background_color'],  # Background color from style_config\n",
    "    paper_bgcolor=style_config['background_color'],  # Paper color to match the chart's background\n",
    "    font=dict(color=style_config['font_color']),  # Set font color for the entire chart\n",
    "    legend_title_text='',  # Hide legend title as it's redundant\n",
    "    autosize=False,  # Disable auto-sizing to control dimensions manually\n",
    "    width=1600,  # Set chart width\n",
    "    height=800,  # Set chart height\n",
    "    title_font=dict(size=24),  # Set font size for the title\n",
    "    xaxis_title_font=dict(size=18),  # Font size for x-axis title\n",
    "    yaxis_title_font=dict(size=18),  # Font size for y-axis title\n",
    "    legend_title_font=dict(size=14),  # Font size for legend title (though it's hidden)\n",
    "    legend_font=dict(size=12),  # Font size for legend items\n",
    "    legend=dict(\n",
    "        x=style_config['legend_x'],  # X position for the legend\n",
    "        y=style_config['legend_y'],  # Y position for the legend\n",
    "        xanchor=style_config['legend_xanchor'],  # X anchor for the legend position\n",
    "        yanchor=style_config['legend_yanchor'],  # Y anchor for the legend position\n",
    "        font=style_config['legend_font'],  # Font settings for the legend\n",
    "        bgcolor='rgba(0, 0, 0, 0)'  # Transparent background for the legend\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add the Labs logo to the chart\n",
    "fig.add_layout_image(create_labs_logo_dict())  # Function to add the logo as an image to the chart\n",
    "\n",
    "# Save the chart to the images folder\n",
    "fig.write_image('../../../images/sfh_ownership_for_individual_entities.png')  # Make sure the path is correct\n",
    "\n",
    "# Display the chart\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the total stock is important and provides a good starting point for analysis, but we can do much more now that we have the `parcl_property_id` of all the properties owned by `AMH` and `Tricon`. We can start uncovering some of their activity by looking at the [property events endpoint](https://docs.parcllabs.com/reference/property_events_v1_property_event_history_post), which contains detailed information about properties, including listings, sales, and rentals.\n",
    "\n",
    "Let's get that information by putting all the `parcl_property_id` values in a list and passing that to the `property.events.retrieve` method of the client. We will focus on acquisitions and dispositions. To do this, we need to retrieve the full history of the properties currently owned by AMH and Tricon. We will start with AMH.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the parcl_property_ids from the search results into a list named search_results_ids_amh to retrieve the sale events \n",
    "# for those properties\n",
    "search_results_ids_amh = amh_homes_phoenix['parcl_property_id'].tolist()\n",
    "\n",
    "# Define the parameters to use in the search for property events. In this case, we are looking for all sale events \n",
    "# related to the properties, so we set the event_type as 'SALE'. We do not define a begin_date or end_date to capture \n",
    "# all available sale events.\n",
    "property_events_parameters_amh = {\n",
    "    'parcl_property_ids': search_results_ids_amh,  # List of property IDs to search\n",
    "    'event_type': 'SALE',  # Filter for sale events only\n",
    "     'start_date': '2019-01-01', # Filter for events starting from this date\n",
    "}\n",
    "\n",
    "# Call the client with the list of property IDs and the event_type as 'SALE' to retrieve the sale events\n",
    "# for these properties. We can pass the parameters dictionary to the retrieve method using **property_events_parameters_amh\n",
    "sale_events_amh = client.property.events.retrieve(\n",
    "    **property_events_parameters_amh\n",
    ")\n",
    "\n",
    "# Display the total number of sale events found and preview the first two records\n",
    "print(f\"Found {len(sale_events_amh)} events matching the criteria.\")\n",
    "print(sale_events_amh.head(2))  # Preview the first two sale events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the process for Tricon\n",
    "\n",
    "# Pass the parcl_property_ids from the search results into a list named search_results_ids_tricon \n",
    "# to retrieve the sale events for those properties\n",
    "search_results_ids_tricon = tricon_homes_phoenix['parcl_property_id'].tolist()\n",
    "\n",
    "# Define the parameters for the property events search. As with AMH, we are looking for all sale events,\n",
    "# so we set the event_type to 'SALE' and do not specify a begin_date or end_date to capture all sales.\n",
    "property_events_parameters_tricon = {\n",
    "    'parcl_property_ids': search_results_ids_tricon,  # List of Tricon property IDs\n",
    "    'event_type': 'SALE',  # Filter for sale events only\n",
    "    'start_date': '2019-01-01',  # Filter for events starting from this date\n",
    "}\n",
    "\n",
    "# Call the client with the list of property IDs and event_type as 'SALE' to retrieve the sale events for Tricon properties.\n",
    "# We pass the parameters dictionary using **property_events_parameters_tricon\n",
    "sale_events_tricon = client.property.events.retrieve(\n",
    "    **property_events_parameters_tricon\n",
    ")\n",
    "\n",
    "# Display the total number of sale events found and preview the first two records\n",
    "print(f\"Found {len(sale_events_tricon)} events matching the criteria.\")\n",
    "print(sale_events_tricon.head(2))  # Preview the first two sale events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The historical event data provides a solid starting point, but we need to modify our dataset to distinguish when one of the entities we are analyzing is purchasing a property and when they are disposing of it. We will utilize the `sale_index` field, which orders sales events chronologically. The overall approach for this analysis is as follows:\n",
    "\n",
    "* Sort the dataframe containing the sales event history in chronological order.\n",
    "* Create two new fields, `month` and `quarter`, to facilitate easier aggregation of totals.\n",
    "* Make a copy of the original dataframe, keeping the same columns, but rename them so we can track the two dataframes separately (you'll see why shortly).\n",
    "* Merge the copied dataframe with the original one on `parcl_property_id`.\n",
    "* Filter the merged dataframe to only include rows where the `sale_index` of one dataframe matches the next event in the other (`sale_index` + 1). This links the sales events, identifying the buyer and seller chronologically, and prevents double-counting.\n",
    "* Apply additional filters to identify when the seller is the entity we are analyzing, and when the buyer is that entity.\n",
    "* Finally, aggregate the results at a quarterly level to capture all acquisitions and dispositions.\n",
    "\n",
    "The code below implements these steps, wrapped in a function for easier reuse later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the function to return aggregated disposition and acquisitions aggregated by quarter\n",
    "def process_events(df, entity):\n",
    "    \"\"\"\n",
    "    This function processes sales event data by creating a dataframe that aligns\n",
    "    seller and buyer transactions, and applies custom logic for flagging disposition \n",
    "    and acquisition events based on the provided entity.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing sales event data.\n",
    "    entity (str): The entity name used for filtering and flagging.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Processed dataframe with buyer and seller events aligned and flags computed.\n",
    "    \"\"\"\n",
    "    # Step 1: Create 'month' and 'quarter' columns based on 'event_date'\n",
    "    df_events = (\n",
    "        df\n",
    "        .assign(\n",
    "            month=lambda x: pd.to_datetime(x['event_date']).dt.to_period('M'),   # Create month period from 'event_date'\n",
    "            quarter=lambda x: pd.to_datetime(x['event_date']).dt.to_period('Q')  # Create quarter period from 'event_date'\n",
    "        )\n",
    "        .loc[:, [\n",
    "            'parcl_property_id', 'sale_index', 'event_date', 'price', \n",
    "            'event_type', 'entity_owner_name', 'investor_flag', 'month', 'quarter'\n",
    "        ]]  # Select relevant columns\n",
    "        .sort_values(['parcl_property_id', 'sale_index'], ascending=[True, True])  # Sort by 'parcl_property_id' and 'sale_index'\n",
    "    )\n",
    "\n",
    "    df_events = (\n",
    "        df\n",
    "        # Step 1: Create 'month' and 'quarter' columns based on the 'event_date'.\n",
    "        # This will make it easier to analyze data by time periods.\n",
    "        .assign(\n",
    "            month=lambda x: pd.to_datetime(x['event_date']).dt.to_period('M'),\n",
    "            quarter=lambda x: pd.to_datetime(x['event_date']).dt.to_period('Q')\n",
    "        )\n",
    "        .loc[:, ['parcl_property_id', 'sale_index', 'event_date', 'price', \n",
    "                 'event_type', 'entity_owner_name', 'investor_flag', 'month', 'quarter'\n",
    "                 ]]\n",
    "        .sort_values(['parcl_property_id', 'sale_index'], ascending=[True, True])   \n",
    "        )\n",
    "    # Step 2: Prepare the next event data for buyer-side\n",
    "    next_event_df = (\n",
    "        df_events\n",
    "        .pipe(lambda df: (\n",
    "            df.rename(columns={\n",
    "                'event_date': 'next_event_date',\n",
    "                'price': 'next_price',\n",
    "                'event_type': 'next_event_type',\n",
    "                'month': 'next_month',\n",
    "                'quarter': 'next_quarter',\n",
    "                'sale_index': 'next_sale_index',\n",
    "                })\n",
    "            )\n",
    "            )\n",
    "        )\n",
    "    # Step 3: Merge the original dataframe with the next event dataframe\n",
    "    results = (\n",
    "        df_events\n",
    "        .merge(\n",
    "            next_event_df,                                # Merge seller and buyer data\n",
    "            on='parcl_property_id',                       # Merge on 'parcl_property_id'\n",
    "            suffixes=('_seller', '_buyer')                # Use suffixes to distinguish seller and buyer columns\n",
    "        )\n",
    "        # Step 4: Filter the cases where the sale event is the next in sequence\n",
    "        .query('(sale_index == next_sale_index - 1) or (sale_index == 1 and next_sale_index == 1)')\n",
    "        \n",
    "        # Step 5: Calculate the number of days between sales events\n",
    "        .assign(days_between_sales=lambda x: (pd.to_datetime(x['next_event_date']) - pd.to_datetime(x['event_date'])).dt.days)\n",
    "    )\n",
    "    \n",
    "    # Step 6: Flag disposition for the entity\n",
    "    results['flag_disposition_entity'] = np.where(\n",
    "        # check for the first condition entity seller and buyer are the same and the sale index and next sale index is 1\n",
    "        ((results['entity_owner_name_seller'] == results['entity_owner_name_buyer']) & (results['sale_index'] == results['next_sale_index']))\n",
    "        # also check if the entity owner name is not entity\n",
    "        | (results['entity_owner_name_seller'] != entity),\n",
    "        # if results are true then set the flag to 1 else set it to nan\n",
    "        np.nan,\n",
    "        1\n",
    "        )\n",
    "        \n",
    "    # Step 7: Flag acquisition for the entity based on sale time difference\n",
    "    results['flag_acquisition_entity'] = np.where(\n",
    "        (results['days_between_sales']<30 & (results['entity_owner_name_seller']== entity) & (results['entity_owner_name_buyer'] != entity)),\n",
    "        np.nan,\n",
    "        np.where(results['entity_owner_name_buyer']== entity,1, np.nan)\n",
    "        )\n",
    "\n",
    "    # Step 8: Aggregate acquisitions and dispositions by quarter\n",
    "    final_df = (\n",
    "        results\n",
    "        .groupby('quarter')  # Group by quarter\n",
    "        .agg(\n",
    "            total_acquisitions=('flag_acquisition_entity', 'sum'),  # Rename acquisition column\n",
    "            total_dispositions=('flag_disposition_entity', 'sum')   # Rename disposition column\n",
    "        )\n",
    "        .reset_index()  # Reset index to make 'quarter' a column\n",
    "    )\n",
    "    \n",
    "    # Step 9: Add the entity name as a new column\n",
    "    final_df['entity'] = entity\n",
    "    # Step 10: Add net column to calculate the net acquisitions\n",
    "    final_df['net'] = final_df['total_acquisitions'] - final_df['total_dispositions']\n",
    "    \n",
    "    return final_df  # Return the finnal dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process acquisition and disposition events for American Homes 4 Rent (AMH)*\n",
    "# This section applies our previously defined function to analyze AMH's portfolio changes*acquisitions_dispositions_amh = process_events(sale_events_amh, 'AMH')\n",
    "acquisitions_dispositions_amh = process_events(sale_events_amh, 'AMH')\n",
    "acquisitions_dispositions_amh.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for Tricon\n",
    "acquisitions_dispositions_tricon = process_events(sale_events_tricon, 'TRICON')\n",
    "acquisitions_dispositions_tricon.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to create the acquisitions and dispositions chart\n",
    "def create_acq_disp_chart(df, path = None, market_name=market_name):\n",
    "    # Convert Period to string for Plotly compatibility\n",
    "    df['quarter'] = df['quarter'].astype(str)\n",
    "\n",
    "    CHART_HEIGHT=950\n",
    "    CHART_WIDTH=1800\n",
    "\n",
    "    # Create subplot with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    # Add trace for Acquisitions\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df['quarter'],\n",
    "            y=df['total_acquisitions'],\n",
    "            name=\"Acquisitions\",\n",
    "            marker_color=style_config[\"bar1_color\"]\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    # Add trace for Dispositions (negative values)\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=df['quarter'],\n",
    "            y=-df['total_dispositions'],\n",
    "            name=\"Dispositions\",\n",
    "            marker_color=\" #99ddff\"\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    # Calculate y-axis ranges\n",
    "    y_max = max(df['total_acquisitions'].max(), df['total_dispositions'].max()) * 1.15\n",
    "    y_min = -y_max\n",
    "    y_range = y_max - y_min\n",
    "\n",
    "    # Compress net effect range\n",
    "    net_max = max(abs(df['net'].max()), abs(df['net'].min()))\n",
    "    compression_factor = 0.6  # Adjust this value to change compression\n",
    "    net_range = y_range * compression_factor\n",
    "    net_scale = net_range / (2 * net_max)\n",
    "\n",
    "    # Scale net effect values\n",
    "    scaled_net = df['net'] * net_scale\n",
    "\n",
    "    # Add trace for Net Effect\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df['quarter'],\n",
    "            y=scaled_net,\n",
    "            mode='lines+markers+text',\n",
    "            name=\"Net Effect\",\n",
    "            line=dict(color='#FCC054', width=3),\n",
    "            marker=dict(size=8, color='#FCC054'),\n",
    "            text=df['net'].round(2),\n",
    "            textposition='top center',\n",
    "            textfont=dict(color='white'),\n",
    "            hovertemplate='%{x}<br>Net: %{text:.2f}<extra></extra>'\n",
    "        ),\n",
    "        secondary_y=False,\n",
    "    )\n",
    "\n",
    "    # Update layout for dark mode and styling\n",
    "    title_text = f\"Investor Acquisitions, Dispositions and Net Effect\".upper()\n",
    "    if market_name:\n",
    "        title_text = f\"Acquisitions vs Dispositions For {df['entity'].iloc[0]}: {market_name}\".upper()\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': title_text, # <br><span style='font-size: 16px; font-style: italic;'>{market_name}</span>\",\n",
    "            'y': 0.95,\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': dict(size=20, color='white')\n",
    "        },\n",
    "        font=dict(color='white', size=14),\n",
    "        plot_bgcolor=\"#000000\",\n",
    "        paper_bgcolor=\"#000000\",\n",
    "        height=CHART_HEIGHT,\n",
    "        width=CHART_WIDTH,\n",
    "        hovermode=\"x unified\",\n",
    "        barmode='relative',\n",
    "        margin=dict(l=0, r=0, t=0, b=0),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0,\n",
    "            xanchor=\"left\",\n",
    "            x=0\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Update x-axis\n",
    "    style_config[\"grid_color\"]\n",
    "    fig.update_xaxes(\n",
    "        title_text=\"\",\n",
    "        showgrid=True,\n",
    "        gridwidth=0.5,\n",
    "        gridcolor=style_config[\"grid_color\"],\n",
    "        tickangle=45,\n",
    "        dtick=\"M6\",\n",
    "        tickformat=',',\n",
    "        tickfont=dict(size=12),\n",
    "        linecolor='#132D59',\n",
    "        linewidth=2,\n",
    "        mirror=True,\n",
    "        title_font=dict(family=\"Inter\")\n",
    "    )\n",
    "\n",
    "    # Update y-axis (Acquisitions, Dispositions, and Net Effect)\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"Acquisitions vs. Dispositions\".upper(),\n",
    "        title_font=dict(size=10),\n",
    "        showgrid=True,\n",
    "        gridwidth=0.5,\n",
    "        gridcolor=style_config[\"grid_color\"],\n",
    "        tickfont=dict(size=12),\n",
    "        title_standoff=8,\n",
    "        linecolor=style_config[\"line_color_axis\"],\n",
    "        linewidth=2,\n",
    "        mirror=True,\n",
    "        range=[y_min + (y_min*0.1), y_max + (y_max*0.1)],\n",
    "        secondary_y=False\n",
    "    )\n",
    "\n",
    "    # Add Parcl Labs watermark\n",
    "    fig.add_layout_image(create_labs_logo_dict(xanchor =\"right\",yanchor = \"bottom\",x=0.93))\n",
    "\n",
    "\n",
    "    fig.update_traces(\n",
    "        textfont=dict(color='#FCC054'),\n",
    "        texttemplate='<span style=\"text-shadow: -1px -1px 0 #000, 1px -1px 0 #000, -1px 1px 0 #000, 1px 1px 0 #000;\">%{text:.0f}</span>',\n",
    "        selector=dict(type='scatter', mode='lines+markers+text')\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    # Save the figure if a save path is provided\n",
    "    save_figure(fig, save_path=path, width=CHART_WIDTH, height=CHART_HEIGHT)\n",
    "\n",
    "    # Display the figure\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the acquisition and disposition chart for AMH\n",
    "create_acq_disp_chart(acquisitions_dispositions_amh, \n",
    "                      path ='../../../images/acquisitions_vs_dispositions_amh_phoenix.png', \n",
    "                      market_name=market_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for Tricon\n",
    "create_acq_disp_chart(acquisitions_dispositions_tricon, \n",
    "                      path ='../../../images/acquisitions_vs_dispositions_tricon_phoenix.png', \n",
    "                      market_name=market_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having analyzed acquisition and disposition patterns for Tricon and AMH, we'll now examine their rental activities in the Phoenix market. This deeper analysis focuses on rental event data for properties owned by each entity.\n",
    "\n",
    "Key aspects of the upcoming analysis:\n",
    "\n",
    "1. Data source: Properties identified in previous steps (using parcl_property_ids)\n",
    "2. Event type: RENTAL\n",
    "3. Time range: 2023-01-01 to 2024-09-01\n",
    "4. Entities: AMH and Tricon (analyzed separately)\n",
    "\n",
    "This rental event data will enable us to:\n",
    "\n",
    "- Quantify rental listing frequency\n",
    "- Track rental price trends\n",
    "- Compare rental strategies between entities\n",
    "\n",
    "The following code retrieves and processes this data, preparing it for detailed rental market analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rental information for AMH\n",
    "# Pass the parcl_property_ids from the search results to a list named search_results_ids to retrieve the sale events \n",
    "# for those properties.\n",
    "search_results_ids_amh = amh_homes_phoenix['parcl_property_id'].tolist()\n",
    "\n",
    "# Define the parameters we want to use in the search for property events.\n",
    "property_events_parameters_amh = {\n",
    "    'parcl_property_ids': search_results_ids_amh,\n",
    "    'event_type': 'RENTAL',\n",
    "    'entity_owner_name': 'AMH',# Specify one of the options or None\n",
    "    'start_date': '2023-01-01',\n",
    "    'end_date': '2024-09-01',\n",
    "}\n",
    "\n",
    "# Call the client with the list of property ids and the event_type as 'SALE' to retrieve the sale events for the properties.\n",
    "# we can pass the search_params dictionary to the retrieve method to get the search results using **property_events_parameters\n",
    "rent_events_amh = client.property.events.retrieve(\n",
    "    **property_events_parameters_amh\n",
    "    )\n",
    "\n",
    "print(f\"Found {len(rent_events_amh)} events matching the criteria.\")\n",
    "print(rent_events_amh.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the parcl_property_ids from the search results to a list named search_results_ids to retrieve the sale events \n",
    "# for those properties.\n",
    "search_results_ids_tricon = tricon_homes_phoenix['parcl_property_id'].tolist()\n",
    "\n",
    "# Define the parameters we want to use in the search for property events.\n",
    "property_events_parameters_tricon = {\n",
    "    'parcl_property_ids': search_results_ids_tricon,\n",
    "    'event_type': 'RENTAL',\n",
    "    'entity_owner_name': 'TRICON',\n",
    "     # Specify one of the options or None\n",
    "    'start_date': '2023-01-01',\n",
    "    'end_date': '2024-09-01',\n",
    "}\n",
    "\n",
    "# Call the client with the list of property ids and the event_type as 'SALE' to retrieve the sale events for the properties.\n",
    "# we can pass the search_params dictionary to the retrieve method to get the search results using **property_events_parameters\n",
    "rent_events_tricon = client.property.events.retrieve(\n",
    "    **property_events_parameters_tricon\n",
    "    )\n",
    "\n",
    "print(f\"Found {len(rent_events_tricon)} events matching the criteria.\")\n",
    "print(rent_events_tricon.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate to monthly rental data\n",
    "monthly_aggregated_amh = (\n",
    "    rent_events_amh\n",
    "    .assign(\n",
    "        event_date=pd.to_datetime(rent_events_amh['event_date']),  # Convert 'event_date' to datetime\n",
    "        month=lambda df: df['event_date'].dt.to_period('M')  # Create 'month' column\n",
    "    )\n",
    "    .groupby(['month', 'entity_owner_name'])\n",
    "    .agg(\n",
    "        average_price=('price', 'mean'),  # Calculate average price per group\n",
    "        total_number_of_events=('event_name', 'size')  # Count the number of events per group\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Repat for Tricon\n",
    "monthly_aggregated_tricon = (\n",
    "    rent_events_tricon\n",
    "    .assign(\n",
    "        event_date=pd.to_datetime(rent_events_tricon['event_date']),  # Convert 'event_date' to datetime\n",
    "        month=lambda df: df['event_date'].dt.to_period('M')  # Create 'month' column\n",
    "    )\n",
    "    .groupby(['month', 'entity_owner_name'])\n",
    "    .agg(\n",
    "        average_price=('price', 'mean'),  # Calculate average price per group\n",
    "        total_number_of_events=('event_name', 'size')  # Count the number of events per group\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge both datasets and add suffixes\n",
    "monthly_aggregated = pd.merge(\n",
    "    monthly_aggregated_amh,\n",
    "    monthly_aggregated_tricon,\n",
    "    on='month',\n",
    "    how='left',\n",
    "    suffixes=('_amh', '_tricon')\n",
    ")\n",
    "monthly_aggregated['month'] = pd.PeriodIndex(monthly_aggregated['month'], freq='M')\n",
    "monthly_aggregated['month'] = monthly_aggregated['month'].dt.to_timestamp()\n",
    "monthly_aggregated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize those trends using a line chart to understand where the behavior of these two entities looks similar and where the are divergences. We will write this code as a function so you can re use it later without the need to type everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to create chart\n",
    "def create_two_series_line_chart(\n",
    "    title: str,\n",
    "    line_data_1: pd.DataFrame,\n",
    "    series_1: str,\n",
    "    line_data_2: pd.DataFrame,\n",
    "    series_2: str,\n",
    "    date_column: str = \"date\",\n",
    "    save_path: str = None,\n",
    "    yaxis_title: str = \"Y-Axis\",\n",
    "    height=675,\n",
    "    width=1200,\n",
    "    yaxis_prefix: str = '$',\n",
    "    style_config=None,  # Default is None, will fall back on default_style_config\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates a dual-series line chart with customizable style options and saves or displays it.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    title : str\n",
    "        The title of the chart.\n",
    "    line_data_1 : pd.DataFrame\n",
    "        The first dataframe containing the data for the first line series.\n",
    "    series_1 : str\n",
    "        The column name in line_data_1 representing the values for the first line series.\n",
    "    line_data_2 : pd.DataFrame\n",
    "        The second dataframe containing the data for the second line series.\n",
    "    series_2 : str\n",
    "        The column name in line_data_2 representing the values for the second line series.\n",
    "    date_column : str, optional\n",
    "        The name of the column in both dataframes representing dates (default is \"date\").\n",
    "    save_path : str, optional\n",
    "        The file path where the figure should be saved (default is None, meaning the chart won't be saved).\n",
    "    yaxis_title : str, optional\n",
    "        The title of the Y-axis (default is \"Y-Axis\").\n",
    "    height : int, optional\n",
    "        The height of the figure in pixels (default is 675).\n",
    "    width : int, optional\n",
    "        The width of the figure in pixels (default is 1200).\n",
    "    yaxis_prefix : str, optional\n",
    "        The prefix for the Y-axis labels (default is '$', used for financial data).\n",
    "    style_config : dict, optional\n",
    "        A dictionary for customizing the appearance of the chart, such as colors and fonts. \n",
    "        If None is provided, it uses the default_style_config (default is None).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    None\n",
    "        Displays the plot using Plotly and optionally saves the figure if a save_path is provided.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The chart will display two time series, each as a line plot with markers.\n",
    "    - The `style_config` allows for extensive customization, such as background colors, font settings, and marker styles.\n",
    "    \"\"\"\n",
    "    # If no style_config is provided, use the default\n",
    "    if style_config is None:\n",
    "        style_config = default_style_config\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Ensure the date column is in a datetime format (if it's not already)\n",
    "    line_data_1[date_column] = pd.to_datetime(line_data_1[date_column])\n",
    "    line_data_2[date_column] = pd.to_datetime(line_data_2[date_column])\n",
    "\n",
    "    # Add the first time series as a line plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=line_data_1[date_column],\n",
    "            y=line_data_1[series_1],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(\n",
    "                width=style_config[\"line_width\"],\n",
    "                color=style_config[\"line_color\"]\n",
    "            ),\n",
    "            marker=dict(\n",
    "                size=style_config[\"marker_size\"],\n",
    "                color=style_config[\"marker_color\"],\n",
    "                line=dict(width=1, color=style_config[\"marker_outline_color\"]),\n",
    "            ),\n",
    "            name=series_1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add the second time series as a line plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=line_data_2[date_column],\n",
    "            y=line_data_2[series_2],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(\n",
    "                width=style_config[\"line_width\"],\n",
    "                color=style_config[\"bar1_color\"]  # Using bar1_color for the second line\n",
    "            ),\n",
    "            marker=dict(\n",
    "                size=style_config[\"marker_size\"],\n",
    "                color=style_config[\"bar1_color\"],\n",
    "                line=dict(width=1, color=style_config[\"marker_outline_color\"]),\n",
    "            ),\n",
    "            name=series_2\n",
    "        )\n",
    "    )\n",
    "    style_config[\"title_font\"]['size']=20\n",
    "    # Update layout to match the styling conventions\n",
    "    fig.update_layout(\n",
    "        margin=dict(l=40, r=40, t=80, b=40),\n",
    "        height=height,\n",
    "        width=width,\n",
    "        title={\n",
    "            \"text\": title,\n",
    "            \"y\": 0.95,\n",
    "            \"x\": 0.5,\n",
    "            \"xanchor\": \"center\",\n",
    "            \"yanchor\": \"top\",\n",
    "            \"font\": style_config[\"title_font\"],\n",
    "            \n",
    "        },\n",
    "        plot_bgcolor=style_config[\"background_color\"],\n",
    "        paper_bgcolor=style_config[\"background_color\"],\n",
    "        font=dict(color=style_config[\"font_color\"]),\n",
    "        xaxis=dict(\n",
    "            title_text=\"\",\n",
    "            tickformat='%b %Y',  # Formatting for monthly data (e.g., Jan 2021)\n",
    "            dtick=\"M2\",  # Show every two months\n",
    "            showgrid=style_config[\"showgrid\"],\n",
    "            gridwidth=style_config[\"gridwidth\"],\n",
    "            gridcolor=style_config[\"grid_color\"],\n",
    "            tickangle=style_config[\"tick_angle\"],\n",
    "            tickfont=style_config[\"axis_font\"],\n",
    "            linecolor=style_config[\"line_color_axis\"],\n",
    "            linewidth=style_config[\"linewidth\"],\n",
    "            titlefont=style_config[\"title_font_axis\"],\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=yaxis_title,\n",
    "            showgrid=style_config[\"showgrid\"],\n",
    "            gridwidth=style_config[\"gridwidth\"],\n",
    "            gridcolor=style_config[\"grid_color\"],\n",
    "            tickfont=style_config[\"axis_font\"],\n",
    "            tickformat=yaxis_prefix,  # Format y-axis with comma for thousands\n",
    "            zeroline=False,\n",
    "            linecolor=style_config[\"line_color_axis\"],\n",
    "            linewidth=style_config[\"linewidth\"],\n",
    "            titlefont=style_config[\"title_font_axis\"],\n",
    "        ),\n",
    "        hovermode=\"x unified\",\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=style_config[\"hover_bg_color\"],\n",
    "            font_size=style_config[\"hover_font_size\"],\n",
    "            font_family=style_config[\"hover_font_family\"],\n",
    "            font_color=style_config[\"hover_font_color\"],\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=style_config[\"legend_x\"],\n",
    "            y=style_config[\"legend_y\"],\n",
    "            xanchor=style_config[\"legend_xanchor\"],\n",
    "            yanchor=style_config[\"legend_yanchor\"],\n",
    "            font=style_config[\"legend_font\"],\n",
    "            bgcolor=\"rgba(0, 0, 0, 0)\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add a logo to the chart (if applicable)\n",
    "    fig.add_layout_image(create_labs_logo_dict())\n",
    "\n",
    "    # Save the figure if a save path is provided\n",
    "    save_figure(fig, save_path=save_path, width=width, height=height)\n",
    "\n",
    "    # Show the figure\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example call to the function\n",
    "style_config['tick_prefix'] = ''\n",
    "create_two_series_line_chart(\n",
    "    title=f\"Average Monthly Rental Price Tricon and AMH in {market_name}\".upper(),\n",
    "    line_data_1=monthly_aggregated,\n",
    "    series_1=\"average_price_amh\",\n",
    "    line_data_2=monthly_aggregated,\n",
    "    series_2=\"average_price_tricon\",\n",
    "    date_column=\"month\",\n",
    "    yaxis_prefix='$,',\n",
    "    yaxis_title=\"Average Monthly Rental Price\",\n",
    "    height=SIZE_CONFIG['x']['height'],\n",
    "    width=SIZE_CONFIG['x']['width'],\n",
    "    style_config=style_config,\n",
    "    save_path='../../../images/entity_monthly_rental_price_phoenix.png'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Repeat for total rental events for AMH and Tricon\n",
    "style_config['tick_prefix'] = '$'\n",
    "create_two_series_line_chart(\n",
    "    title=f\"Total Monthly Rental Events AMH and Tricon in {market_name}\".upper(),\n",
    "    line_data_1=monthly_aggregated,\n",
    "    series_1=\"total_number_of_events_amh\",\n",
    "    line_data_2=monthly_aggregated,\n",
    "    series_2=\"total_number_of_events_tricon\",\n",
    "    date_column=\"month\",\n",
    "    yaxis_prefix=',',\n",
    "    yaxis_title=\"Total Monthly Rental Events\",\n",
    "    height=SIZE_CONFIG['x']['height'],\n",
    "    width=SIZE_CONFIG['x']['width'],\n",
    "    style_config=style_config,\n",
    "    save_path='../../../images/entity_total_rental_events_phoenix.png'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parcllabs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
